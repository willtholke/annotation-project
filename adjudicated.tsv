UID	Category	Snippet
huggingface|transformers|setup.py|000	Class	"class DepsTableUpdateCommand(Command):
    """"""
    A custom distutils command that updates the dependency table.
    usage: python setup.py deps_table_update
    """"""
"
huggingface|transformers|setup.py|001	Function	"def deps_list(*pkgs):
    return [deps[pkg] for pkg in pkgs]
"
huggingface|transformers|setup.py|002	Function	"    def initialize_options(self):
        pass
"
huggingface|transformers|setup.py|003	Function	"    def finalize_options(self):
        pass
"
huggingface|transformers|setup.py|004	Function	"    def run(self):
        entries = ""\n"".join([f'    ""{k}"": ""{v}"",' for k, v in deps.items()])
        content = [
            ""# THIS FILE HAS BEEN AUTOGENERATED. To update:"",
            ""# 1. modify the `_deps` dict in setup.py"",
            ""# 2. run `make deps_table_update``"",
            ""deps = {"",
            entries,
            ""}"",
            """",
        ]
        target = ""src/transformers/dependency_versions_table.py""
        print(f""updating {target}"")
        with open(target, ""w"", encoding=""utf-8"", newline=""\n"") as f:
            f.write(""\n"".join(content))
"
huggingface|transformers|create_circleci_config.py|000	Class	"class CircleCIJob:
    name: str
    additional_env: Dict[str, Any] = None
    cache_name: str = None
    cache_version: str = ""0.6""
    docker_image: List[Dict[str, str]] = None
    install_steps: List[str] = None
    marker: Optional[str] = None
    parallelism: Optional[int] = 1
    pytest_num_workers: int = 8
    pytest_options: Dict[str, Any] = None
    resource_class: Optional[str] = ""xlarge""
    tests_to_run: Optional[List[str]] = None
    working_directory: str = ""~/transformers""
"
huggingface|transformers|create_circleci_config.py|001	Function	"    def __post_init__(self):
        # Deal with defaults for mutable attributes.
        if self.additional_env is None:
            self.additional_env = {}
        if self.cache_name is None:
            self.cache_name = self.name
        if self.docker_image is None:
            # Let's avoid changing the default list and make a copy.
            self.docker_image = copy.deepcopy(DEFAULT_DOCKER_IMAGE)
        if self.install_steps is None:
            self.install_steps = []
        if self.pytest_options is None:
            self.pytest_options = {}
        if isinstance(self.tests_to_run, str):
            self.tests_to_run = [self.tests_to_run]
        if self.parallelism is None:
            self.parallelism = 1
"
huggingface|transformers|create_circleci_config.py|002	Function	"    def to_dict(self):
        env = COMMON_ENV_VARIABLES.copy()
        env.update(self.additional_env)
        job = {
            ""working_directory"": self.working_directory,
            ""docker"": self.docker_image,
            ""environment"": env,
        }
        if self.resource_class is not None:
            job[""resource_class""] = self.resource_class
        if self.parallelism is not None:
            job[""parallelism""] = self.parallelism
        steps = [
            ""checkout"",
            {""attach_workspace"": {""at"": ""~/transformers/test_preparation""}},
            {
                ""restore_cache"": {
                    ""keys"": [
                        f""v{self.cache_version}-{self.cache_name}-"" + '{{ checksum ""setup.py"" }}',
                        f""v{self.cache_version}-{self.cache_name}-"",
                    ]
                }
            },
        ]
        steps.extend([{""run"": l} for l in self.install_steps])
        steps.append(
            {
                ""save_cache"": {
                    ""key"": f""v{self.cache_version}-{self.cache_name}-"" + '{{ checksum ""setup.py"" }}',
                    ""paths"": [""~/.cache/pip""],
                }
            }
        )
        steps.append({""run"": {""name"": ""Show installed libraries and their versions"", ""command"": ""pip freeze | tee installed.txt""}})
        steps.append({""store_artifacts"": {""path"": ""~/transformers/installed.txt""}})
"
huggingface|transformers|create_circleci_config.py|003	Function	"    def job_name(self):
        return self.name if ""examples"" in self.name else f""tests_{self.name}""
"
huggingface|transformers|create_circleci_config.py|004	Function	"def create_circleci_config(folder=None):
    if folder is None:
        folder = os.getcwd()
    # Used in CircleCIJob.to_dict() to expand the test list (for using parallelism)
    os.environ[""test_preparation_dir""] = folder
    jobs = []
    all_test_file = os.path.join(folder, ""test_list.txt"")
    if os.path.exists(all_test_file):
        with open(all_test_file) as f:
            all_test_list = f.read()
    else:
        all_test_list = []
    if len(all_test_list) > 0:
        jobs.extend(PIPELINE_TESTS)
"
huggingface|transformers|conftest.py|000	Class	"class CustomOutputChecker(OutputChecker):
    def check_output(self, want, got, optionflags):
        if IGNORE_RESULT & optionflags:
            return True
        return OutputChecker.check_output(self, want, got, optionflags)
"
huggingface|transformers|conftest.py|001	Function	"def pytest_configure(config):
    config.addinivalue_line(
        ""markers"", ""is_pt_tf_cross_test: mark test to run only when PT and TF interactions are tested""
    )
    config.addinivalue_line(
        ""markers"", ""is_pt_flax_cross_test: mark test to run only when PT and FLAX interactions are tested""
    )
    config.addinivalue_line(
        ""markers"", ""is_pipeline_test: mark test to run only when pipelines are tested""
    )
    config.addinivalue_line(""markers"", ""is_staging_test: mark test to run only in the staging environment"")
"
huggingface|transformers|conftest.py|002	Function	"def pytest_addoption(parser):
    from transformers.testing_utils import pytest_addoption_shared
"
huggingface|transformers|conftest.py|003	Function	"def pytest_terminal_summary(terminalreporter):
    from transformers.testing_utils import pytest_terminal_summary_main
"
huggingface|transformers|conftest.py|004	Function	"def pytest_sessionfinish(session, exitstatus):
    # If no tests are collected, pytest exists with code 5, which makes the CI fail.
    if exitstatus == 5:
        session.exitstatus = 0
"
huggingface|transformers|conftest.py|005	Function	"    def check_output(self, want, got, optionflags):
        if IGNORE_RESULT & optionflags:
            return True
        return OutputChecker.check_output(self, want, got, optionflags)
"
psf|requests|setup.py|000	Class	"class PyTest(TestCommand):
    user_options = [(""pytest-args="", ""a"", ""Arguments to pass into py.test"")]
"
psf|requests|setup.py|001	Function	"    def initialize_options(self):
        TestCommand.initialize_options(self)
        try:
            from multiprocessing import cpu_count
"
psf|requests|setup.py|002	Function	"    def finalize_options(self):
        TestCommand.finalize_options(self)
        self.test_args = []
        self.test_suite = True
"
psf|requests|setup.py|003	Function	"    def run_tests(self):
        import pytest
"
psf|requests|flask_theme_support.py|000	Class	"class FlaskyStyle(Style):
    background_color = ""#f8f8f8""
    default_style = """"
"
psf|requests|flask_theme_support.py|001	Class	"        # No corresponding class for the following:
        #Text:                     """", # class:  ''
        Whitespace:                ""underline #f8f8f8"",      # class: 'w'
        Error:                     ""#a40000 border:#ef2929"", # class: 'err'
        Other:                     ""#000000"",                # class 'x'
"
psf|requests|__init__.py|000	Function	"def check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):
    urllib3_version = urllib3_version.split(""."")
    assert urllib3_version != [""dev""]  # Verify urllib3 isn't installed from git.
"
psf|requests|__init__.py|001	Function	"def _check_cryptography(cryptography_version):
    # cryptography < 1.3.4
    try:
        cryptography_version = list(map(int, cryptography_version.split(""."")))
    except ValueError:
        return
"
scrapy|scrapy|setup.py|000	Function	"def has_environment_marker_platform_impl_support():
    """"""Code extracted from 'pytest/setup.py'
    https://github.com/pytest-dev/pytest/blob/7538680c/setup.py#L31
"
scrapy|scrapy|conftest.py|000	Function	"def _py_files(folder):
    return (str(p) for p in Path(folder).rglob(""*.py""))
"
scrapy|scrapy|conftest.py|001	Function	"def chdir(tmpdir):
    """"""Change to pytest-provided temporary directory""""""
    tmpdir.chdir()
"
scrapy|scrapy|conftest.py|002	Function	"def pytest_addoption(parser):
    parser.addoption(
        ""--reactor"",
        default=""default"",
        choices=[""default"", ""asyncio""],
    )
"
scrapy|scrapy|conftest.py|003	Function	"def reactor_pytest(request):
    if not request.cls:
        # doctests
        return
    request.cls.reactor_pytest = request.config.getoption(""--reactor"")
    return request.cls.reactor_pytest
"
scrapy|scrapy|conftest.py|004	Function	"def only_asyncio(request, reactor_pytest):
    if request.node.get_closest_marker(""only_asyncio"") and reactor_pytest != ""asyncio"":
        pytest.skip(""This test is only run with --reactor=asyncio"")
"
scrapy|scrapy|conftest.py|005	Function	"def only_not_asyncio(request, reactor_pytest):
    if (
        request.node.get_closest_marker(""only_not_asyncio"")
        and reactor_pytest == ""asyncio""
    ):
        pytest.skip(""This test is only run without --reactor=asyncio"")
"
scrapy|scrapy|conftest.py|006	Function	"def pytest_configure(config):
    if config.getoption(""--reactor"") == ""asyncio"":
        install_reactor(""twisted.internet.asyncioreactor.AsyncioSelectorReactor"")
"
scrapy|scrapy|scrapydocs.py|000	Class	"class settingslist_node(nodes.General, nodes.Element):
    pass
"
scrapy|scrapy|scrapydocs.py|001	Class	"class SettingsListDirective(Directive):
    def run(self):
        return [settingslist_node("""")]
"
scrapy|scrapy|scrapydocs.py|002	Function	"    def run(self):
        return [settingslist_node("""")]
"
scrapy|scrapy|scrapydocs.py|003	Function	"def is_setting_index(node):
    if node.tagname == ""index"" and node[""entries""]:
        # index entries for setting directives look like:
        # [('pair', 'SETTING_NAME; setting', 'std:setting-SETTING_NAME', '')]
        entry_type, info, refid = node[""entries""][0][:3]
        return entry_type == ""pair"" and info.endswith(""; setting"")
    return False
"
scrapy|scrapy|scrapydocs.py|004	Function	"def get_setting_target(node):
    # target nodes are placed next to the node in the doc tree
    return node.parent[node.parent.index(node) + 1]
"
scrapy|scrapy|scrapydocs.py|005	Function	"def get_setting_name_and_refid(node):
    """"""Extract setting name from directive index node""""""
    entry_type, info, refid = node[""entries""][0][:3]
    return info.replace(""; setting"", """"), refid
"
scrapy|scrapy|scrapydocs.py|006	Function	"def collect_scrapy_settings_refs(app, doctree):
    env = app.builder.env
"
scrapy|scrapy|scrapydocs.py|007	Function	"def make_setting_element(setting_data, app, fromdocname):
    refnode = make_refnode(
        app.builder,
        fromdocname,
        todocname=setting_data[""docname""],
        targetid=setting_data[""refid""],
        child=nodes.Text(setting_data[""setting_name""]),
    )
    p = nodes.paragraph()
    p += refnode
"
scrapy|scrapy|scrapydocs.py|008	Function	"def replace_settingslist_nodes(app, doctree, fromdocname):
    env = app.builder.env
"
scrapy|scrapy|scrapydocs.py|009	Function	"def setup(app):
    app.add_crossref_type(
        directivename=""setting"",
        rolename=""setting"",
        indextemplate=""pair: %s; setting"",
    )
    app.add_crossref_type(
        directivename=""signal"",
        rolename=""signal"",
        indextemplate=""pair: %s; signal"",
    )
    app.add_crossref_type(
        directivename=""command"",
        rolename=""command"",
        indextemplate=""pair: %s; command"",
    )
    app.add_crossref_type(
        directivename=""reqmeta"",
        rolename=""reqmeta"",
        indextemplate=""pair: %s; reqmeta"",
    )
    app.add_role(""source"", source_role)
    app.add_role(""commit"", commit_role)
    app.add_role(""issue"", issue_role)
    app.add_role(""rev"", rev_role)
"
scrapy|scrapy|scrapydocs.py|010	Function	"def source_role(name, rawtext, text, lineno, inliner, options={}, content=[]):
    ref = ""https://github.com/scrapy/scrapy/blob/master/"" + text
    set_classes(options)
    node = nodes.reference(rawtext, text, refuri=ref, **options)
    return [node], []
"
scrapy|scrapy|scrapydocs.py|011	Function	"def issue_role(name, rawtext, text, lineno, inliner, options={}, content=[]):
    ref = ""https://github.com/scrapy/scrapy/issues/"" + text
    set_classes(options)
    node = nodes.reference(rawtext, ""issue "" + text, refuri=ref, **options)
    return [node], []
"
scrapy|scrapy|scrapydocs.py|012	Function	"def commit_role(name, rawtext, text, lineno, inliner, options={}, content=[]):
    ref = ""https://github.com/scrapy/scrapy/commit/"" + text
    set_classes(options)
    node = nodes.reference(rawtext, ""commit "" + text, refuri=ref, **options)
    return [node], []
"
scrapy|scrapy|scrapydocs.py|013	Function	"def rev_role(name, rawtext, text, lineno, inliner, options={}, content=[]):
    ref = ""http://hg.scrapy.org/scrapy/changeset/"" + text
    set_classes(options)
    node = nodes.reference(rawtext, ""r"" + text, refuri=ref, **options)
    return [node], []
"
scrapy|scrapy|conf.py|000	Function	"def setup(app):
    app.connect(""autodoc-skip-member"", maybe_skip_member)
"
scrapy|scrapy|conf.py|001	Function	"def maybe_skip_member(app, what, name, obj, skip, options):
    if not skip:
        # autodocs was generating a text ""alias of"" for the following members
        # https://github.com/sphinx-doc/sphinx/issues/4422
        return name in {""default_item_class"", ""default_selector_class""}
    return skip
"
scrapy|scrapy|conftest.py|007	Function	"def load_response(url: str, filename: str) -> HtmlResponse:
    input_path = Path(__file__).parent / ""_tests"" / filename
    return HtmlResponse(url, body=input_path.read_bytes())
"
scrapy|scrapy|conftest.py|008	Function	"def setup(namespace):
    namespace[""load_response""] = load_response
"
certbot|certbot|challenges.py|000	Class	"class Challenge(jose.TypedJSONObjectWithFields):
    # _fields_to_partial_json
    """"""ACME challenge.""""""
    TYPES: Dict[str, Type['Challenge']] = {}
"
certbot|certbot|challenges.py|001	Class	"class ChallengeResponse(jose.TypedJSONObjectWithFields):
    # _fields_to_partial_json
    """"""ACME challenge response.""""""
    TYPES: Dict[str, Type['ChallengeResponse']] = {}
"
certbot|certbot|challenges.py|002	Class	"class UnrecognizedChallenge(Challenge):
    """"""Unrecognized challenge.
"
certbot|certbot|challenges.py|003	Class	"class _TokenChallenge(Challenge):
    """"""Challenge with token.
"
certbot|certbot|challenges.py|004	Class	"class KeyAuthorizationChallengeResponse(ChallengeResponse):
    """"""Response to Challenges based on Key Authorization.
"
certbot|certbot|challenges.py|005	Class	"class KeyAuthorizationChallenge(_TokenChallenge, metaclass=abc.ABCMeta):
    """"""Challenge based on Key Authorization.
"
certbot|certbot|challenges.py|006	Class	"class DNS01Response(KeyAuthorizationChallengeResponse):
    """"""ACME dns-01 challenge response.""""""
    typ = ""dns-01""
"
certbot|certbot|challenges.py|007	Class	"class DNS01(KeyAuthorizationChallenge):
    """"""ACME dns-01 challenge.""""""
    response_cls = DNS01Response
    typ = response_cls.typ
"
certbot|certbot|challenges.py|008	Class	"class HTTP01Response(KeyAuthorizationChallengeResponse):
    """"""ACME http-01 challenge response.""""""
    typ = ""http-01""
"
certbot|certbot|challenges.py|009	Class	"class HTTP01(KeyAuthorizationChallenge):
    """"""ACME http-01 challenge.""""""
    response_cls = HTTP01Response
    typ = response_cls.typ
"
certbot|certbot|challenges.py|010	Class	"class TLSALPN01Response(KeyAuthorizationChallengeResponse):
    """"""ACME tls-alpn-01 challenge response.""""""
    typ = ""tls-alpn-01""
"
certbot|certbot|challenges.py|011	Class	"class TLSALPN01(KeyAuthorizationChallenge):
    """"""ACME tls-alpn-01 challenge.""""""
    response_cls = TLSALPN01Response
    typ = response_cls.typ
"
certbot|certbot|challenges.py|012	Class	"class DNS(_TokenChallenge):
    """"""ACME ""dns"" challenge.""""""
    typ = ""dns""
"
certbot|certbot|challenges.py|013	Class	"class DNSResponse(ChallengeResponse):
    """"""ACME ""dns"" challenge response.
"
certbot|certbot|challenges.py|014	Function	"    def from_json(cls: Type[GenericChallenge],
                  jobj: Mapping[str, Any]) -> Union[GenericChallenge, 'UnrecognizedChallenge']:
        try:
            return cast(GenericChallenge, super().from_json(jobj))
        except jose.UnrecognizedTypeError as error:
            logger.debug(error)
            return UnrecognizedChallenge.from_json(jobj)
"
certbot|certbot|challenges.py|015	Function	"    def to_partial_json(self) -> Dict[str, Any]:
        # Removes the `type` field which is inserted by TypedJSONObjectWithFields.to_partial_json.
        # This field breaks RFC8555 compliance.
        jobj = super().to_partial_json()
        jobj.pop(self.type_field_name, None)
        return jobj
"
certbot|certbot|challenges.py|016	Function	"    def __init__(self, jobj: Mapping[str, Any]) -> None:
        super().__init__()
        object.__setattr__(self, ""jobj"", jobj)
"
certbot|certbot|challenges.py|017	Function	"    def to_partial_json(self) -> Dict[str, Any]:
        return self.jobj  # pylint: disable=no-member
"
certbot|certbot|challenges.py|018	Function	"    def from_json(cls, jobj: Mapping[str, Any]) -> 'UnrecognizedChallenge':
        return cls(jobj)
"
certbot|certbot|challenges.py|019	Function	"    def good_token(self) -> bool:  # XXX: @token.decoder
        """"""Is `token` good?
"
certbot|certbot|challenges.py|020	Function	"    def verify(self, chall: 'KeyAuthorizationChallenge', account_public_key: jose.JWK) -> bool:
        """"""Verify the key authorization.
"
certbot|certbot|challenges.py|021	Function	"    def to_partial_json(self) -> Dict[str, Any]:
        jobj = super().to_partial_json()
        jobj.pop('keyAuthorization', None)
        return jobj
"
certbot|certbot|challenges.py|022	Function	"    def key_authorization(self, account_key: jose.JWK) -> str:
        """"""Generate Key Authorization.
"
certbot|certbot|challenges.py|023	Function	"    def response(self, account_key: jose.JWK) -> KeyAuthorizationChallengeResponse:
        """"""Generate response to the challenge.
"
certbot|certbot|challenges.py|024	Function	"    def validation(self, account_key: jose.JWK, **kwargs: Any) -> Any:
        """"""Generate validation for the challenge.
"
certbot|certbot|challenges.py|025	Function	"    def response_and_validation(self, account_key: jose.JWK, *args: Any, **kwargs: Any
                                ) -> Tuple[KeyAuthorizationChallengeResponse, Any]:
        """"""Generate response and validation.
"
certbot|certbot|challenges.py|026	Function	"    def simple_verify(self, chall: 'DNS01', domain: str, account_public_key: jose.JWK) -> bool:  # pylint: disable=unused-argument
        """"""Simple verify.
"
certbot|certbot|challenges.py|027	Function	"    def validation(self, account_key: jose.JWK, **unused_kwargs: Any) -> str:
        """"""Generate validation.
"
certbot|certbot|challenges.py|028	Function	"    def validation_domain_name(self, name: str) -> str:
        """"""Domain name for TXT validation record.
"
certbot|certbot|challenges.py|029	Function	"    def simple_verify(self, chall: 'HTTP01', domain: str, account_public_key: jose.JWK,
                      port: Optional[int] = None, timeout: int = 30) -> bool:
        """"""Simple verify.
"
certbot|certbot|challenges.py|030	Function	"    def path(self) -> str:
        """"""Path (starting with '/') for provisioned resource.
"
certbot|certbot|challenges.py|031	Function	"    def uri(self, domain: str) -> str:
        """"""Create an URI to the provisioned resource.
"
certbot|certbot|challenges.py|032	Function	"    def validation(self, account_key: jose.JWK, **unused_kwargs: Any) -> str:
        """"""Generate validation.
"
certbot|certbot|challenges.py|033	Function	"    def h(self) -> bytes:
        """"""Hash value stored in challenge certificate""""""
        return hashlib.sha256(self.key_authorization.encode('utf-8')).digest()
"
certbot|certbot|challenges.py|034	Function	"    def gen_cert(self, domain: str, key: Optional[crypto.PKey] = None, bits: int = 2048
                 ) -> Tuple[crypto.X509, crypto.PKey]:
        """"""Generate tls-alpn-01 certificate.
"
certbot|certbot|challenges.py|035	Function	"    def probe_cert(self, domain: str, host: Optional[str] = None,
                   port: Optional[int] = None) -> crypto.X509:
        """"""Probe tls-alpn-01 challenge certificate.
"
certbot|certbot|challenges.py|036	Function	"    def verify_cert(self, domain: str, cert: crypto.X509) -> bool:
        """"""Verify tls-alpn-01 challenge certificate.
"
certbot|certbot|challenges.py|037	Function	"    def simple_verify(self, chall: 'TLSALPN01', domain: str, account_public_key: jose.JWK,
                      cert: Optional[crypto.X509] = None, host: Optional[str] = None,
                      port: Optional[int] = None) -> bool:
        """"""Simple verify.
"
certbot|certbot|challenges.py|038	Function	"    def validation(self, account_key: jose.JWK, **kwargs: Any) -> Tuple[crypto.X509, crypto.PKey]:
        """"""Generate validation.
"
certbot|certbot|challenges.py|039	Function	"    def is_supported() -> bool:
        """"""
        Check if TLS-ALPN-01 challenge is supported on this machine.
        This implies that a recent version of OpenSSL is installed (>= 1.0.2),
        or a recent cryptography version shipped with the OpenSSL library is installed.
"
certbot|certbot|challenges.py|040	Function	"    def gen_validation(self, account_key: jose.JWK, alg: jose.JWASignature = jose.RS256,
                       **kwargs: Any) -> jose.JWS:
        """"""Generate validation.
"
certbot|certbot|challenges.py|041	Function	"    def check_validation(self, validation: jose.JWS, account_public_key: jose.JWK) -> bool:
        """"""Check validation.
"
certbot|certbot|challenges.py|042	Function	"    def gen_response(self, account_key: jose.JWK, **kwargs: Any) -> 'DNSResponse':
        """"""Generate response.
"
certbot|certbot|challenges.py|043	Function	"    def validation_domain_name(self, name: str) -> str:
        """"""Domain name for TXT validation record.
"
certbot|certbot|challenges.py|044	Function	"    def check_validation(self, chall: 'DNS', account_public_key: jose.JWK) -> bool:
        """"""Check validation.
"
certbot|certbot|client.py|000	Class	"class ClientV2:
    """"""ACME client for a v2 API.
"
certbot|certbot|client.py|001	Class	"class ClientNetwork:
    """"""Wrapper around requests that signs POSTs for authentication.
"
certbot|certbot|client.py|002	Function	"    def __init__(self, directory: messages.Directory, net: 'ClientNetwork') -> None:
        """"""Initialize.
"
certbot|certbot|client.py|003	Function	"    def new_account(self, new_account: messages.NewRegistration) -> messages.RegistrationResource:
        """"""Register.
"
certbot|certbot|client.py|004	Function	"    def query_registration(self, regr: messages.RegistrationResource
                           ) -> messages.RegistrationResource:
        """"""Query server about registration.
"
certbot|certbot|client.py|005	Function	"    def update_registration(self, regr: messages.RegistrationResource,
                            update: Optional[messages.Registration] = None
                            ) -> messages.RegistrationResource:
        """"""Update registration.
"
certbot|certbot|client.py|006	Function	"    def _get_v2_account(self, regr: messages.RegistrationResource, update_body: bool = False
                       ) -> messages.RegistrationResource:
        self.net.account = None
        only_existing_reg = regr.body.update(only_return_existing=True)
        response = self._post(self.directory['newAccount'], only_existing_reg)
        updated_uri = response.headers['Location']
        new_regr = regr.update(body=messages.Registration.from_json(response.json())
                               if update_body else regr.body,
                               uri=updated_uri)
        self.net.account = new_regr
        return new_regr
"
certbot|certbot|client.py|007	Function	"    def new_order(self, csr_pem: bytes) -> messages.OrderResource:
        """"""Request a new Order object from the server.
"
certbot|certbot|client.py|008	Function	"    def poll(self, authzr: messages.AuthorizationResource
             ) -> Tuple[messages.AuthorizationResource, requests.Response]:
        """"""Poll Authorization Resource for status.
"
certbot|certbot|client.py|009	Function	"    def poll_and_finalize(self, orderr: messages.OrderResource,
                          deadline: Optional[datetime.datetime] = None) -> messages.OrderResource:
        """"""Poll authorizations and finalize the order.
"
certbot|certbot|client.py|010	Function	"    def poll_authorizations(self, orderr: messages.OrderResource, deadline: datetime.datetime
                            ) -> messages.OrderResource:
        """"""Poll Order Resource for status.""""""
        responses = []
        for url in orderr.body.authorizations:
            while datetime.datetime.now() < deadline:
                authzr = self._authzr_from_response(self._post_as_get(url), uri=url)
                if authzr.body.status != messages.STATUS_PENDING:  # pylint: disable=no-member
                    responses.append(authzr)
                    break
                time.sleep(1)
        # If we didn't get a response for every authorization, we fell through
        # the bottom of the loop due to hitting the deadline.
        if len(responses) < len(orderr.body.authorizations):
            raise errors.TimeoutError()
        failed = []
        for authzr in responses:
            if authzr.body.status != messages.STATUS_VALID:
                for chall in authzr.body.challenges:
                    if chall.error is not None:
                        failed.append(authzr)
        if failed:
            raise errors.ValidationError(failed)
        return orderr.update(authorizations=responses)
"
certbot|certbot|client.py|011	Function	"    def finalize_order(self, orderr: messages.OrderResource, deadline: datetime.datetime,
                       fetch_alternative_chains: bool = False) -> messages.OrderResource:
        """"""Finalize an order and obtain a certificate.
"
certbot|certbot|client.py|012	Function	"    def revoke(self, cert: jose.ComparableX509, rsn: int) -> None:
        """"""Revoke certificate.
"
certbot|certbot|client.py|013	Function	"    def external_account_required(self) -> bool:
        """"""Checks if ACME server requires External Account Binding authentication.""""""
        return hasattr(self.directory, 'meta') and \
               hasattr(self.directory.meta, 'external_account_required') and \
               self.directory.meta.external_account_required
"
certbot|certbot|client.py|014	Function	"    def _post_as_get(self, *args: Any, **kwargs: Any) -> requests.Response:
        """"""
        Send GET request using the POST-as-GET protocol.
        :param args:
        :param kwargs:
        :return:
        """"""
        new_args = args[:1] + (None,) + args[1:]
        return self._post(*new_args, **kwargs)
"
certbot|certbot|client.py|015	Function	"    def _get_links(self, response: requests.Response, relation_type: str) -> List[str]:
        """"""
        Retrieves all Link URIs of relation_type from the response.
        :param requests.Response response: The requests HTTP response.
        :param str relation_type: The relation type to filter by.
        """"""
        # Can't use response.links directly because it drops multiple links
        # of the same relation type, which is possible in RFC8555 responses.
        if 'Link' not in response.headers:
            return []
        links = parse_header_links(response.headers['Link'])
        return [l['url'] for l in links
                if 'rel' in l and 'url' in l and l['rel'] == relation_type]
"
certbot|certbot|client.py|016	Function	"    def get_directory(cls, url: str, net: 'ClientNetwork') -> messages.Directory:
        """"""
        Retrieves the ACME directory (RFC 8555 section 7.1.1) from the ACME server.
        :param str url: the URL where the ACME directory is available
        :param ClientNetwork net: the ClientNetwork to use to make the request
"
certbot|certbot|client.py|017	Function	"    def _regr_from_response(cls, response: requests.Response, uri: Optional[str] = None,
                            terms_of_service: Optional[str] = None
                            ) -> messages.RegistrationResource:
        if 'terms-of-service' in response.links:
            terms_of_service = response.links['terms-of-service']['url']
"
certbot|certbot|client.py|018	Function	"    def _send_recv_regr(self, regr: messages.RegistrationResource,
                        body: messages.Registration) -> messages.RegistrationResource:
        response = self._post(regr.uri, body)
"
certbot|certbot|client.py|019	Function	"    def _post(self, *args: Any, **kwargs: Any) -> requests.Response:
        """"""Wrapper around self.net.post that adds the newNonce URL.
"
certbot|certbot|client.py|020	Function	"    def deactivate_registration(self, regr: messages.RegistrationResource
                                ) -> messages.RegistrationResource:
        """"""Deactivate registration.
"
certbot|certbot|client.py|021	Function	"    def deactivate_authorization(self,
                                 authzr: messages.AuthorizationResource
                                 ) -> messages.AuthorizationResource:
        """"""Deactivate authorization.
"
certbot|certbot|client.py|022	Function	"    def _authzr_from_response(self, response: requests.Response,
                              identifier: Optional[messages.Identifier] = None,
                              uri: Optional[str] = None) -> messages.AuthorizationResource:
        authzr = messages.AuthorizationResource(
            body=messages.Authorization.from_json(response.json()),
            uri=response.headers.get('Location', uri))
        if identifier is not None and authzr.body.identifier != identifier:  # pylint: disable=no-member
            raise errors.UnexpectedUpdate(authzr)
        return authzr
"
certbot|certbot|client.py|023	Function	"    def answer_challenge(self, challb: messages.ChallengeBody,
                         response: challenges.ChallengeResponse) -> messages.ChallengeResource:
        """"""Answer challenge.
"
certbot|certbot|client.py|024	Function	"    def retry_after(cls, response: requests.Response, default: int) -> datetime.datetime:
        """"""Compute next `poll` time based on response ``Retry-After`` header.
"
certbot|certbot|client.py|025	Function	"    def _revoke(self, cert: jose.ComparableX509, rsn: int, url: str) -> None:
        """"""Revoke certificate.
"
certbot|certbot|client.py|026	Function	"    def __init__(self, key: jose.JWK, account: Optional[messages.RegistrationResource] = None,
                 alg: jose.JWASignature = jose.RS256, verify_ssl: bool = True,
                 user_agent: str = 'acme-python', timeout: int = DEFAULT_NETWORK_TIMEOUT) -> None:
        self.key = key
        self.account = account
        self.alg = alg
        self.verify_ssl = verify_ssl
        self._nonces: Set[Text] = set()
        self.user_agent = user_agent
        self.session = requests.Session()
        self._default_timeout = timeout
        adapter = HTTPAdapter()
"
certbot|certbot|client.py|027	Function	"    def __del__(self) -> None:
        # Try to close the session, but don't show exceptions to the
        # user if the call to close() fails. See #4840.
        try:
            self.session.close()
        except Exception:  # pylint: disable=broad-except
            pass
"
certbot|certbot|client.py|028	Function	"    def _wrap_in_jws(self, obj: jose.JSONDeSerializable, nonce: str, url: str) -> str:
        """"""Wrap `JSONDeSerializable` object in JWS.
"
certbot|certbot|client.py|029	Function	"    def _check_response(cls, response: requests.Response,
                        content_type: Optional[str] = None) -> requests.Response:
        """"""Check response content and its type.
"
certbot|certbot|client.py|030	Function	"    def _send_request(self, method: str, url: str, *args: Any, **kwargs: Any) -> requests.Response:
        """"""Send HTTP request.
"
certbot|certbot|client.py|031	Function	"    def head(self, *args: Any, **kwargs: Any) -> requests.Response:
        """"""Send HEAD request without checking the response.
"
certbot|certbot|client.py|032	Function	"    def get(self, url: str, content_type: str = JSON_CONTENT_TYPE,
            **kwargs: Any) -> requests.Response:
        """"""Send GET request and check response.""""""
        return self._check_response(
            self._send_request('GET', url, **kwargs), content_type=content_type)
"
certbot|certbot|client.py|033	Function	"    def _add_nonce(self, response: requests.Response) -> None:
        if self.REPLAY_NONCE_HEADER in response.headers:
            nonce = response.headers[self.REPLAY_NONCE_HEADER]
            try:
                decoded_nonce = jws.Header._fields['nonce'].decode(nonce)
            except jose.DeserializationError as error:
                raise errors.BadNonce(nonce, error)
            logger.debug('Storing nonce: %s', nonce)
            self._nonces.add(decoded_nonce)
        else:
            raise errors.MissingNonce(response)
"
certbot|certbot|client.py|034	Function	"    def _get_nonce(self, url: str, new_nonce_url: str) -> str:
        if not self._nonces:
            logger.debug('Requesting fresh nonce')
            if new_nonce_url is None:
                response = self.head(url)
            else:
                # request a new nonce from the acme newNonce endpoint
                response = self._check_response(self.head(new_nonce_url), content_type=None)
            self._add_nonce(response)
        return self._nonces.pop()
"
certbot|certbot|client.py|035	Function	"    def post(self, *args: Any, **kwargs: Any) -> requests.Response:
        """"""POST object wrapped in `.JWS` and check response.
"
certbot|certbot|client.py|036	Function	"    def _post_once(self, url: str, obj: jose.JSONDeSerializable,
                   content_type: str = JOSE_CONTENT_TYPE, **kwargs: Any) -> requests.Response:
        new_nonce_url = kwargs.pop('new_nonce_url', None)
        data = self._wrap_in_jws(obj, self._get_nonce(url, new_nonce_url), url)
        kwargs.setdefault('headers', {'Content-Type': content_type})
        response = self._send_request('POST', url, data=data, **kwargs)
        response = self._check_response(response, content_type=content_type)
        self._add_nonce(response)
        return response
"
certbot|certbot|crypto_util.py|000	Class	"class _DefaultCertSelection:
    def __init__(self, certs: Mapping[bytes, Tuple[crypto.PKey, crypto.X509]]):
        self.certs = certs
"
certbot|certbot|crypto_util.py|001	Class	"class SSLSocket:  # pylint: disable=too-few-public-methods
    """"""SSL wrapper for sockets.
"
certbot|certbot|crypto_util.py|002	Class	"    class FakeConnection:
        """"""Fake OpenSSL.SSL.Connection.""""""
"
certbot|certbot|crypto_util.py|003	Function	"    def __init__(self, certs: Mapping[bytes, Tuple[crypto.PKey, crypto.X509]]):
        self.certs = certs
"
certbot|certbot|crypto_util.py|004	Function	"    def __call__(self, connection: SSL.Connection) -> Optional[Tuple[crypto.PKey, crypto.X509]]:
        server_name = connection.get_servername()
        if server_name:
            return self.certs.get(server_name, None)
        return None # pragma: no cover
"
certbot|certbot|crypto_util.py|005	Function	"    def __init__(self, sock: socket.socket,
                 certs: Optional[Mapping[bytes, Tuple[crypto.PKey, crypto.X509]]] = None,
                 method: int = _DEFAULT_SSL_METHOD,
                 alpn_selection: Optional[Callable[[SSL.Connection, List[bytes]], bytes]] = None,
                 cert_selection: Optional[Callable[[SSL.Connection],
                                                   Optional[Tuple[crypto.PKey,
                                                                  crypto.X509]]]] = None
                 ) -> None:
        self.sock = sock
        self.alpn_selection = alpn_selection
        self.method = method
        if not cert_selection and not certs:
            raise ValueError(""Neither cert_selection or certs specified."")
        if cert_selection and certs:
            raise ValueError(""Both cert_selection and certs specified."")
        actual_cert_selection: Union[_DefaultCertSelection,
                                     Optional[Callable[[SSL.Connection],
                                                       Optional[Tuple[crypto.PKey,
                                                                crypto.X509]]]]] = cert_selection
        if actual_cert_selection is None:
            actual_cert_selection = _DefaultCertSelection(certs if certs else {})
        self.cert_selection = actual_cert_selection
"
certbot|certbot|crypto_util.py|006	Function	"    def __getattr__(self, name: str) -> Any:
        return getattr(self.sock, name)
"
certbot|certbot|crypto_util.py|007	Function	"    def _pick_certificate_cb(self, connection: SSL.Connection) -> None:
        """"""SNI certificate callback.
"
certbot|certbot|crypto_util.py|008	Function	"        def __init__(self, connection: SSL.Connection) -> None:
            self._wrapped = connection
"
certbot|certbot|crypto_util.py|009	Function	"        def __getattr__(self, name: str) -> Any:
            return getattr(self._wrapped, name)
"
certbot|certbot|crypto_util.py|010	Function	"        def shutdown(self, *unused_args: Any) -> bool:
            # OpenSSL.SSL.Connection.shutdown doesn't accept any args
            try:
                return self._wrapped.shutdown()
            except SSL.Error as error:
                # We wrap the error so we raise the same error type as sockets
                # in the standard library. This is useful when this object is
                # used by code which expects a standard socket such as
                # socketserver in the standard library.
                raise socket.error(error)
"
certbot|certbot|crypto_util.py|011	Function	"    def accept(self) -> Tuple[FakeConnection, Any]:  # pylint: disable=missing-function-docstring
        sock, addr = self.sock.accept()
"
certbot|certbot|crypto_util.py|012	Function	"def probe_sni(name: bytes, host: bytes, port: int = 443, timeout: int = 300,  # pylint: disable=too-many-arguments
              method: int = _DEFAULT_SSL_METHOD, source_address: Tuple[str, int] = ('', 0),
              alpn_protocols: Optional[Sequence[bytes]] = None) -> crypto.X509:
    """"""Probe SNI server for SSL certificate.
"
certbot|certbot|crypto_util.py|013	Function	"def make_csr(private_key_pem: bytes, domains: Optional[Union[Set[str], List[str]]] = None,
             must_staple: bool = False,
             ipaddrs: Optional[List[Union[ipaddress.IPv4Address, ipaddress.IPv6Address]]] = None
             ) -> bytes:
    """"""Generate a CSR containing domains or IPs as subjectAltNames.
"
certbot|certbot|crypto_util.py|014	Function	"def _pyopenssl_cert_or_req_all_names(loaded_cert_or_req: Union[crypto.X509, crypto.X509Req]
                                     ) -> List[str]:
    # unlike its name this only outputs DNS names, other type of idents will ignored
    common_name = loaded_cert_or_req.get_subject().CN
    sans = _pyopenssl_cert_or_req_san(loaded_cert_or_req)
"
certbot|certbot|crypto_util.py|015	Function	"def _pyopenssl_cert_or_req_san(cert_or_req: Union[crypto.X509, crypto.X509Req]) -> List[str]:
    """"""Get Subject Alternative Names from certificate or CSR using pyOpenSSL.
"
certbot|certbot|crypto_util.py|016	Function	"def _pyopenssl_cert_or_req_san_ip(cert_or_req: Union[crypto.X509, crypto.X509Req]) -> List[str]:
    """"""Get Subject Alternative Names IPs from certificate or CSR using pyOpenSSL.
"
certbot|certbot|crypto_util.py|017	Function	"def _pyopenssl_extract_san_list_raw(cert_or_req: Union[crypto.X509, crypto.X509Req]) -> List[str]:
    """"""Get raw SAN string from cert or csr, parse it as UTF-8 and return.
"
certbot|certbot|crypto_util.py|018	Function	"def gen_ss_cert(key: crypto.PKey, domains: Optional[List[str]] = None,
                not_before: Optional[int] = None,
                validity: int = (7 * 24 * 60 * 60), force_san: bool = True,
                extensions: Optional[List[crypto.X509Extension]] = None,
                ips: Optional[List[Union[ipaddress.IPv4Address, ipaddress.IPv6Address]]] = None
                ) -> crypto.X509:
    """"""Generate new self-signed certificate.
"
certbot|certbot|crypto_util.py|019	Function	"def dump_pyopenssl_chain(chain: Union[List[jose.ComparableX509], List[crypto.X509]],
                         filetype: int = crypto.FILETYPE_PEM) -> bytes:
    """"""Dump certificate chain into a bundle.
"
certbot|certbot|crypto_util.py|020	Function	"    def _dump_cert(cert: Union[jose.ComparableX509, crypto.X509]) -> bytes:
        if isinstance(cert, jose.ComparableX509):
            if isinstance(cert.wrapped, crypto.X509Req):
                raise errors.Error(""Unexpected CSR provided."")  # pragma: no cover
            cert = cert.wrapped
        return crypto.dump_certificate(filetype, cert)
"
openai|whisper|setup.py|000	Function	"def read_version(fname=""whisper/version.py""):
    exec(compile(open(fname, encoding=""utf-8"").read(), fname, ""exec""))
    return locals()[""__version__""]
"
openai|whisper|setup.py|001	Function	"def read_version(fname=""whisper/version.py""):
    exec(compile(open(fname, encoding=""utf-8"").read(), fname, ""exec""))
    return locals()[""__version__""]
"
openai|whisper|conftest.py|000	Function	"def pytest_configure(config):
    config.addinivalue_line(""markers"", ""requires_cuda"")
"
openai|whisper|conftest.py|001	Function	"def random():
    rand.seed(42)
    numpy.random.seed(42)
"
openai|whisper|test_audio.py|000	Function	"def test_audio():
    audio_path = os.path.join(os.path.dirname(__file__), ""jfk.flac"")
    audio = load_audio(audio_path)
    assert audio.ndim == 1
    assert SAMPLE_RATE * 10 < audio.shape[0] < SAMPLE_RATE * 12
    assert 0 < audio.std() < 1
"
openai|whisper|test_normalizer.py|000	Function	"def test_number_normalizer(std):
    assert std(""two"") == ""2""
    assert std(""thirty one"") == ""31""
    assert std(""five twenty four"") == ""524""
    assert std(""nineteen ninety nine"") == ""1999""
    assert std(""twenty nineteen"") == ""2019""
"
openai|whisper|test_normalizer.py|001	Function	"def test_spelling_normalizer():
    std = EnglishSpellingNormalizer()
"
openai|whisper|test_normalizer.py|002	Function	"def test_text_normalizer():
    std = EnglishTextNormalizer()
    assert std(""Let's"") == ""let us""
    assert std(""he's like"") == ""he is like""
    assert std(""she's been like"") == ""she has been like""
    assert std(""10km"") == ""10 km""
    assert std(""10mm"") == ""10 mm""
    assert std(""RC232"") == ""rc 232""
"
httpie|httpie|setup.py|000	Function	"def long_description():
    with open('README.md', encoding='utf-8') as f:
        return f.read()
"
httpie|httpie|fetch.py|000	Class	"class FinishedForNow(Exception):
    """"""Raised when remaining GitHub rate limit is zero.""""""
"
httpie|httpie|fetch.py|001	Function	"def main(previous_release: str, current_release: str) -> int:
    since = release_date(previous_release)
    until = release_date(current_release)
"
httpie|httpie|fetch.py|002	Function	"def find_committers(since: str, until: str) -> FullNames:
    url = f'{REPO_URL}/commits'
    page = 1
    per_page = 100
    params = {
        'since': since,
        'until': until,
        'per_page': per_page,
    }
    committers: FullNames = set()
"
httpie|httpie|fetch.py|003	Function	"def find_reporters(since: str, until: str) -> GitHubLogins:
    url = f'{API_URL}/search/issues'
    page = 1
    per_page = 100
    params = {
        'q': f'repo:{REPO}/{OWNER} is:issue closed:{since}..{until}',
        'per_page': per_page,
    }
    reporters: GitHubLogins = set()
"
httpie|httpie|fetch.py|004	Function	"def merge_all_the_people(release: str, contributors: People, committers: FullNames, reporters: GitHubLogins) -> None:
    """"""
    >>> contributors = {'Alice': new_person(github='alice', twitter='alice')}
    >>> merge_all_the_people('2.6.0', contributors, {}, {})
    >>> contributors
    {'Alice': {'committed': [], 'reported': [], 'github': 'alice', 'twitter': 'alice'}}
"
httpie|httpie|fetch.py|005	Function	"def release_date(release: str) -> str:
    date = check_output(['git', 'log', '-1', '--format=%ai', release], text=True).strip()
    return datetime.strptime(date, '%Y-%m-%d %H:%M:%S %z').isoformat()
"
httpie|httpie|fetch.py|006	Function	"def load_awesome_people() -> People:
    try:
        with DB_FILE.open(encoding='utf-8') as fh:
            return json.load(fh)
    except (FileNotFoundError, ValueError):
        return {}
"
httpie|httpie|fetch.py|007	Function	"def fetch(url: str, params: Optional[Dict[str, str]] = None) -> UserInfo:
    headers = {
        'Accept': 'application/vnd.github.v3+json',
        'Authentication': f'token {GITHUB_TOKEN}'
    }
    for retry in range(1, 6):
        debug(f'[{retry}/5]', f'{url = }', f'{params = }')
        with requests.get(url, params=params, headers=headers) as req:
            try:
                req.raise_for_status()
            except requests.exceptions.HTTPError as exc:
                if exc.response.status_code == 403:
                    # 403 Client Error: rate limit exceeded for url: ...
                    now = int(datetime.utcnow().timestamp())
                    xrate_limit_reset = int(exc.response.headers['X-RateLimit-Reset'])
                    wait = xrate_limit_reset - now
                    if wait > 20:
                        raise FinishedForNow()
                    debug(' !', 'Waiting', wait, 'seconds before another try ...')
                    sleep(wait)
                continue
            return req.json()
    assert ValueError('Rate limit exceeded')
"
httpie|httpie|fetch.py|008	Function	"def new_person(**kwargs: str) -> Person:
    data = deepcopy(DEFAULT_PERSON)
    data.update(**kwargs)
    return data
"
httpie|httpie|fetch.py|009	Function	"def user(fullname: Optional[str] = '', github_username: Optional[str] = '') -> UserInfo:
    if github_username:
        url = f'{API_URL}/users/{github_username}'
        return fetch(url)
"
httpie|httpie|fetch.py|010	Function	"def fetch_missing_users_details(people: People) -> None:
    for name, details in people.items():
        if details['github'] and details['twitter']:
            continue
        user_info = user(github_username=details['github'], fullname=name)
        if not details['github']:
            details['github'] = user_info['login']
        if not details['twitter']:
            details['twitter'] = user_info['twitter_username']
"
httpie|httpie|fetch.py|011	Function	"def save_awesome_people(people: People) -> None:
    with DB_FILE.open(mode='w', encoding='utf-8') as fh:
        json.dump(people, fh, indent=4, sort_keys=True)
        fh.write(""\n"")
"
httpie|httpie|fetch.py|012	Function	"def debug(*args: Any) -> None:
    if os.getenv('DEBUG') == '1':
        print(*args)
"
httpie|httpie|generate.py|000	Function	"def generate_snippets(release: str) -> str:
    people = load_awesome_people()
    contributors = {
        name: details
        for name, details in people.items()
        if details['github'] not in IGNORE_ACCOUNTS
        and (release in details['committed'] or release in details['reported'])
    }
"
httpie|httpie|generate.py|001	Function	"def generate_documentation() -> str:
    database = load_database()
    structure = build_docs_structure(database)
    template = Template(source=TPL_FILE.read_text(encoding='utf-8'))
    output = template.render(structure=structure)
    output = clean_template_output(output)
    return output
"
httpie|httpie|generate.py|002	Function	"def save_doc_file(content: str) -> None:
    current_doc = load_doc_file()
    marker_start = current_doc.find(MARKER_START) + len(MARKER_START)
    assert marker_start > 0, 'cannot find the start marker'
    marker_end = current_doc.find(MARKER_END, marker_start)
    assert marker_start < marker_end, f'{marker_end=} < {marker_start=}'
    updated_doc = (
        current_doc[:marker_start]
        + '\n\n'
        + content
        + '\n\n'
        + current_doc[marker_end:]
    )
    if current_doc != updated_doc:
        DOC_FILE.write_text(updated_doc, encoding='utf-8')
"
httpie|httpie|generate.py|003	Function	"def build_docs_structure(database: Database):
    tools = database[KEY_TOOLS]
    assert len(tools) == len({tool['title'] for tool in tools.values()}), 'tool titles need to be unique'
    tree = database[KEY_DOC_STRUCTURE]
    structure = []
    for platform, tools_ids in tree.items():
        assert platform.isalnum(), f'{platform=} must be alphanumeric for generated links to work'
        platform_tools = [tools[tool_id] for tool_id in tools_ids]
        structure.append((platform, platform_tools))
    return structure
"
httpie|httpie|generate.py|004	Function	"def clean_template_output(output):
    output = '\n'.join(line.strip() for line in output.strip().splitlines())
    output = re.sub('\n{3,}', '\n\n', output)
    return output
"
httpie|httpie|generate.py|005	Function	"def load_database() -> Database:
    return yaml.safe_load(DB_FILE.read_text(encoding='utf-8'))
"
httpie|httpie|generate.py|006	Function	"def load_doc_file() -> str:
    return DOC_FILE.read_text(encoding='utf-8')
"
httpie|httpie|generate.py|007	Function	"def main() -> int:
    content = generate_documentation()
    save_doc_file(content)
    return 0
"
httpie|httpie|build.py|000	Function	"def build_binaries() -> Iterator[Tuple[str, Path]]:
    for target_script, extra_args in TARGET_SCRIPTS.items():
        subprocess.check_call(
            [
                'pyinstaller',
                '--onefile',
                '--noupx',
                '-p',
                HTTPIE_DIR,
                '--additional-hooks-dir',
                HOOKS_DIR,
                *extra_args,
                target_script,
            ]
        )
"
httpie|httpie|build.py|001	Function	"def build_packages(http_binary: Path, httpie_binary: Path) -> None:
    import httpie
"
httpie|httpie|build.py|002	Function	"def main():
    binaries = dict(build_binaries())
    build_packages(binaries['http_cli'], binaries['httpie_cli'])
"
huggingface|pytorch-image-models|avg_checkpoints.py|000	Function	"def checkpoint_metric(checkpoint_path):
    if not checkpoint_path or not os.path.isfile(checkpoint_path):
        return {}
    print(""=> Extracting metric from checkpoint '{}'"".format(checkpoint_path))
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    metric = None
    if 'metric' in checkpoint:
        metric = checkpoint['metric']
    elif 'metrics' in checkpoint and 'metric_name' in checkpoint:
        metrics = checkpoint['metrics']
        print(metrics)
        metric = metrics[checkpoint['metric_name']]
    return metric
"
huggingface|pytorch-image-models|avg_checkpoints.py|001	Function	"def main():
    args = parser.parse_args()
    # by default use the EMA weights (if present)
    args.use_ema = not args.no_use_ema
    # by default sort by checkpoint metric (if present) and avg top n checkpoints
    args.sort = not args.no_sort
"
huggingface|pytorch-image-models|benchmark.py|000	Class	"class BenchmarkRunner:
    def __init__(
            self,
            model_name,
            detail=False,
            device='cuda',
            torchscript=False,
            torchcompile=None,
            aot_autograd=False,
            precision='float32',
            fuser='',
            num_warm_iter=10,
            num_bench_iter=50,
            use_train_size=False,
            **kwargs
    ):
        self.model_name = model_name
        self.detail = detail
        self.device = device
        self.amp_dtype, self.model_dtype, self.data_dtype = resolve_precision(precision)
        self.channels_last = kwargs.pop('channels_last', False)
        if self.amp_dtype is not None:
            self.amp_autocast = partial(torch.cuda.amp.autocast, dtype=self.amp_dtype)
        else:
            self.amp_autocast = suppress
"
huggingface|pytorch-image-models|benchmark.py|001	Class	"class InferenceBenchmarkRunner(BenchmarkRunner):
"
huggingface|pytorch-image-models|benchmark.py|002	Class	"class TrainBenchmarkRunner(BenchmarkRunner):
"
huggingface|pytorch-image-models|benchmark.py|003	Class	"class ProfileRunner(BenchmarkRunner):
"
huggingface|pytorch-image-models|benchmark.py|004	Function	"def timestamp(sync=False):
    return time.perf_counter()
"
huggingface|pytorch-image-models|benchmark.py|005	Function	"def cuda_timestamp(sync=False, device=None):
    if sync:
        torch.cuda.synchronize(device=device)
    return time.perf_counter()
"
huggingface|pytorch-image-models|benchmark.py|006	Function	"def count_params(model: nn.Module):
    return sum([m.numel() for m in model.parameters()])
"
huggingface|pytorch-image-models|benchmark.py|007	Function	"def resolve_precision(precision: str):
    assert precision in ('amp', 'amp_bfloat16', 'float16', 'bfloat16', 'float32')
    amp_dtype = None  # amp disabled
    model_dtype = torch.float32
    data_dtype = torch.float32
    if precision == 'amp':
        amp_dtype = torch.float16
    elif precision == 'amp_bfloat16':
        amp_dtype = torch.bfloat16
    elif precision == 'float16':
        model_dtype = torch.float16
        data_dtype = torch.float16
    elif precision == 'bfloat16':
        model_dtype = torch.bfloat16
        data_dtype = torch.bfloat16
    return amp_dtype, model_dtype, data_dtype
"
huggingface|pytorch-image-models|benchmark.py|008	Function	"def profile_deepspeed(model, input_size=(3, 224, 224), batch_size=1, detailed=False):
    _, macs, _ = get_model_profile(
        model=model,
        input_shape=(batch_size,) + input_size,  # input shape/resolution
        print_profile=detailed,  # prints the model graph with the measured profile attached to each module
        detailed=detailed,  # print the detailed profile
        warm_up=10,  # the number of warm-ups before measuring the time of each module
        as_string=False,  # print raw numbers (e.g. 1000) or as human-readable strings (e.g. 1k)
        output_file=None,  # path to the output file. If None, the profiler prints to stdout.
        ignore_modules=None)  # the list of modules to ignore in the profiling
    return macs, 0  # no activation count in DS
"
huggingface|pytorch-image-models|benchmark.py|009	Function	"def profile_fvcore(model, input_size=(3, 224, 224), batch_size=1, detailed=False, force_cpu=False):
    if force_cpu:
        model = model.to('cpu')
    device, dtype = next(model.parameters()).device, next(model.parameters()).dtype
    example_input = torch.ones((batch_size,) + input_size, device=device, dtype=dtype)
    fca = FlopCountAnalysis(model, example_input)
    aca = ActivationCountAnalysis(model, example_input)
    if detailed:
        fcs = flop_count_str(fca)
        print(fcs)
    return fca.total(), aca.total()
"
huggingface|pytorch-image-models|benchmark.py|010	Function	"    def __init__(
            self,
            model_name,
            detail=False,
            device='cuda',
            torchscript=False,
            torchcompile=None,
            aot_autograd=False,
            precision='float32',
            fuser='',
            num_warm_iter=10,
            num_bench_iter=50,
            use_train_size=False,
            **kwargs
    ):
        self.model_name = model_name
        self.detail = detail
        self.device = device
        self.amp_dtype, self.model_dtype, self.data_dtype = resolve_precision(precision)
        self.channels_last = kwargs.pop('channels_last', False)
        if self.amp_dtype is not None:
            self.amp_autocast = partial(torch.cuda.amp.autocast, dtype=self.amp_dtype)
        else:
            self.amp_autocast = suppress
"
huggingface|pytorch-image-models|benchmark.py|011	Function	"    def _init_input(self):
        self.example_inputs = torch.randn(
            (self.batch_size,) + self.input_size, device=self.device, dtype=self.data_dtype)
        if self.channels_last:
            self.example_inputs = self.example_inputs.contiguous(memory_format=torch.channels_last)
"
huggingface|pytorch-image-models|benchmark.py|012	Function	"    def __init__(
            self,
            model_name,
            device='cuda',
            torchscript=False,
            **kwargs
    ):
        super().__init__(model_name=model_name, device=device, torchscript=torchscript, **kwargs)
        self.model.eval()
"
huggingface|pytorch-image-models|benchmark.py|013	Function	"    def run(self):
        def _step():
            t_step_start = self.time_fn()
            with self.amp_autocast():
                output = self.model(self.example_inputs)
            t_step_end = self.time_fn(True)
            return t_step_end - t_step_start
"
huggingface|pytorch-image-models|benchmark.py|014	Function	"        def _step():
            t_step_start = self.time_fn()
            with self.amp_autocast():
                output = self.model(self.example_inputs)
            t_step_end = self.time_fn(True)
            return t_step_end - t_step_start
"
huggingface|pytorch-image-models|benchmark.py|015	Function	"    def __init__(
            self,
            model_name,
            device='cuda',
            torchscript=False,
            **kwargs
    ):
        super().__init__(model_name=model_name, device=device, torchscript=torchscript, **kwargs)
        self.model.train()
"
huggingface|pytorch-image-models|benchmark.py|016	Function	"    def _gen_target(self, batch_size):
        return torch.empty(
            (batch_size,) + self.target_shape, device=self.device, dtype=torch.long).random_(self.num_classes)
"
huggingface|pytorch-image-models|benchmark.py|017	Function	"    def run(self):
        def _step(detail=False):
            self.optimizer.zero_grad()  # can this be ignored?
            t_start = self.time_fn()
            t_fwd_end = t_start
            t_bwd_end = t_start
            with self.amp_autocast():
                output = self.model(self.example_inputs)
                if isinstance(output, tuple):
                    output = output[0]
                if detail:
                    t_fwd_end = self.time_fn(True)
                target = self._gen_target(output.shape[0])
                self.loss(output, target).backward()
                if detail:
                    t_bwd_end = self.time_fn(True)
            self.optimizer.step()
            t_end = self.time_fn(True)
            if detail:
                delta_fwd = t_fwd_end - t_start
                delta_bwd = t_bwd_end - t_fwd_end
                delta_opt = t_end - t_bwd_end
                return delta_fwd, delta_bwd, delta_opt
            else:
                delta_step = t_end - t_start
                return delta_step
"
huggingface|pytorch-image-models|benchmark.py|018	Function	"        def _step(detail=False):
            self.optimizer.zero_grad()  # can this be ignored?
            t_start = self.time_fn()
            t_fwd_end = t_start
            t_bwd_end = t_start
            with self.amp_autocast():
                output = self.model(self.example_inputs)
                if isinstance(output, tuple):
                    output = output[0]
                if detail:
                    t_fwd_end = self.time_fn(True)
                target = self._gen_target(output.shape[0])
                self.loss(output, target).backward()
                if detail:
                    t_bwd_end = self.time_fn(True)
            self.optimizer.step()
            t_end = self.time_fn(True)
            if detail:
                delta_fwd = t_fwd_end - t_start
                delta_bwd = t_bwd_end - t_fwd_end
                delta_opt = t_end - t_bwd_end
                return delta_fwd, delta_bwd, delta_opt
            else:
                delta_step = t_end - t_start
                return delta_step
"
huggingface|pytorch-image-models|benchmark.py|019	Function	"    def __init__(self, model_name, device='cuda', profiler='', **kwargs):
        super().__init__(model_name=model_name, device=device, **kwargs)
        if not profiler:
            if has_deepspeed_profiling:
                profiler = 'deepspeed'
            elif has_fvcore_profiling:
                profiler = 'fvcore'
        assert profiler, ""One of deepspeed or fvcore needs to be installed for profiling to work.""
        self.profiler = profiler
        self.model.eval()
"
huggingface|pytorch-image-models|benchmark.py|020	Function	"    def run(self):
        _logger.info(
            f'Running profiler on {self.model_name} w/ '
            f'input size {self.input_size} and batch size {self.batch_size}.')
"
huggingface|pytorch-image-models|benchmark.py|021	Function	"def _try_run(
        model_name,
        bench_fn,
        bench_kwargs,
        initial_batch_size,
        no_batch_size_retry=False
):
    batch_size = initial_batch_size
    results = dict()
    error_str = 'Unknown'
    while batch_size:
        try:
            torch.cuda.empty_cache()
            bench = bench_fn(model_name=model_name, batch_size=batch_size, **bench_kwargs)
            results = bench.run()
            return results
        except RuntimeError as e:
            error_str = str(e)
            _logger.error(f'""{error_str}"" while running benchmark.')
            if not check_batch_size_retry(error_str):
                _logger.error(f'Unrecoverable error encountered while benchmarking {model_name}, skipping.')
                break
            if no_batch_size_retry:
                break
        batch_size = decay_batch_step(batch_size)
        _logger.warning(f'Reducing batch size to {batch_size} for retry.')
    results['error'] = error_str
    return results
"
huggingface|pytorch-image-models|benchmark.py|022	Function	"def benchmark(args):
    if args.amp:
        _logger.warning(""Overriding precision to 'amp' since --amp flag set."")
        args.precision = 'amp' if args.amp_dtype == 'float16' else '_'.join(['amp', args.amp_dtype])
    _logger.info(f'Benchmarking in {args.precision} precision. '
                 f'{""NHWC"" if args.channels_last else ""NCHW""} layout. '
                 f'torchscript {""enabled"" if args.torchscript else ""disabled""}')
"
huggingface|pytorch-image-models|benchmark.py|023	Function	"def main():
    setup_default_logging()
    args = parser.parse_args()
    model_cfgs = []
    model_names = []
"
huggingface|pytorch-image-models|benchmark.py|024	Function	"def write_results(results_file, results, format='csv'):
    with open(results_file, mode='w') as cf:
        if format == 'json':
            json.dump(results, cf, indent=4)
        else:
            if not isinstance(results, (list, tuple)):
                results = [results]
            if not results:
                return
            dw = csv.DictWriter(cf, fieldnames=results[0].keys())
            dw.writeheader()
            for r in results:
                dw.writerow(r)
            cf.flush()
"
huggingface|pytorch-image-models|bulk_runner.py|000	Function	"def cmd_from_args(args) -> Tuple[Union[Callable, str], List[str]]:
    # If ``args`` not passed, defaults to ``sys.argv[:1]``
    with_python = not args.no_python
    cmd: Union[Callable, str]
    cmd_args = []
    if with_python:
        cmd = os.getenv(""PYTHON_EXEC"", sys.executable)
        cmd_args.append(""-u"")
        if args.module:
            cmd_args.append(""-m"")
        cmd_args.append(args.script)
    else:
        if args.module:
            raise ValueError(
                ""Don't use both the '--no_python' flag""
                "" and the '--module' flag at the same time.""
            )
        cmd = args.script
    cmd_args.extend(args.script_args)
"
huggingface|pytorch-image-models|bulk_runner.py|001	Function	"def main():
    args = parser.parse_args()
    cmd, cmd_args = cmd_from_args(args)
"
huggingface|pytorch-image-models|bulk_runner.py|002	Function	"def write_results(results_file, results):
    with open(results_file, mode='w') as cf:
        dw = csv.DictWriter(cf, fieldnames=results[0].keys())
        dw.writeheader()
        for r in results:
            dw.writerow(r)
        cf.flush()
"
huggingface|pytorch-image-models|clean_checkpoint.py|000	Function	"def main():
    args = parser.parse_args()
"
huggingface|pytorch-image-models|clean_checkpoint.py|001	Function	"def clean_checkpoint(
        checkpoint,
        output,
        use_ema=True,
        no_hash=False,
        clean_aux_bn=False,
        safe_serialization: bool=False,
):
    # Load an existing checkpoint to CPU, strip everything but the state_dict and re-save
    if checkpoint and os.path.isfile(checkpoint):
        print(""=> Loading checkpoint '{}'"".format(checkpoint))
        state_dict = load_state_dict(checkpoint, use_ema=use_ema)
        new_state_dict = {}
        for k, v in state_dict.items():
            if clean_aux_bn and 'aux_bn' in k:
                # If all aux_bn keys are removed, the SplitBN layers will end up as normal and
                # load with the unmodified model using BatchNorm2d.
                continue
            name = k[7:] if k.startswith('module.') else k
            new_state_dict[name] = v
        print(""=> Loaded state_dict from '{}'"".format(checkpoint))
"
facebookresearch|detectron2|setup.py|000	Function	"def get_version():
    init_py_path = path.join(path.abspath(path.dirname(__file__)), ""detectron2"", ""__init__.py"")
    init_py = open(init_py_path, ""r"").readlines()
    version_line = [l.strip() for l in init_py if l.startswith(""__version__"")][0]
    version = version_line.split(""="")[-1].strip().strip(""'\"""")
"
facebookresearch|detectron2|setup.py|001	Function	"def get_extensions():
    this_dir = path.dirname(path.abspath(__file__))
    extensions_dir = path.join(this_dir, ""detectron2"", ""layers"", ""csrc"")
"
facebookresearch|detectron2|setup.py|002	Function	"def get_model_zoo_configs() -> List[str]:
    """"""
    Return a list of configs to include in package for model zoo. Copy over these configs inside
    detectron2/model_zoo.
    """"""
"
pypa|pipenv|conf.py|000	Function	"def setup(app):
    app.add_css_file(""custom.css"")
"
pypa|pipenv|get-pipenv.py|000	Function	"# def determine_pip_install_arguments():
#     implicit_pip = True
# +    implicit_setuptools = False
# -    implicit_setuptools = True
#     implicit_wheel = True
#
#     # Check if the user has requested us not to install setuptools
# @@ -87,8 +60,6 @@
#
#     # We only want to implicitly install setuptools and wheel if they don't
#     # already exist on the target platform.
# +    # No need for doing this, since pipenv already has setuptools as
# +    # a dependency in setup.py
#     if implicit_setuptools:
#         try:
#             import setuptools  # noqa
# @@ -109,8 +80,6 @@
#         args += [""setuptools""]
#     if implicit_wheel:
#         args += [""wheel""]
# +
# +    args += [""pipenv""]
#
#     return [""install"", ""--upgrade"", ""--force-reinstall""] + args
"
pypa|pipenv|get-pipenv.py|001	Function	"def determine_pip_install_arguments():
    implicit_pip = True
    implicit_setuptools = False
    implicit_wheel = True
"
pypa|pipenv|get-pipenv.py|002	Function	"def monkeypatch_for_cert(tmpdir):
    """"""Patches `pip install` to provide default certificate with the lowest priority.
"
pypa|pipenv|get-pipenv.py|003	Function	"    def cert_parse_args(self, args):
        if not self.parser.get_default_values().cert:
            # There are no user provided cert -- force use of bundled cert
            self.parser.defaults[""cert""] = cert_path  # calculated above
        return install_parse_args(self, args)
"
pypa|pipenv|get-pipenv.py|004	Function	"def bootstrap(tmpdir):
    monkeypatch_for_cert(tmpdir)
"
pypa|pipenv|get-pipenv.py|005	Function	"def main():
    tmpdir = None
    try:
        # Create a temporary working directory
        tmpdir = tempfile.mkdtemp()
"
google|jax|setup.py|000	Function	"def generate_proto(source):
  if not protoc or not os.path.exists(source):
    return
  protoc_command = [protoc, '-I.', '--python_out=.', source]
  if subprocess.call(protoc_command) != 0:
    sys.exit(-1)
"
google|jax|parse_logs.py|000	Class	"class DefaultReport:
  outcome : str = ""none""
"
google|jax|parse_logs.py|001	Function	"def parse_line(line):
  # TODO(jakevdp): should we parse other report types?
  parsed = json.loads(line)
  if parsed.get(""$report_type"") == ""TestReport"":
    return TestReport._from_json(parsed)
  return DefaultReport()
"
google|jax|parse_logs.py|002	Function	"def main(logfile, outfile):
  logging.info(""Parsing %s"", logfile)
  try:
    with open(logfile, 'r') as f:
      reports = (parse_line(line) for line in f)
      failures = (r for r in reports if r.outcome == ""failed"")
      summary = ""\n"".join(f""{f.nodeid}: {f.longrepr.chain[0][1].message}""
                          for f in failures)
    logging.info(""Parsed summary:\n%s"", summary)
  except Exception:
    err_info = traceback.format_exc()
    logging.info(""Parsing failed:\n%s"", err_info)
    summary = f""Log parsing failed; traceback:\n\n{err_info}""
  logging.info(""Writing result to %s"", outfile)
  with open(outfile, 'w') as f:
    f.write(MSG_FORMAT.format(summary=summary))
"
google|jax|extract_e2e_tests_metrics.py|000	Function	"def main(logfile: str, outmd: str, outjson: str, name: str):
    print(f""Extracting content of {logfile}"")
    print(f""and writing to {outmd} and {outjson}"")
"
google|jax|oci_cluster_manager.py|000	Function	"def get_regions():
    return requests.post(_API_URL, json={'name':'list_regions'},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['regions']
"
google|jax|oci_cluster_manager.py|001	Function	"def find_existing_cluster():
    return requests.post(_API_URL, json={'name':'find_cluster'},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['region']
"
google|jax|oci_cluster_manager.py|002	Function	"def get_cluster_ip(region):
    return requests.post(_API_URL, json={'name':'get_cluster_ip', 'region':region},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['cluster_ip']
"
google|jax|oci_cluster_manager.py|003	Function	"def get_cluster_username(region):
    return requests.post(_API_URL, json={'name':'get_cluster_username', 'region':region},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['cluster_username']
"
google|jax|oci_cluster_manager.py|004	Function	"def create_cluster(region):
    logging.debug(requests.post(_API_URL, json={'name':'create_cluster', 'region':region},
                                auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS))
"
google|jax|oci_cluster_manager.py|005	Function	"def add_pubkey(region, pubkey):
    logging.debug(requests.post(_API_URL, json={'name':'add_pubkey', 'region':region, 'pubkey':pubkey},
                                auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS))
"
google|jax|oci_cluster_manager.py|006	Function	"def get_cluster_hostkeys(region):
    return requests.post(_API_URL, json={'name':'get_cluster_hostkeys', 'region':region},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['cluster_hostkeys']
"
google|jax|oci_cluster_manager.py|007	Function	"def get_status(region):
    return requests.post(_API_URL, json={'name':'get_status', 'region': region},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['status']
"
google|jax|oci_cluster_manager.py|008	Function	"def destroy_all_clusters():
    logging.debug(requests.post(_API_URL, json={'name':'destroy_all_clusters'},
                                auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS))
"
google|jax|oci_cluster_manager.py|009	Function	"def main():
"
google|jax|api_benchmark.py|000	Class	"class AnEnum(enum.IntEnum):
  A = 123
  B = 456
"
google|jax|api_benchmark.py|001	Function	"def required_devices(num_devices_required):
  """"""Helper to skip benchmarks that require more devices.""""""
  def helper1(f):
    @functools.wraps(f)
    def helper2(state):
      if jax.device_count() < num_devices_required:
        state.skip_with_error(f""requires {num_devices_required} devices"")
        return
      return f(state)
    return helper2
  return helper1
"
google|jax|api_benchmark.py|002	Function	"  def helper1(f):
    @functools.wraps(f)
    def helper2(state):
      if jax.device_count() < num_devices_required:
        state.skip_with_error(f""requires {num_devices_required} devices"")
        return
      return f(state)
    return helper2
  return helper1
"
google|jax|api_benchmark.py|003	Function	"    def helper2(state):
      if jax.device_count() < num_devices_required:
        state.skip_with_error(f""requires {num_devices_required} devices"")
        return
      return f(state)
    return helper2
"
google|jax|api_benchmark.py|004	Function	"def create_mesh(shape, axis_names, state):
  size = np.prod(shape)
  if len(jax.devices()) < size:
    state.skip_with_error(f""Requires {size} devices"")
    return None
  devices = sorted(jax.devices(), key=lambda d: d.id)
  mesh_devices = np.array(devices[:size]).reshape(shape)
  global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)
  return global_mesh
"
google|jax|api_benchmark.py|005	Function	"def swap(a, b):
  return b, a
"
google|jax|api_benchmark.py|006	Function	"def eager_unary_dispatch(state):
  a = jax.device_put(1)
  lax.neg(a)
  while state:
    lax.neg(a)
"
google|jax|api_benchmark.py|007	Function	"def eager_unary(state):
  a = jax.device_put(1)
  lax.neg(a).block_until_ready()
  while state:
    lax.neg(a).block_until_ready()
"
google|jax|api_benchmark.py|008	Function	"def eager_binary_dispatch(state):
  a = jax.device_put(1)
  b = jax.device_put(2)
  lax.add(a, b)
  while state:
    lax.add(a, b)
"
google|jax|api_benchmark.py|009	Function	"def eager_binary(state):
  a = jax.device_put(1)
  b = jax.device_put(2)
  lax.add(a, b).block_until_ready()
  while state:
    lax.add(a, b).block_until_ready()
"
google|jax|api_benchmark.py|010	Function	"def jit_trivial_dispatch(state):
  """"""Benchmarks only the duration for jitted_f to return the future.""""""
  f = jax.jit(swap)
  a, b = f(1, 2)
  x = f(a, b)
  while state:
    x = f(a, b)
  x[0].block_until_ready()
"
google|jax|api_benchmark.py|011	Function	"def jit_trivial(state):
  f = jax.jit(swap)
  a, b = f(1, 2)
  f(a, b)
"
google|jax|api_benchmark.py|012	Function	"def jit_simple_dispatch(state):
  a = jax.device_put(1)
  b = jax.device_put(2)
  f = jax.jit(operator.add)
  f(a, b)
"
google|jax|api_benchmark.py|013	Function	"def jit_simple(state):
  a = jax.device_put(1)
  b = jax.device_put(2)
  f = jax.jit(operator.add)
  f(a, b)
"
google|jax|api_benchmark.py|014	Function	"def jit_simple_dispatch_array(state):
  a = jax.device_put(1)
  b = jax.device_put(2)
  f = jax.jit(operator.add)
  f(a, b)
"
google|jax|api_benchmark.py|015	Function	"def jit_simple_array(state):
  a = jax.device_put(1)
  b = jax.device_put(2)
  f = jax.jit(operator.add)
  f(a, b)
"
google|jax|api_benchmark.py|016	Function	"def jit_small_matmul(state):
  x = np.random.uniform(size=(2, 2)).astype(np.float32)
  x = jax.device_put(x)
"
google|jax|api_benchmark.py|017	Function	"def jit_big_matmul(state):
  x = np.random.uniform(size=(100, 100)).astype(np.float32)
  x = jax.device_put(x)
"
google|jax|api_benchmark.py|018	Function	"def jit_simple_many_args_dispatch(state):
  args = [jax.device_put(i) for i in range(state.range(0))]
  f = jax.jit(lambda xs: functools.reduce(operator.add, xs))
  x = f(args)
  x.block_until_ready()
"
google|jax|api_benchmark.py|019	Function	"def jit_simple_many_args(state):
  args = [jax.device_put(i) for i in range(state.range(0))]
  f = jax.jit(lambda xs: functools.reduce(operator.add, xs))
  f(args).block_until_ready()
"
google|jax|api_benchmark.py|020	Function	"def jit_simple_pruned_args_dispatch(n, state):
  args = [jax.device_put(i) for i in range(n)]
  f = jax.jit(lambda *xs: xs[0] + 1)
  x = f(*args)
  x.block_until_ready()
"
google|jax|api_benchmark.py|021	Function	"def jit_simple_pruned_args(n, state):
  args = [jax.device_put(i) for i in range(n)]
  f = jax.jit(lambda *xs: xs[0] + 1)
  x = f(*args)
  x.block_until_ready()
"
google|jax|api_benchmark.py|022	Function	"def jit_dispatch_without_transfer(state):
  # We pick up a realistic input. 224 is usual for classification and 128 a
  # TPU-friendly batch-size.
  imgs = np.ones((128, 224, 224), np.float32)
  imgs = jax.device_put(imgs)
"
google|jax|api_benchmark.py|023	Function	"def jit_dispatch_with_transfer(state):
  imgs = np.ones((128, 224, 224), np.float32)
"
google|jax|api_benchmark.py|024	Function	"def pmap_trivial_2_devices(state):
  f = jax.pmap(swap)
  a, b = f(jnp.array([1, 2]), jnp.array([3, 4]))
"
google|jax|api_benchmark.py|025	Function	"def pmap_trivial_dispatch_8_devices(state):
  f = jax.pmap(swap)
  a, b = f(jnp.array([1, 2, 3, 4, 5, 6, 7, 8]),
           jnp.array([2, 3, 4, 5, 6, 7, 8, 9]))
"
google|jax|api_benchmark.py|026	Function	"def pmap_trivial_8_devices(state):
  f = jax.pmap(swap)
  a, b = f(jnp.array([1, 2, 3, 4, 5, 6, 7, 8]),
           jnp.array([2, 3, 4, 5, 6, 7, 8, 9]))
"
google|jax|api_benchmark.py|027	Function	"def pmap_simple_2_devices(state):
  f = jax.pmap(lambda a, b: (a + b, a - b))
  a, b = f(jnp.array([1, 2]), jnp.array([3, 4]))
"
google|jax|api_benchmark.py|028	Function	"def pmap_simple_dispatch_8_devices(state):
  f = jax.pmap(lambda a, b: (a + b, a - b))
  a, b = f(jnp.array([1, 2, 3, 4, 5, 6, 7, 8]),
           jnp.array([2, 3, 4, 5, 6, 7, 8, 9]))
"
google|jax|api_benchmark.py|029	Function	"def pmap_simple_8_devices(state):
  f = jax.pmap(lambda a, b: (a + b, a - b))
  a, b = f(jnp.array([1, 2, 3, 4, 5, 6, 7, 8]),
           jnp.array([2, 3, 4, 5, 6, 7, 8, 9]))
"
google|jax|api_benchmark.py|030	Function	"def pmap_simple_dispatch_8_devices_100_args(state):
  f = jax.pmap(lambda *args: args[1:] + (args[0] + 1,))
  args = []
  for i in range(100):
    args.append(jnp.array(list(range(i, i+8))))
"
google|jax|api_benchmark.py|031	Function	"def pmap_simple_8_devices_100_args(state):
  f = jax.pmap(lambda *args: args[1:] + (args[0] + 1,))
  args = []
  for i in range(100):
    args.append(jnp.array(list(range(i, i+8))))
"
google|jax|api_benchmark.py|032	Function	"def _run_sda_index_bench(state, num_devices):
  x = jax.pmap(jnp.sin)(jnp.arange(num_devices))
  jax.device_get(x)
  while state:
    for i in range(num_devices):
      _ = x[i]
"
google|jax|api_benchmark.py|033	Function	"def sda_index_1(state):
  _run_sda_index_bench(state, 1)
"
google|jax|api_benchmark.py|034	Function	"def sda_index_2(state):
  _run_sda_index_bench(state, 2)
"
google|jax|api_benchmark.py|035	Function	"def sda_index_8(state):
  _run_sda_index_bench(state, 8)
"
google|jax|api_benchmark.py|036	Function	"def _sparse_bcoo_fromdense(state, jit: bool = False, compile: bool = False):
  shape = (2000, 2000)
  nse = 10000
  size = np.prod(shape)
  rng = np.random.RandomState(1701)
  data = rng.randn(nse)
  indices = np.unravel_index(
      rng.choice(size, size=nse, replace=False), shape=shape)
  mat = jnp.zeros(shape).at[indices].set(data)
"
google|jax|api_benchmark.py|037	Function	"def sparse_bcoo_fromdense(state):
  return _sparse_bcoo_fromdense(state)
"
google|jax|api_benchmark.py|038	Function	"def sparse_bcoo_fromdense_jit(state):
  return _sparse_bcoo_fromdense(state, jit=True)
"
google|jax|api_benchmark.py|039	Function	"def sparse_bcoo_fromdense_compile(state):
  return _sparse_bcoo_fromdense(state, compile=True)
"
google|jax|api_benchmark.py|040	Function	"def _sparse_bcoo_todense(state, jit: bool = False, compile: bool = False):
  shape = (2000, 2000)
  nse = 10000
  size = np.prod(shape)
  rng = np.random.RandomState(1701)
  data = rng.randn(nse)
  indices = np.unravel_index(
      rng.choice(size, size=nse, replace=False), shape=shape)
  mat = sparse.BCOO((jnp.array(data), jnp.column_stack(indices)), shape=shape)
"
google|jax|api_benchmark.py|041	Function	"def sparse_bcoo_todense(state):
  return _sparse_bcoo_todense(state)
"
google|jax|api_benchmark.py|042	Function	"def sparse_bcoo_todense_jit(state):
  return _sparse_bcoo_todense(state, jit=True)
"
google|jax|api_benchmark.py|043	Function	"def sparse_bcoo_todense_compile(state):
  return _sparse_bcoo_todense(state, compile=True)
"
google|jax|api_benchmark.py|044	Function	"def _sparse_bcoo_matvec(state, jit: bool = False, compile: bool = False):
  shape = (2000, 2000)
  nse = 10000
  key = jax.random.PRNGKey(1701)
  mat = sparse.random_bcoo(key, nse=nse, shape=shape, dtype=jnp.float32,
                           indices_dtype=jnp.int32, sorted_indices=True)
  vec = jax.random.uniform(key, shape=(shape[1],), dtype=jnp.float32)
"
google|jax|api_benchmark.py|045	Function	"def sparse_bcoo_matvec(state):
  return _sparse_bcoo_matvec(state)
"
google|jax|api_benchmark.py|046	Function	"def sparse_bcoo_matvec_jit(state):
  return _sparse_bcoo_matvec(state, jit=True)
"
google|jax|api_benchmark.py|047	Function	"def sparse_bcoo_matvec_compile(state):
  return _sparse_bcoo_matvec(state, compile=True)
"
google|jax|api_benchmark.py|048	Function	"def bench_shaped_abstractify(state):
  device, *_ = jax.devices()
  args = [jax.device_put_replicated(1, [device])] * 1000
  while state:
    _ = [shaped_abstractify(x) for x in args]
"
google|jax|api_benchmark.py|049	Function	"def _run_benchmark_for_xla_abstractify(arg, state):
  while state:
    xla.abstractify(arg)
"
google|jax|api_benchmark.py|050	Function	"def bench_xla_abstractify():
  _abstractify_args = [
      (3, 'scalar_int'),
      (3.5, 'scalar_float'),
      (np.int32(3), 'scalar_numpy_int32'),
      (np.uint32(7), 'scalar_numpy_uint32'),
      (np.random.randn(3, 4, 5, 6), 'numpy_random'),
      (np.arange(100, dtype=np.float32), 'numpy_arange_100_float32'),
      (AnEnum.B, 'enum'),
  ]
  benchmarks = []
  for a, name in _abstractify_args:
    benchmarks.extend([
        google_benchmark.register(
            partial(_run_benchmark_for_xla_abstractify, a),
            name=f'bench_xla_abstractify_{name}'),
    ])
bench_xla_abstractify()
"
google|jax|api_benchmark.py|051	Function	"def bench_are_op_shardings_equal(state):
  op1 = xc.OpSharding()
  op1.type = xc.OpSharding.Type.OTHER
  op1.tile_assignment_dimensions = [4, 192, 16]
  op1.tile_assignment_devices = list(range(12288))
"
google|jax|api_benchmark.py|052	Function	"def bench_pjit_check_aval_sharding(state):
  mesh = create_mesh((4, 2), ('x', 'y'), state)
  if mesh is None:
    return
  s = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec('x', 'y'))
  aval = jax.core.ShapedArray((8, 2), np.int32)
"
google|jax|api_benchmark.py|053	Function	"def bench_remat_eager_retracing_overheads(state):
  def double_compose(f):
    return lambda x: f(f(x))
"
google|jax|api_benchmark.py|054	Function	"  def double_compose(f):
    return lambda x: f(f(x))
"
google|jax|api_benchmark.py|055	Function	"def bench_remat_eager_retracing_overheads_static_argnums(state):
  def double_compose(f):
    return lambda x, y: f(f(x, y), y)
"
google|jax|api_benchmark.py|056	Function	"  def double_compose(f):
    return lambda x, y: f(f(x, y), y)
"
google|jax|api_benchmark.py|057	Function	"def bench_slicing_compilation(state):
  x = jnp.arange(3)
  while state:
    jax.jit(lambda x: (x[0], x[1], x[2])).lower(x).compile()
"
google|jax|api_benchmark.py|058	Function	"def bench_slicing_compilation2(state):
  x = jnp.arange(3)
  while state:
    jax.jit(lambda x: (x[:1], x[1:2], x[2:3])).lower(x).compile()
"
google|jax|api_benchmark.py|059	Function	"def bench_repeated_static_indexing(state):
  x = jnp.arange(500)
  while state:
    jax.block_until_ready([x[i] for i in range(500)])
"
google|jax|api_benchmark.py|060	Function	"def bench_repeated_static_slicing(state):
  x = jnp.arange(1000)
  while state:
    jax.block_until_ready([x[i:i + 2] for i in range(0, 1000, 2)])
"
google|jax|api_benchmark.py|061	Function	"def pjit_simple_benchmark(state, num_devices, num_args, cpp_jit, use_aot=False):
  spec = jax.sharding.PartitionSpec('x')
  mesh = create_mesh((num_devices,), ('x',), state)
  if mesh is None:
    return
  s = jax.sharding.NamedSharding(mesh, spec)
  inp_data = np.arange(num_devices).astype(np.float32)
  x = array.make_array_from_callback(inp_data.shape, s, lambda idx: inp_data[idx])
"
google|jax|api_benchmark.py|062	Function	"def pjit_simple_1_device(state):
  pjit_simple_benchmark(
      state, num_devices=1, num_args=state.range(0), cpp_jit=state.range(1))
"
google|jax|api_benchmark.py|063	Function	"def pjit_simple_4_device(state):
  pjit_simple_benchmark(
      state, num_devices=4, num_args=state.range(0), cpp_jit=state.range(1))
"
google|jax|api_benchmark.py|064	Function	"def pjit_simple_4000_device(state):
  pjit_simple_benchmark(
      state, num_devices=4000, num_args=state.range(0), cpp_jit=state.range(1))
"
google|jax|api_benchmark.py|065	Function	"def pjit_aot_1_device(state):
  pjit_simple_benchmark(
      state,
      num_devices=1,
      num_args=state.range(0),
      cpp_jit=state.range(1),
      use_aot=True)
"
google|jax|api_benchmark.py|066	Function	"def pjit_aot_4_device(state):
  pjit_simple_benchmark(
      state,
      num_devices=4,
      num_args=state.range(0),
      cpp_jit=state.range(1),
      use_aot=True)
"
google|jax|api_benchmark.py|067	Function	"def pjit_aot_4000_device(state):
  pjit_simple_benchmark(
      state,
      num_devices=4000,
      num_args=state.range(0),
      cpp_jit=state.range(1),
      use_aot=True)
"
google|jax|api_benchmark.py|068	Function	"def host_local_array_to_global_array(state):
  global_mesh = create_mesh((4, 2), ('x', 'y'), state)
  input_shape = (8, 2)
  input_data = np.arange(np.prod(input_shape)).reshape(input_shape)
  in_pspec = jax.sharding.PartitionSpec('x', 'y')
"
google|jax|api_benchmark.py|069	Function	"def device_put(state):
  x = np.array(1, np.int32)
  while state:
    _ = jax.device_put(x).block_until_ready()
"
google|jax|api_benchmark.py|070	Function	"def device_put_sharded(state):
  arr_inp = [np.array(i) for i in range(jax.device_count())]
  dev = jax.devices()
"
google|jax|api_benchmark.py|071	Function	"def device_get_8_devices(state):
  mesh = jax.sharding.Mesh(
      np.array(jax.devices()[:8]).reshape((4, 2)), ('x', 'y')
  )
  sharding = jax.sharding.NamedSharding(
      mesh, jax.sharding.PartitionSpec('x', 'y')
  )
  inp = jax.device_put(np.zeros((8, 4), dtype=np.float32), sharding)
"
google|jax|api_benchmark.py|072	Function	"  def fn(x):
    y = x + x
    return [y for _ in range(50)]
"
google|jax|api_benchmark.py|073	Function	"def np_asarray_8_devices(state):
  mesh = jax.sharding.Mesh(
      np.array(jax.devices()[:8]).reshape((4, 2)), ('x', 'y')
  )
  sharding = jax.sharding.NamedSharding(
      mesh, jax.sharding.PartitionSpec('x', 'y')
  )
  inp = jax.device_put(np.zeros((8, 4), dtype=np.float32), sharding)
"
google|jax|api_benchmark.py|074	Function	"  def fn(x):
    y = x + x
    return [y for _ in range(50)]
"
google|jax|api_benchmark.py|075	Function	"def jax_array_arrays_8_devices(state):
  mesh = jax.sharding.Mesh(
      np.array(jax.devices()[:8]).reshape((4, 2)), ('x', 'y')
  )
  sharding = jax.sharding.NamedSharding(
      mesh, jax.sharding.PartitionSpec('x', 'y')
  )
  inp = jax.device_put(np.zeros((8, 4), dtype=np.float32), sharding)
"
google|jax|api_benchmark.py|076	Function	"  def fn(x):
    y = x + x
    return [y for _ in range(200)]
"
google|jax|api_benchmark.py|077	Function	"def batch_inplace_while(inplace_op, state):
"
google|jax|api_benchmark.py|078	Function	"  def f(init_step, init_xs):
"
google|jax|api_benchmark.py|079	Function	"    def cond(carry):
      step, xs = carry
      return step < xs.size
"
google|jax|api_benchmark.py|080	Function	"    def body(carry):
      step, xs = carry
      if inplace_op == 'scatter':
        xs = xs.at[step].set(1)
      elif inplace_op == 'dynamic_update_slice':
        xs = lax.dynamic_update_index_in_dim(xs, 1., step, 0)
      else:
        assert False
      return step + 1, xs
"
