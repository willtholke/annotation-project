0	adjudicated	label-na	"def benchmark(f: Callable[[], Any], iters: Optional[int] = None,
              warmup: Optional[int] = None, name: Optional[str] = None,
              target_total_secs: Optional[Union[int, float]] = None):
  """"""Benchmarks ``f``. Prints the results and returns the raw times.
  """""""
1	adjudicated	label-na	"def benchmark_suite(prepare: Callable[..., Callable], params_list: List[Dict],
                    name: str, target_total_secs: Optional[int] = None):
  """"""Benchmarks a function for several combinations of parameters.
  """""""
2	adjudicated	label-na	"def _get_baseline_means(baseline_dir, name):
  baseline_dir = os.path.expanduser(baseline_dir)
  filename = os.path.join(baseline_dir, name + "".csv"")
  if not os.path.exists(filename):
    raise FileNotFoundError(""Can't find baseline file: %s"" % filename)
  with open(filename, newline="""") as csvfile:
    reader = csv.reader(csvfile)
    header = next(reader)
    mean_idx = header.index(""mean"")
    return [float(row[mean_idx]) for row in reader]"
3	adjudicated	label-na	"def _export_results(data_header, data, export_dir, name):
  assert ""mean"" in data_header # For future comparisons via _get_baseline_means
  export_dir = os.path.expanduser(export_dir)
  os.makedirs(export_dir, exist_ok=True)
  filename = os.path.join(export_dir, name + "".csv"")
  with open(filename, ""w"", newline="""") as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(data_header)
    writer.writerows(data)
  return filename"
4	adjudicated	label-na	"def _param_str(param):
  if callable(param):
    return param.__name__
  return str(param)"
5	adjudicated	label-na	"def math_benchmark(*args):
  def decorator(func):
    for test_case in args[0]:"
6	adjudicated	label-na	"def wrapper(state, test_case=test_case):
  return func(state, **test_case)"
7	adjudicated	label-na	"def jax_unary(state, **kwargs):
  shape = kwargs['shape']
  dtype = kwargs['dtype']
  op = kwargs['op']
  input0 = np.random.random(shape).astype(dtype)
  f = op
  f_jitted = jax.jit(f)
  f_jitted(input0).block_until_ready()
  while state:
    f_jitted(input0).block_until_ready()
  state.counters['items_per_second'] = Counter(
      input0.size * state.iterations, Counter.kIsRate
  )"
8	adjudicated	label-na	"def jax_binary_op(state, **kwargs):
  mkn = kwargs['mkn']
  m = mkn[0]
  k = mkn[1]
  n = mkn[2]
  dtype = kwargs['dtype']
  op = kwargs['op']
  a = np.random.random([m, k]).astype(dtype)
  b = np.random.random([k, n]).astype(dtype)
  f = op
  f_jitted = jax.jit(f)
  f_jitted(a, b).block_until_ready()
  while state:
    f_jitted(a, b).block_until_ready()
  state.counters['items_per_second'] = Counter(
      state.iterations, Counter.kIsRate
  )"
9	adjudicated	label-na	"def get_regions():
    return requests.post(_API_URL, json={'name':'list_regions'},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['regions']"
10	adjudicated	label-na	"def find_existing_cluster():
    return requests.post(_API_URL, json={'name':'find_cluster'},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['region']"
11	adjudicated	label-na	"def get_cluster_ip(region):
    return requests.post(_API_URL, json={'name':'get_cluster_ip', 'region':region},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['cluster_ip']"
12	adjudicated	label-na	"def get_cluster_username(region):
    return requests.post(_API_URL, json={'name':'get_cluster_username', 'region':region},
                         auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS).json()['cluster_username']"
13	adjudicated	label-na	"def create_cluster(region):
    logging.debug(requests.post(_API_URL, json={'name':'create_cluster', 'region':region},
                                auth=_API_AUTH, timeout=_REQUEST_TIMEOUT_SECONDS))"
14	adjudicated	label-na	"class DefaultReport:
  outcome : str = ""none"""
15	adjudicated	label-na	"def parse_line(line):
  # TODO(jakevdp): should we parse other report types?
  parsed = json.loads(line)
  if parsed.get(""$report_type"") == ""TestReport"":
    return TestReport._from_json(parsed)
  return DefaultReport()"
16	adjudicated	label-na	"def main(logfile, outfile):
  logging.info(""Parsing %s"", logfile)
  try:
    with open(logfile, 'r') as f:
      reports = (parse_line(line) for line in f)
      failures = (r for r in reports if r.outcome == ""failed"")
      summary = ""\n"".join(f""{f.nodeid}: {f.longrepr.chain[0][1].message}""
                          for f in failures)
    logging.info(""Parsed summary:\n%s"", summary)
  except Exception:
    err_info = traceback.format_exc()
    logging.info(""Parsing failed:\n%s"", err_info)
    summary = f""Log parsing failed; traceback:\n\n{err_info}""
  logging.info(""Writing result to %s"", outfile)
  with open(outfile, 'w') as f:
    f.write(MSG_FORMAT.format(summary=summary))"
17	adjudicated	label-na	"class AnEnum(enum.IntEnum):
  A = 123
  B = 456"
18	adjudicated	label-na	"def required_devices(num_devices_required):
  """"""Helper to skip benchmarks that require more devices.""""""
  def helper1(f):
    @functools.wraps(f)
    def helper2(state):
      if jax.device_count() < num_devices_required:
        state.skip_with_error(f""requires {num_devices_required} devices"")
        return
      return f(state)
    return helper2
  return helper1"
19	adjudicated	label-na	"def create_mesh(shape, axis_names, state):
  size = np.prod(shape)
  if len(jax.devices()) < size:
    state.skip_with_error(f""Requires {size} devices"")
    return None
  devices = sorted(jax.devices(), key=lambda d: d.id)
  mesh_devices = np.array(devices[:size]).reshape(shape)
  global_mesh = jax.sharding.Mesh(mesh_devices, axis_names)
  return global_mesh"
20	adjudicated	label-na	"def is_windows():
  return sys.platform.startswith(""win32"")"
21	adjudicated	label-na	"def shell(cmd):
  try:
    output = subprocess.check_output(cmd)
  except subprocess.CalledProcessError as e:
    print(e.output)
    raise
  return output.decode(""UTF-8"").strip()"
22	adjudicated	label-na	"def get_python_bin_path(python_bin_path_flag):
  """"""Returns the path to the Python interpreter to use.""""""
  path = python_bin_path_flag or sys.executable
  return path.replace(os.sep, ""/"")"
23	adjudicated	label-na	"def get_python_version(python_bin_path):
  version_output = shell(
    [python_bin_path, ""-c"",
     (""import sys; print(\""{}.{}\"".format(sys.version_info[0], ""
      ""sys.version_info[1]))"")])
  major, minor = map(int, version_output.split("".""))
  return major, minor"
24	adjudicated	label-na	"def check_python_version(python_version):
  if python_version < (3, 8):
    print(""ERROR: JAX requires Python 3.8 or newer, found "", python_version)
    sys.exit(-1)"
25	adjudicated	label-na	"def get_benchmark_fn(nargs, nshards):
  pmap_fn = pmap(lambda *args: jnp.sum(jnp.array(args)))
  shape = (nshards, 4)
  args = [np.random.random(shape) for _ in range(nargs)]
  sharded_args = pmap(lambda x: x)(args)
  assert all(isinstance(arg, jax.Array) for arg in sharded_args)
  def benchmark_fn():
    for _ in range(100):
      pmap_fn(*sharded_args)
  return benchmark_fn"
26	adjudicated	label-na	"def benchmark_fn():
  for _ in range(100):
    pmap_fn(*sharded_args)
return benchmark_fn"
27	adjudicated	label-na	"def get_benchmark_fn(nargs, nshards):
  pmap_fn = pmap(lambda *args: jnp.sum(jnp.array(args)))
  shape = (nshards, 4)
  args = [jnp.array(np.random.random(shape)) for _ in range(nargs)]
  assert all(isinstance(arg, jax.Array) for arg in args)
  def benchmark_fn():
    for _ in range(10):
      pmap_fn(*args)
  return benchmark_fn"
28	adjudicated	label-na	"def main(logfile: str, outmd: str, outjson: str, name: str):
    print(f""Extracting content of {logfile}"")
    print(f""and writing to {outmd} and {outjson}"")"
29	adjudicated	label-na	"class MakeCutouts(nn.Module):
  def __init__(self, cut_size, cut_power=1.0):
      super().__init__()"
30	adjudicated	label-na	"class CLIPGuidedStableDiffusion(DiffusionPipeline):
    """"""CLIP guided stable diffusion based on the amazing repo by @crowsonkb and @Jack000
    - https://github.com/Jack000/glid-3-xl
    - https://github.dev/crowsonkb/k-diffusion
    """"""

    def __init__(self, cut_size, cut_power=1.0):
        super().__init__()

    def forward(self, pixel_values, num_cutouts):
    sideY, sideX = pixel_values.shape[2:4]
    max_size = min(sideX, sideY)
    min_size = min(sideX, sideY, self.cut_size)
    cutouts = []
    for _ in range(num_cutouts):
        size = int(torch.rand([]) ** self.cut_power * (max_size - min_size) + min_size)
        offsetx = torch.randint(0, sideX - size + 1, ())
        offsety = torch.randint(0, sideY - size + 1, ())
        cutout = pixel_values[:, :, offsety : offsety + size, offsetx : offsetx + size]
        cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))
    return torch.cat(cutouts)

    def spherical_dist_loss(x, y):
    x = F.normalize(x, dim=-1)
    y = F.normalize(y, dim=-1)
    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)"
31	adjudicated	label-na	"class DDIMNoiseComparativeAnalysisPipeline(DiffusionPipeline):
    r""""""
    This model inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods the
    library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)
    """""""
32	adjudicated	label-na	"def preprocess(image):
    if isinstance(image, torch.Tensor):
        return image
    elif isinstance(image, PIL.Image.Image):
        image = [image]"
33	adjudicated	label-na	"def check_inputs(self, strength):
    if strength < 0 or strength > 1:
        raise ValueError(f""The value of strength should in [0.0, 1.0] but is {strength}"")"
34	adjudicated	label-na	"def get_timesteps(self, num_inference_steps, strength, device):
    # get the original timestep using init_timestep
    init_timestep = min(int(num_inference_steps * strength), num_inference_steps)"
35	adjudicated	label-na	"class CheckpointMergerPipeline(DiffusionPipeline):
    """"""
    A class that that supports merging diffusion models based on the discussion here:
    https://github.com/huggingface/diffusers/issues/877

    def __init__(self):
        self.register_to_config()
        super().__init__()

    def _compare_model_configs(self, dict0, dict1):
        if dict0 == dict1:
            return True
        else:
            config0, meta_keys0 = self._remove_meta_keys(dict0)
            config1, meta_keys1 = self._remove_meta_keys(dict1)
            if config0 == config1:
                print(f""Warning !: Mismatch in keys {meta_keys0} and {meta_keys1}."")
                return True
        return False

    def _remove_meta_keys(self, config_dict: Dict):
        meta_keys = []
        temp_dict = config_dict.copy()
        for key in config_dict.keys():
            if key.startswith(""_""):
                temp_dict.pop(key)
                meta_keys.append(key)
        return (temp_dict, meta_keys)"
36	adjudicated	label-na	"class ImagicStableDiffusionPipeline(DiffusionPipeline):
    r""""""
    Pipeline for imagic image editing.
    See paper here: https://arxiv.org/pdf/2210.09276.pdf
    """""""
37	adjudicated	label-na	"def preprocess(image):
    w, h = image.size
    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32
    image = image.resize((w, h), resample=PIL_INTERPOLATION[""lanczos""])
    image = np.array(image).astype(np.float32) / 255.0
    image = image[None].transpose(0, 3, 1, 2)
    image = torch.from_numpy(image)
    return 2.0 * image - 1.0"
38	adjudicated	label-na	"def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = ""auto""):
    r""""""
    Enable sliced attention computation.
    When this option is enabled, the attention module will split the input tensor in slices, to compute attention
    in several steps. This is useful to save some memory in exchange for a small speed decrease.
    Args:
        slice_size (`str` or `int`, *optional*, defaults to `""auto""`):
            When `""auto""`, halves the input to the attention heads, so attention will be computed in two steps. If
            a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,
            `attention_head_dim` must be a multiple of `slice_size`.
    """"""
    if slice_size == ""auto"":
        # half the attention head size is usually a good trade-off between
        # speed and memory
        slice_size = self.unet.config.attention_head_dim // 2
    self.unet.set_attention_slice(slice_size)"
39	adjudicated	label-na	"def disable_attention_slicing(self):
    r""""""
    Disable sliced attention computation. If `enable_attention_slicing` was previously invoked, this method will go
    back to computing attention in one step.
    """"""
    # set slice_size = `None` to disable `attention slicing`
    self.enable_attention_slicing(None)"
40	adjudicated	label-na	"class ComposableStableDiffusionPipeline(DiffusionPipeline):
    r""""""
    Pipeline for text-to-image generation using Stable Diffusion."
41	adjudicated	label-na	"def __init__(
    self,
    vae: AutoencoderKL,
    text_encoder: CLIPTextModel,
    tokenizer: CLIPTokenizer,
    unet: UNet2DConditionModel,
    scheduler: Union[
        DDIMScheduler,
        PNDMScheduler,
        LMSDiscreteScheduler,
        EulerDiscreteScheduler,
        EulerAncestralDiscreteScheduler,
        DPMSolverMultistepScheduler,
    ],
    safety_checker: StableDiffusionSafetyChecker,
    feature_extractor: CLIPFeatureExtractor,
    requires_safety_checker: bool = True,
):
    super().__init__()"
42	adjudicated	label-na	"def enable_vae_slicing(self):
    r""""""
    Enable sliced VAE decoding.
    """""""
43	adjudicated	label-na	"def disable_vae_slicing(self):
    r""""""
    Disable sliced VAE decoding. If `enable_vae_slicing` was previously invoked, this method will go back to
    computing decoding in one step.
    """"""
    self.vae.disable_slicing()"
44	adjudicated	label-na	"def enable_sequential_cpu_offload(self, gpu_id=0):
    r""""""
    Offloads all models to CPU using accelerate, significantly reducing memory usage. When called, unet,
    text_encoder, vae and safety checker have their state dicts saved to CPU and then are moved to a
    `torch.device('meta') and loaded to GPU only when their specific submodule has its `forward` method called.
    """"""
    if is_accelerate_available():
        from accelerate import cpu_offload
    else:
        raise ImportError(""Please install accelerate via `pip install accelerate`"")"
45	adjudicated	label-na	"def prepare_mask_and_masked_image(image, mask):
    image = np.array(image.convert(""RGB""))
    image = image[None].transpose(0, 3, 1, 2)
    image = torch.from_numpy(image).to(dtype=torch.float32) / 127.5 - 1.0"
46	adjudicated	label-na	"def check_size(image, height, width):
    if isinstance(image, PIL.Image.Image):
        w, h = image.size
    elif isinstance(image, torch.Tensor):
        *_, h, w = image.shape"
47	adjudicated	label-na	"def overlay_inner_image(image, inner_image, paste_offset: Tuple[int] = (0, 0)):
    inner_image = inner_image.convert(""RGBA"")
    image = image.convert(""RGB"")"
48	adjudicated	label-na	"class BitDiffusion(DiffusionPipeline):
    def __init__(
        self,
        unet: UNet2DConditionModel,
        scheduler: Union[DDIMScheduler, DDPMScheduler],
        bit_scale: Optional[float] = 1.0,
    ):
        super().__init__()
        self.bit_scale = bit_scale
        self.scheduler.step = (
            ddim_bit_scheduler_step if isinstance(scheduler, DDIMScheduler) else ddpm_bit_scheduler_step
        )"
49	adjudicated	label-na	"def decimal_to_bits(x, bits=BITS):
    """"""expects image tensor ranging from 0 to 1, outputs bit tensor ranging from -1 to 1""""""
    device = x.device"
50	adjudicated	label-na	"def bits_to_decimal(x, bits=BITS):
    """"""expects bits from -1 to 1, outputs image tensor from 0 to 1""""""
    device = x.device"
51	adjudicated	label-na	"def ddim_bit_scheduler_step(
    self,
    model_output: torch.FloatTensor,
    timestep: int,
    sample: torch.FloatTensor,
    eta: float = 0.0,
    use_clipped_model_output: bool = True,
    generator=None,
    return_dict: bool = True,
) -> Union[DDIMSchedulerOutput, Tuple]:
    """"""
    Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
    process from the learned model outputs (most often the predicted noise).
    Args:
        model_output (`torch.FloatTensor`): direct output from learned diffusion model.
        timestep (`int`): current discrete timestep in the diffusion chain.
        sample (`torch.FloatTensor`):
            current instance of sample being created by diffusion process.
        eta (`float`): weight of noise for added noise in diffusion step.
        use_clipped_model_output (`bool`): TODO
        generator: random number generator.
        return_dict (`bool`): option for returning tuple rather than DDIMSchedulerOutput class
    Returns:
        [`~schedulers.scheduling_utils.DDIMSchedulerOutput`] or `tuple`:
        [`~schedulers.scheduling_utils.DDIMSchedulerOutput`] if `return_dict` is True, otherwise a `tuple`. When
        returning a tuple, the first element is the sample tensor.
    """"""
    if self.num_inference_steps is None:
        raise ValueError(
            ""Number of inference steps is 'None', you need to run 'set_timesteps' after creating the scheduler""
        )"
52	adjudicated	label-na	"def ddpm_bit_scheduler_step(
    self,
    model_output: torch.FloatTensor,
    timestep: int,
    sample: torch.FloatTensor,
    prediction_type=""epsilon"",
    generator=None,
    return_dict: bool = True,
) -> Union[DDPMSchedulerOutput, Tuple]:
    """"""
    Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
    process from the learned model outputs (most often the predicted noise).
    Args:
        model_output (`torch.FloatTensor`): direct output from learned diffusion model.
        timestep (`int`): current discrete timestep in the diffusion chain.
        sample (`torch.FloatTensor`):
            current instance of sample being created by diffusion process.
        prediction_type (`str`, default `epsilon`):
            indicates whether the model predicts the noise (epsilon), or the samples (`sample`).
        generator: random number generator.
        return_dict (`bool`): option for returning tuple rather than DDPMSchedulerOutput class
    Returns:
        [`~schedulers.scheduling_utils.DDPMSchedulerOutput`] or `tuple`:
        [`~schedulers.scheduling_utils.DDPMSchedulerOutput`] if `return_dict` is True, otherwise a `tuple`. When
        returning a tuple, the first element is the sample tensor.
    """"""
    t = timestep"
53	adjudicated	label-na	"def set_seed(seed: int):
    hf_set_seed(seed)"
54	adjudicated	label-na	"class Entity:
    """"""
    Internal class to represent entities while converting biomedical NER corpora to a standardized format
    (only used for pre-processing purposes!). Each entity consists of the char span it addresses in
    the original text as well as the type of entity (e.g. Chemical, Gene, and so on).
    """""""
55	adjudicated	label-na	"class DpEntry(NamedTuple):
    position_end: int
    entity_count: int
    entity_lengths_sum: int
    last_entity: Optional[Entity]"
56	adjudicated	label-na	"class ClassificationCorpus(Corpus):
    """"""
    A classification corpus from FastText-formatted text files.
    """""""
57	adjudicated	label-na	"class ClassificationDataset(FlairDataset):
    """"""
    Dataset for classification instantiated from a single FastText-formatted file.
    """""""
58	adjudicated	label-na	"class CSVClassificationCorpus(Corpus):
    """"""
    Classification corpus instantiated from CSV data files.
    """""""
59	adjudicated	label-na	"class CSVClassificationDataset(FlairDataset):
    """"""
    Dataset for text classification from CSV column formatted data.
    """""""
60	adjudicated	label-na	"def main():
    print(""#### Versions:"")
    print(f""##### Flair\n{flair.__version__}"")
    print(f""##### Pytorch\n{torch.__version__}"")
    print(f""##### Transformers\n{transformers.__version__}"")
    print(f""#### GPU\n{torch.cuda.is_available()}"")"
61	adjudicated	label-na	"class DataLoader(torch.utils.data.dataloader.DataLoader):
    def __init__(
        self,
        dataset,
        batch_size=1,
        shuffle=False,
        sampler=None,
        batch_sampler=None,
        num_workers=None,
        drop_last=False,
        timeout=0,
        worker_init_fn=None,
    ):
        # in certain cases, multi-CPU data loading makes no sense and slows
        # everything down. For this reason, we detect if a dataset is in-memory:
        # if so, num_workers is set to 0 for faster processing
        flair_dataset = dataset
        while True:
            if type(flair_dataset) is Subset:
                flair_dataset = flair_dataset.dataset
            elif type(flair_dataset) is ConcatDataset:
                flair_dataset = flair_dataset.datasets[0]
            else:
                break"
62	adjudicated	label-na	"class FlairDatapointDataset(FlairDataset, Generic[DT]):
    """"""
    A simple Dataset object to wrap a List of Datapoints, for example Sentences
    """""""
63	adjudicated	label-na	"class SentenceDataset(FlairDatapointDataset):
    @deprecated(version=""0.11"", reason=""The 'SentenceDataset' class was renamed to 'FlairDatapointDataset'"")
    def __init__(self, sentences: Union[Sentence, List[Sentence]]):
        super().__init__(sentences)"
64	adjudicated	label-na	"class ModelArguments:
    model_name_or_path: str = field(
        metadata={""help"": ""The model checkpoint for weights initialization.""},
    )
    layers: str = field(default=""-1"", metadata={""help"": ""Layers to be fine-tuned.""})
    subtoken_pooling: str = field(
        default=""first"",
        metadata={""help"": ""Subtoken pooling strategy used for fine-tuned.""},
    )
    hidden_size: int = field(default=256, metadata={""help"": ""Hidden size for NER model.""})
    use_crf: bool = field(default=False, metadata={""help"": ""Whether to use a CRF on-top or not.""})"
65	adjudicated	label-na	"class TrainingArguments:
    num_epochs: int = field(default=10, metadata={""help"": ""The number of training epochs.""})
    batch_size: int = field(default=8, metadata={""help"": ""Batch size used for training.""})
    mini_batch_chunk_size: int = field(
        default=1,
        metadata={""help"": ""If smaller than batch size, batches will be chunked.""},
    )
    learning_rate: float = field(default=5e-05, metadata={""help"": ""Learning rate""})
    seed: int = field(default=42, metadata={""help"": ""Seed used for reproducible fine-tuning results.""})
    device: str = field(default=""cuda:0"", metadata={""help"": ""CUDA device string.""})
    weight_decay: float = field(default=0.0, metadata={""help"": ""Weight decay for optimizer.""})
    embeddings_storage_mode: str = field(default=""none"", metadata={""help"": ""Defines embedding storage method.""})"
66	adjudicated	label-na	"class FlertArguments:
    context_size: int = field(default=0, metadata={""help"": ""Context size when using FLERT approach.""})
    respect_document_boundaries: bool = field(
        default=False,
        metadata={""help"": ""Whether to respect document boundaries or not when using FLERT.""},
    )"
67	adjudicated	label-na	"class DataArguments:
    dataset_name: str = field(metadata={""help"": ""Flair NER dataset name.""})
    dataset_arguments: str = field(default="""", metadata={""help"": ""Dataset arguments for Flair NER dataset.""})
    output_dir: str = field(
        default=""resources/taggers/ner"",
        metadata={""help"": ""Defines output directory for final fine-tuned model.""},
    )"
68	adjudicated	label-na	"def get_flair_corpus(data_args):
    ner_task_mapping = {}"
69	adjudicated	label-na	"class Dictionary:
    """"""
    This class holds a dictionary that maps strings to IDs, used to generate one-hot encodings of strings.
    """""""
70	adjudicated	label-na	"class Label:
    """"""
    This class represents a label. Each label has a value and optionally a confidence score. The
    score needs to be between 0.0 and 1.0. Default value for the score is 1.0.
    """""""
71	adjudicated	label-na	"class DataPoint:
    """"""
    This is the parent class of all data points in Flair (including Token, Sentence, Image, etc.). Each DataPoint
    must be embeddable (hence the abstract property embedding() and methods to() and clear_embeddings()). Also,
    each DataPoint may have Labels in several layers of annotation (hence the functions add_label(), get_labels()
    and the property 'label')
    """""""
72	adjudicated	label-na	"def setup(app: Sphinx) -> None:
    app.add_object_type(
        ""confval"",
        ""confval"",
        objname=""configuration value"",
        indextemplate=""pair: %s; configuration value"",
        doc_field_types=[
            Field(""type"", label=""Type"", has_arg=False, names=(""type"",)),
            Field(""default"", label=""Default"", has_arg=False, names=(""default"",)),
        ],
    )"
73	adjudicated	label-na	"def make_cache(input_dir: str, sqlite: bool) -> MetadataStore:
    if sqlite:
        return SqliteMetadataStore(input_dir)
    else:
        return FilesystemMetadataStore(input_dir)"
74	adjudicated	label-na	"def apply_diff(cache_dir: str, diff_file: str, sqlite: bool = False) -> None:
    cache = make_cache(cache_dir, sqlite)
    with open(diff_file) as f:
        diff = json.load(f)"
75	adjudicated	label-na	"def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(""--sqlite"", action=""store_true"", default=False, help=""Use a sqlite cache"")
    parser.add_argument(""cache_dir"", help=""Directory for the cache"")
    parser.add_argument(""diff"", help=""Cache diff file"")
    args = parser.parse_args()"
76	adjudicated	label-na	"class CacheData:
    def __init__(
        self,
        filename: str,
        data_json: JsonDict,
        meta_json: JsonDict,
        data_size: int,
        meta_size: int,
    ) -> None:
        self.filename = filename
        self.data = data_json
        self.meta = meta_json
        self.data_size = data_size
        self.meta_size = meta_size"
77	adjudicated	label-na	"def total_size(self) -> int:
    return self.data_size + self.meta_size"
78	adjudicated	label-na	"def extract_classes(chunks: Iterable[CacheData]) -> Iterable[JsonDict]:
    def extract(chunks: Iterable[JsonDict]) -> Iterable[JsonDict]:
        for chunk in chunks:
            if isinstance(chunk, dict):
                yield chunk
                yield from extract(chunk.values())
            elif isinstance(chunk, list):
                yield from extract(chunk)"
79	adjudicated	label-na	"def extract(chunks: Iterable[JsonDict]) -> Iterable[JsonDict]:
    for chunk in chunks:
        if isinstance(chunk, dict):
            yield chunk
            yield from extract(chunk.values())
        elif isinstance(chunk, list):
            yield from extract(chunk)"
80	adjudicated	label-na	"class It(Iterator[str]):
    stop = False"
81	adjudicated	label-na	"class Aw(Awaitable[int]):
    def __await__(self) -> Generator[str, Any, int]:
        yield ""a""
        return 1"
82	adjudicated	label-na	"def plain_generator() -> Generator[str, None, int]:
    yield ""a""
    return 1"
83	adjudicated	label-na	"async def plain_coroutine() -> int:
    return 1"
84	adjudicated	label-na	"def decorated_generator() -> Generator[str, None, int]:
    yield ""a""
    return 1"
85	adjudicated	label-na	"def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        ""--to-sqlite"",
        action=""store_true"",
        default=False,
        help=""Convert to a sqlite cache (default: convert from)"",
    )
    parser.add_argument(
        ""--output_dir"",
        action=""store"",
        default=None,
        help=""Output cache location (default: same as input)"",
    )
    parser.add_argument(""input_dir"", help=""Input directory for the cache"")
    args = parser.parse_args()"
86	adjudicated	label-na	"def pytest_configure(config):
    mypy_source_root = os.path.dirname(os.path.abspath(__file__))
    if os.getcwd() != mypy_source_root:
        os.chdir(mypy_source_root)"
87	adjudicated	label-na	"def pytest_addoption(parser) -> None:
    parser.addoption(
        ""--bench"", action=""store_true"", default=False, help=""Enable the benchmark test runs""
    )"
88	adjudicated	label-na	"def parse_commit_title(diff: str) -> str:
    m = re.search(""\n    ([^ ].*)"", diff)
    assert m is not None, ""Could not parse diff""
    return m.group(1)"
89	adjudicated	label-na	"def main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        ""--typeshed-dir"", help=""location of typeshed"", metavar=""dir"", required=True
    )
    parser.add_argument(""commit"", help=""typeshed commit hash to cherry-pick"")
    args = parser.parse_args()
    typeshed_dir = args.typeshed_dir
    commit = args.commit"
90	adjudicated	label-na	"def setup(app):
    app.add_css_file(""custom.css"")"
91	adjudicated	label-na	"class PipenvGroup(DYMMixin, Group):
    """"""Custom Group class provides formatted main help"""""""
92	adjudicated	label-na	"class State:
    def __init__(self):
        self.index = None
        self.verbose = False
        self.quiet = False
        self.pypi_mirror = None
        self.python = None
        self.site_packages = None
        self.clear = False
        self.system = False
        self.project = Project()
        self.installstate = InstallState()
        self.lockoptions = LockOptions()"
93	adjudicated	label-na	"class InstallState:
    def __init__(self):
        self.dev = False
        self.pre = False
        self.selective_upgrade = False
        self.keep_outdated = False
        self.skip_lock = False
        self.ignore_pipfile = False
        self.code = False
        self.requirementstxt = None
        self.deploy = False
        self.packages = []
        self.editables = []
        self.extra_pip_args = []
        self.categories = []"
94	adjudicated	label-na	"class LockOptions:
    def __init__(self):
        self.dev_only = False"
95	adjudicated	label-na	"def cli(
    ctx,
    state,
    where=False,
    venv=False,
    py=False,
    envs=False,
    rm=False,
    bare=False,
    man=False,
    support=None,
    help=False,
    site_packages=None,
    **kwargs,
):
    from pipenv.patched.pip._vendor import rich
    from pipenv.utils.shell import system_which"
96	adjudicated	label-na	"def install(state, **kwargs):
    """"""Installs provided packages and adds them to Pipfile, or (if no packages are given), installs all packages from Pipfile.""""""
    from pipenv.routines.install import do_install
    "
97	adjudicated	label-na	"def upgrade(state, **kwargs):
    from pipenv.routines.update import upgrade
    from pipenv.utils.project import ensure_project"
98	adjudicated	label-na	"def uninstall(ctx, state, all_dev=False, all=False, **kwargs):
    """"""Uninstalls a provided package and removes it from Pipfile.""""""
    from pipenv.routines.uninstall import do_uninstall"
99	adjudicated	label-na	"def lock(ctx, state, **kwargs):
    """"""Generates Pipfile.lock.""""""
    from pipenv.routines.lock import do_lock
    from pipenv.utils.project import ensure_project"
100	adjudicated	label-na	"def determine_pip_install_arguments():
    implicit_pip = True
    implicit_setuptools = False
    implicit_wheel = True"
101	adjudicated	label-na	"def monkeypatch_for_cert(tmpdir):
    """"""Patches `pip install` to provide default certificate with the lowest priority.
    """""""
102	adjudicated	label-na	"def cert_parse_args(self, args):
    if not self.parser.get_default_values().cert:
        # There are no user provided cert -- force use of bundled cert
        self.parser.defaults[""cert""] = cert_path  # calculated above
    return install_parse_args(self, args)"
103	adjudicated	label-na	"def bootstrap(tmpdir):
    monkeypatch_for_cert(tmpdir)"
104	adjudicated	label-na	"def map(dataset: datasets.Dataset, **kwargs):
    _ = dataset.map(**kwargs)"
105	adjudicated	label-na	"def filter(dataset: datasets.Dataset, **kwargs):
    _ = dataset.filter(**kwargs"
106	adjudicated	label-na	"def benchmark_map_filter():
    times = {""num examples"": SPEED_TEST_N_EXAMPLES}
    with tempfile.TemporaryDirectory() as tmp_dir:
        features = datasets.Features({""text"": datasets.Value(""string""), ""numbers"": datasets.Value(""float32"")})
        dataset = generate_example_dataset(
            os.path.join(tmp_dir, ""dataset.arrow""), features, num_examples=SPEED_TEST_N_EXAMPLES
        )"
107	adjudicated	label-na	"def tokenize(examples):
    return tokenizer(examples[""text""])"
108	adjudicated	label-na	"class RandIter:
    low: int
    high: int
    size: int
    seed: int"
109	adjudicated	label-na	"def generate_100B_dataset(num_examples: int, chunk_size: int) -> datasets.Dataset:
    table = pa.Table.from_pydict({""col"": [0] * chunk_size})
    table = pa.concat_tables([table] * (num_examples // chunk_size))
    return datasets.Dataset(table, fingerprint=""table_100B"")"
110	adjudicated	label-na	"def __post_init__(self):
    rng = np.random.default_rng(self.seed)
    self._sampled_values = rng.integers(low=self.low, high=self.high, size=self.size).tolist()"
111	adjudicated	label-na	"def __iter__(self):
    return iter(self._sampled_values)"
112	adjudicated	label-na	"def __len__(self):
    return self.size"
113	adjudicated	label-na	"def format_json_to_md(input_json_file, output_md_file):
    with open(input_json_file, encoding=""utf-8"") as f:
        results = json.load(f)"
114	adjudicated	label-na	"def read(dataset: datasets.Dataset, length):
    for i in range(length):
        _ = dataset[i]"
115	adjudicated	label-na	"def read_batch(dataset: datasets.Dataset, length, batch_size):
    for i in range(0, len(dataset), batch_size):
        _ = dataset[i : i + batch_size]"
116	adjudicated	label-na	"def read_formatted(dataset: datasets.Dataset, length, type):
    with dataset.formatted_as(type=type):
        for i in range(length):
            _ = dataset[i]"
117	adjudicated	label-na	"def read_formatted_batch(dataset: datasets.Dataset, length, batch_size, type):
    with dataset.formatted_as(type=type):
        for i in range(0, length, batch_size):
            _ = dataset[i : i + batch_size]"
118	adjudicated	label-na	"def benchmark_iterating():
    times = {""num examples"": SPEED_TEST_N_EXAMPLES}
    functions = [
        (read, {""length"": SMALL_TEST}),
        (read, {""length"": SPEED_TEST_N_EXAMPLES}),
        (read_batch, {""length"": SPEED_TEST_N_EXAMPLES, ""batch_size"": 10}),
        (read_batch, {""length"": SPEED_TEST_N_EXAMPLES, ""batch_size"": 100}),
        (read_batch, {""length"": SPEED_TEST_N_EXAMPLES, ""batch_size"": 1_000}),
        (read_formatted, {""type"": ""numpy"", ""length"": SMALL_TEST}),
        (read_formatted, {""type"": ""pandas"", ""length"": SMALL_TEST}),
        (read_formatted, {""type"": ""torch"", ""length"": SMALL_TEST}),
        (read_formatted, {""type"": ""tensorflow"", ""length"": SMALL_TEST}),
        (read_formatted_batch, {""type"": ""numpy"", ""length"": SMALL_TEST, ""batch_size"": 10}),
        (read_formatted_batch, {""type"": ""numpy"", ""length"": SMALL_TEST, ""batch_size"": 1_000}),
    ]"
119	adjudicated	label-na	"def get_duration(func):
    def wrapper(*args, **kwargs):
        starttime = timeit.default_timer()
        _ = func(*args, **kwargs)
        delta = timeit.default_timer() - starttime
        return delta"
120	adjudicated	label-na	"def wrapper(*args, **kwargs):
    starttime = timeit.default_timer()
    _ = func(*args, **kwargs)
    delta = timeit.default_timer() - starttime
    return delta"
121	adjudicated	label-na	"def generate_examples(features: dict, num_examples=100, seq_shapes=None):
    dummy_data = []
    seq_shapes = seq_shapes or {}
    for i in range(num_examples):
        example = {}
        for col_id, (k, v) in enumerate(features.items()):
            if isinstance(v, _ArrayXD):
                data = np.random.rand(*v.shape).astype(v.dtype)
            elif isinstance(v, datasets.Value):
                if v.dtype == ""string"":
                    data = ""The small grey turtle was surprisingly fast when challenged.""
                else:
                    data = np.random.randint(10, size=1).astype(v.dtype).item()
            elif isinstance(v, datasets.Sequence):
                while isinstance(v, datasets.Sequence):
                    v = v.feature
                shape = seq_shapes[k]
                data = np.random.rand(*shape).astype(v.dtype)
            example[k] = data"
122	adjudicated	label-na	"def generate_example_dataset(dataset_path, features, num_examples=100, seq_shapes=None):
    dummy_data = generate_examples(features, num_examples=num_examples, seq_shapes=seq_shapes)"
123	adjudicated	label-na	"def write(my_features, dummy_data, tmp_dir):
    with ArrowWriter(features=my_features, path=os.path.join(tmp_dir, ""beta.arrow"")) as writer:
        for key, record in dummy_data:
            example = my_features.encode_example(record)
            writer.write(example)
        num_examples, num_bytes = writer.finalize()"
124	adjudicated	label-na	"def read_unformated(feats, tmp_dir):
    dataset = datasets.Dataset.from_file(
        filename=os.path.join(tmp_dir, ""beta.arrow""), info=datasets.DatasetInfo(features=feats)
    )
    for _ in dataset:
        pass"
125	adjudicated	label-na	"def read_formatted_as_numpy(feats, tmp_dir):
    dataset = datasets.Dataset.from_file(
        filename=os.path.join(tmp_dir, ""beta.arrow""), info=datasets.DatasetInfo(features=feats)
    )
    dataset.set_format(""numpy"")
    for _ in dataset:
        pass"
126	adjudicated	label-na	"def read_batch_unformated(feats, tmp_dir):
    batch_size = 10
    dataset = datasets.Dataset.from_file(
        filename=os.path.join(tmp_dir, ""beta.arrow""), info=datasets.DatasetInfo(features=feats)
    )
    for i in range(0, len(dataset), batch_size):
        _ = dataset[i : i + batch_size]"
127	adjudicated	label-na	"def read_batch_formatted_as_numpy(feats, tmp_dir):
    batch_size = 10
    dataset = datasets.Dataset.from_file(
        filename=os.path.join(tmp_dir, ""beta.arrow""), info=datasets.DatasetInfo(features=feats)
    )
    dataset.set_format(""numpy"")
    for i in range(0, len(dataset), batch_size):
        _ = dataset[i : i + batch_size]"
128	adjudicated	label-na	"def select(dataset: datasets.Dataset):
    _ = dataset.select(range(0, len(dataset), 2))"
129	adjudicated	label-na	"def sort(dataset: datasets.Dataset):
    _ = dataset.sort(""numbers"")"
130	adjudicated	label-na	"def shuffle(dataset: datasets.Dataset):
    _ = dataset.shuffle()"
131	adjudicated	label-na	"def train_test_split(dataset: datasets.Dataset):
    _ = dataset.train_test_split(0.1)"
132	adjudicated	label-na	"def shard(dataset: datasets.Dataset, num_shards=10):
    for shard_id in range(num_shards):
        _ = dataset.shard(num_shards, shard_id)"
133	adjudicated	label-na	"class RegexpChunkApp:
    """"""
    A graphical tool for exploring the regular expression based chunk
    parser ``nltk.chunk.RegexpChunkParser``.
    """""""
134	adjudicated	label-na	"def normalize_grammar(self, grammar):
    # Strip comments
    grammar = re.sub(r""((\\.|[^#])*)(#.*)?"", r""\1"", grammar)
    # Normalize whitespace
    grammar = re.sub("" +"", "" "", grammar)
    grammar = re.sub(r""\n\s+"", r""\n"", grammar)
    grammar = grammar.strip()
    # [xx] Hack: automatically backslash $!
    grammar = re.sub(r""([^\\])\$"", r""\1\\$"", grammar)
    return grammar"
135	adjudicated	label-na	"def _init_bindings(self, top):
    top.bind(""<Control-n>"", self._devset_next)
    top.bind(""<Control-p>"", self._devset_prev)
    top.bind(""<Control-t>"", self.toggle_show_trace)
    top.bind(""<KeyPress>"", self.update)
    top.bind(""<Control-s>"", lambda e: self.save_grammar())
    top.bind(""<Control-o>"", lambda e: self.load_grammar())
    self.grammarbox.bind(""<Control-t>"", self.toggle_show_trace)
    self.grammarbox.bind(""<Control-n>"", self._devset_next)
    self.grammarbox.bind(""<Control-p>"", self._devset_prev)"
136	adjudicated	label-na	"def _init_fonts(self, top):
    # TWhat's our font size (default=same as sysfont)
    self._size = IntVar(top)
    self._size.set(20)
    self._font = Font(family=""helvetica"", size=-self._size.get())
    self._smallfont = Font(
        family=""helvetica"", size=-(int(self._size.get() * 14 // 20))
    )"
137	adjudicated	label-na	"class RecursiveDescentApp:
    """"""
    A graphical tool for exploring the recursive descent parser.  The tool
    displays the parser's tree and the remaining text, and allows the
    user to control the parser's operation.  In particular, the user
    can expand subtrees on the frontier, match tokens on the frontier
    against the text, and backtrack.  A ""step"" button simply steps
    through the parsing process, performing the operations that
    ``RecursiveDescentParser`` would use.
    """"""

    def __init__(self, grammar, sent, trace=0):
        self._sent = sent
        self._parser = SteppingRecursiveDescentParser(grammar, trace)

"
138	adjudicated	label-na	"def __init__(self, grammar, sent, trace=0):
    self._sent = sent
    self._parser = SteppingRecursiveDescentParser(grammar, trace)"
139	adjudicated	label-na	"def _init_fonts(self, root):
    # See: <http://www.astro.washington.edu/owen/ROTKFolklore.html>
    self._sysfont = Font(font=Button()[""font""])
    root.option_add(""*Font"", self._sysfont)"
140	adjudicated	label-na	"def _init_bindings(self):
    # Key bindings are a good thing.
    self._top.bind(""<Control-q>"", self.destroy)
    self._top.bind(""<Control-x>"", self.destroy)
    self._top.bind(""<Escape>"", self.destroy)
    self._top.bind(""e"", self.expand)
    # self._top.bind('<Alt-e>', self.expand)
    # self._top.bind('<Control-e>', self.expand)
    self._top.bind(""m"", self.match)
    self._top.bind(""<Alt-m>"", self.match)
    self._top.bind(""<Control-m>"", self.match)
    self._top.bind(""b"", self.backtrack)
    self._top.bind(""<Alt-b>"", self.backtrack)
    self._top.bind(""<Control-b>"", self.backtrack)
    self._top.bind(""<Control-z>"", self.backtrack)
    self._top.bind(""<BackSpace>"", self.backtrack)
    self._top.bind(""a"", self.autostep)
    # self._top.bind('<Control-a>', self.autostep)
    self._top.bind(""<Control-space>"", self.autostep)
    self._top.bind(""<Control-c>"", self.cancel_autostep)
    self._top.bind(""<space>"", self.step)
    self._top.bind(""<Delete>"", self.reset)
    self._top.bind(""<Control-p>"", self.postscript)
    # self._top.bind('<h>', self.help)
    # self._top.bind('<Alt-h>', self.help)
    self._top.bind(""<Control-h>"", self.help)
    self._top.bind(""<F1>"", self.help)
    # self._top.bind('<g>', self.toggle_grammar)
    # self._top.bind('<Alt-g>', self.toggle_grammar)
    # self._top.bind('<Control-g>', self.toggle_grammar)
    self._top.bind(""<Control-g>"", self.edit_grammar)
    self._top.bind(""<Control-t>"", self.edit_sentence)"
141	adjudicated	label-na	"class ConcordanceSearchView:
    _BACKGROUND_COLOUR = ""#FFF""  # white"
142	adjudicated	label-na	"class ConcordanceSearchModel:
    def __init__(self, queue):
        self.queue = queue
        self.CORPORA = _CORPORA
        self.DEFAULT_CORPUS = _DEFAULT
        self.selected_corpus = None
        self.reset_query()
        self.reset_results()
        self.result_count = None
        self.last_sent_searched = 0"
143	adjudicated	label-na	"class LoadCorpus(threading.Thread):
    def __init__(self, name, model):
        threading.Thread.__init__(self)
        self.model, self.name = model, name"
144	adjudicated	label-na	"class SearchCorpus(threading.Thread):
    def __init__(self, model, page, count):
        self.model, self.count, self.page = model, count, page
        threading.Thread.__init__(self)"
145	adjudicated	label-na	"class Zone:
    def __init__(self, image, initialField, initialText):
        frm = Frame(root)
        frm.config(background=""white"")
        self.image = PhotoImage(format=""gif"", data=images[image.upper()])
        self.imageDimmed = PhotoImage(format=""gif"", data=images[image])
        self.img = Label(frm)
        self.img.config(borderwidth=0)
        self.img.pack(side=""left"")
        self.fld = Text(frm, **fieldParams)
        self.initScrollText(frm, self.fld, initialField)
        frm = Frame(root)
        self.txt = Text(frm, **textParams)
        self.initScrollText(frm, self.txt, initialText)
        for i in range(2):
            self.txt.tag_config(colors[i], background=colors[i])
            self.txt.tag_config(""emph"" + colors[i], foreground=emphColors[i])"
146	adjudicated	label-na	"class FindZone(Zone):
    def addTags(self, m):
        color = next(self.colorCycle)
        self.txt.tag_add(color, ""1.0+%sc"" % m.start(), ""1.0+%sc"" % m.end())
        try:
            self.txt.tag_add(
                ""emph"" + color, ""1.0+%sc"" % m.start(""emph""), ""1.0+%sc"" % m.end(""emph"")
            )
        except:
            pass"
147	adjudicated	label-na	"class ReplaceZone(Zone):
    def addTags(self, m):
        s = sz.rex.sub(self.repl, m.group())
        self.txt.delete(
            ""1.0+%sc"" % (m.start() + self.diff), ""1.0+%sc"" % (m.end() + self.diff)
        )
        self.txt.insert(""1.0+%sc"" % (m.start() + self.diff), s, next(self.colorCycle))
        self.diff += len(s) - (m.end() - m.start())"
148	adjudicated	label-na	"def __init__(self, image, initialField, initialText):
    frm = Frame(root)
    frm.config(background=""white"")
    self.image = PhotoImage(format=""gif"", data=images[image.upper()])
    self.imageDimmed = PhotoImage(format=""gif"", data=images[image])
    self.img = Label(frm)
    self.img.config(borderwidth=0)
    self.img.pack(side=""left"")
    self.fld = Text(frm, **fieldParams)
    self.initScrollText(frm, self.fld, initialField)
    frm = Frame(root)
    self.txt = Text(frm, **textParams)
    self.initScrollText(frm, self.txt, initialText)
    for i in range(2):
        self.txt.tag_config(colors[i], background=colors[i])
        self.txt.tag_config(""emph"" + colors[i], foreground=emphColors[i])"
149	adjudicated	label-na	"def initScrollText(self, frm, txt, contents):
    scl = Scrollbar(frm)
    scl.config(command=txt.yview)
    scl.pack(side=""right"", fill=""y"")
    txt.pack(side=""left"", expand=True, fill=""x"")
    txt.config(yscrollcommand=scl.set)
    txt.insert(""1.0"", contents)
    frm.pack(fill=""x"")
    Frame(height=2, bd=1, relief=""ridge"").pack(fill=""x"")"
150	adjudicated	label-na	"class CollocationsView:
    _BACKGROUND_COLOUR = ""#FFF""  # white"
151	adjudicated	label-na	"class CollocationsModel:
    def __init__(self, queue):
        self.result_count = None
        self.selected_corpus = None
        self.collocations = None
        self.CORPORA = _CORPORA
        self.DEFAULT_CORPUS = _DEFAULT
        self.queue = queue
        self.reset_results()"
152	adjudicated	label-na	"class LoadCorpus(threading.Thread):
    def __init__(self, name, model):
        threading.Thread.__init__(self)
        self.model, self.name = model, name"
153	adjudicated	label-na	"def __init__(self):
    self.queue = q.Queue()
    self.model = CollocationsModel(self.queue)
    self.top = Tk()
    self._init_top(self.top)
    self._init_menubar()
    self._init_widgets(self.top)
    self.load_corpus(self.model.DEFAULT_CORPUS)
    self.after = self.top.after(POLL_INTERVAL, self._poll)"
154	adjudicated	label-na	"class EdgeList(ColorizedList):
    ARROW = SymbolWidget.SYMBOLS[""rightarrow""]"
155	adjudicated	label-na	"class ChartMatrixView:
    """"""
    A view of a chart that displays the contents of the corresponding matrix.
    """""""
156	adjudicated	label-na	"class ChartResultsView:
    def __init__(self, parent, chart, grammar, toplevel=True):
        self._chart = chart
        self._grammar = grammar
        self._trees = []
        self._y = 10
        self._treewidgets = []
        self._selection = None
        self._selectbox = None"
157	adjudicated	label-na	"class ChartView:
    """"""
    A component for viewing charts.  This is used by ``ChartParserApp`` to
    allow students to interactively experiment with various chart
    parsing techniques.  It is also used by ``Chart.draw()``.
    """""""
158	adjudicated	label-na	"def _fake_PIPE(*args, **kwargs):
    raise NotImplementedError(""subprocess.PIPE is not supported."")"
159	adjudicated	label-na	"def _fake_Popen(*args, **kwargs):
    raise NotImplementedError(""subprocess.Popen is not supported."")"
160	adjudicated	label-na	"def demo():
    print(""To run the demo code for a module, type nltk.module.demo()"")"
161	adjudicated	label-na	"def make_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        ""--deprecation"",
        choices=[""all"", ""pending"", ""imminent"", ""none""],
        default=""imminent"",
    )
    parser.add_argument(""--postgres"", action=""store_true"")
    parser.add_argument(""--elasticsearch5"", action=""store_true"")
    parser.add_argument(""--elasticsearch6"", action=""store_true"")
    parser.add_argument(""--elasticsearch7"", action=""store_true"")
    parser.add_argument(""--emailuser"", action=""store_true"")
    parser.add_argument(""--disabletimezone"", action=""store_true"")
    parser.add_argument(""--bench"", action=""store_true"")
    return parser"
162	adjudicated	label-na	"def parse_args(args=None):
    return make_parser().parse_known_args(args)"
163	adjudicated	label-na	"def runtests():
    args, rest = parse_args()"
164	adjudicated	label-na	"def pytest_addoption(parser):
    parser.addoption(
        ""--deprecation"",
        choices=[""all"", ""pending"", ""imminent"", ""none""],
        default=""pending"",
    )
    parser.addoption(""--postgres"", action=""store_true"")
    parser.addoption(""--elasticsearch"", action=""store_true"")"
165	adjudicated	label-na	"def pytest_configure(config):
    deprecation = config.getoption(""deprecation"")"
166	adjudicated	label-na	"def pytest_unconfigure(config):
    from wagtail.test.settings import MEDIA_ROOT, STATIC_ROOT"
167	adjudicated	label-na	"def get_language_name(locale_string):
    try:
        return LANGUAGE_OVERRIDES[locale_string]
    except KeyError:
        return Locale.parse(locale_string).english_name"
168	adjudicated	label-na	"def setup(app):
    app.add_js_file(""js/banner.js"")"
169	adjudicated	label-na	"def __init__(self, environment):
    """"""Initialize the extension with the given environment.""""""
    super().__init__(environment)"
170	adjudicated	label-na	"def _expand_path(path):
    """"""Expand both environment variables and user home in the given path.""""""
    path = os.path.expandvars(path)
    path = os.path.expanduser(path)
    return path"
171	adjudicated	label-na	"def merge_configs(default, overwrite):
    """"""Recursively update a dict with the key/value pair of another.

    def get_config(config_path):
    """"""Retrieve the config from the specified path, returning a config dict.""""""
    if not os.path.exists(config_path):
        raise ConfigDoesNotExistException(f'Config file {config_path} does not exist.')"
172	adjudicated	label-na	"def get_config(config_path):
    """"""Retrieve the config from the specified path, returning a config dict.""""""
    if not os.path.exists(config_path):
        raise ConfigDoesNotExistException(f'Config file {config_path} does not exist.')"
173	adjudicated	label-na	"class ConfigDoesNotExistException(CookiecutterException):
    """"""
    Exception for missing config file.
    """""""
174	adjudicated	label-na	"def version_msg():
    """"""Return the Cookiecutter version, location and Python powering it.""""""
    python_version = sys.version
    location = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    return f""Cookiecutter {__version__} from {location} (Python {python_version})"""
175	adjudicated	label-na	"def validate_extra_context(ctx, param, value):
    """"""Validate extra context.""""""
    for string in value:
        if '=' not in string:
            raise click.BadParameter(
                f""EXTRA_CONTEXT should contain items of the form key=value; ""
                f""'{string}' doesn't match that form""
            )"
176	adjudicated	label-na	"def list_installed_templates(default_config, passed_config_file):
    """"""List installed (locally cloned) templates. Use cookiecutter --list-installed.""""""
    config = get_user_config(passed_config_file, default_config)
    cookiecutter_folder = config.get('cookiecutters_dir')
    if not os.path.exists(cookiecutter_folder):
        click.echo(
            f""Error: Cannot list installed templates. ""
            f""Folder does not exist: {cookiecutter_folder}""
        )
        sys.exit(-1)"
177	adjudicated	label-na	"def main(
    template,
    extra_context,
    no_input,
    checkout,
    verbose,
    replay,
    overwrite_if_exists,
    output_dir,
    config_file,
    default_config,
    debug_file,
    directory,
    skip_if_file_exists,
    accept_hooks,
    replay_file,
    list_installed,
    keep_project_on_failure,
):
    """"""Create a project from a Cookiecutter project template (TEMPLATE)."
178	adjudicated	label-na	"def load_response(url: str, filename: str) -> HtmlResponse:
    input_path = Path(__file__).parent / ""_tests"" / filename
    return HtmlResponse(url, body=input_path.read_bytes())"
179	adjudicated	label-na	"def setup(namespace):
    namespace[""load_response""] = load_response"
180	adjudicated	label-na	"class settingslist_node(nodes.General, nodes.Element):
    pass"
181	adjudicated	label-na	"class SettingsListDirective(Directive):
    def run(self):
        return [settingslist_node("""")]"
182	adjudicated	label-na	"def is_setting_index(node):
    if node.tagname == ""index"" and node[""entries""]:
        # index entries for setting directives look like:
        # [('pair', 'SETTING_NAME; setting', 'std:setting-SETTING_NAME', '')]
        entry_type, info, refid = node[""entries""][0][:3]
        return entry_type == ""pair"" and info.endswith(""; setting"")
    return False"
183	adjudicated	label-na	"def get_setting_target(node):
    # target nodes are placed next to the node in the doc tree
    return node.parent[node.parent.index(node) + 1]"
184	adjudicated	label-na	"def setup(app):
    app.connect(""autodoc-skip-member"", maybe_skip_member)"
185	adjudicated	label-na	"def maybe_skip_member(app, what, name, obj, skip, options):
    if not skip:
        # autodocs was generating a text ""alias of"" for the following members
        # https://github.com/sphinx-doc/sphinx/issues/4422
        return name in {""default_item_class"", ""default_selector_class""}
    return skip"
186	adjudicated	label-na	"def main():
    # Used for remembering the file (and its contents)
    # so we don't have to open the same file again.
    _filename = None
    _contents = None"
187	adjudicated	label-na	"class QPSSpider(Spider):
    name = ""qps""
    benchurl = ""http://localhost:8880/"""
188	adjudicated	label-na	"def __init__(self, *a, **kw):
    super().__init__(*a, **kw)
    if self.qps is not None:
        self.qps = float(self.qps)
        self.download_delay = 1 / self.qps
    elif self.download_delay is not None:
        self.download_delay = float(self.download_delay)"
189	adjudicated	label-na	"def start_requests(self):
    url = self.benchurl
    if self.latency is not None:
        url += f""?latency={self.latency}"""
190	adjudicated	label-na	"def parse(self, response):
    pass"
191	adjudicated	label-na	"def _py_files(folder):
    return (str(p) for p in Path(folder).rglob(""*.py""))"
192	adjudicated	label-na	"def chdir(tmpdir):
    """"""Change to pytest-provided temporary directory""""""
    tmpdir.chdir()"
193	adjudicated	label-na	"def pytest_addoption(parser):
    parser.addoption(
        ""--reactor"",
        default=""default"",
        choices=[""default"", ""asyncio""],
    )"
194	adjudicated	label-na	"class Root(Resource):
    def __init__(self):
        Resource.__init__(self)
        self.concurrent = 0
        self.tail = deque(maxlen=100)
        self._reset_stats()"
195	adjudicated	label-na	"def __init__(self):
    Resource.__init__(self)
    self.concurrent = 0
    self.tail = deque(maxlen=100)
    self._reset_stats()"
196	adjudicated	label-na	"def _reset_stats(self):
    self.tail.clear()
    self.start = self.lastmark = self.lasttime = time()"
197	adjudicated	label-na	"def getChild(self, request, name):
    return self"
198	adjudicated	label-na	"def render(self, request):
    now = time()
    delta = now - self.lasttime"
199	adjudicated	label-na	"def test_dtw(N: int, M: int):
    steps = np.concatenate([np.zeros(N - 1), np.ones(M - 1)])
    np.random.shuffle(steps)
    x = np.random.random((N, M)).astype(np.float32)"
200	adjudicated	label-na	"def test_dtw_cuda_equivalence(N: int, M: int):
    x_numpy = np.random.randn(N, M).astype(np.float32)
    x_cuda = torch.from_numpy(x_numpy).cuda()"
201	adjudicated	label-na	"def test_median_filter(shape):
    x = torch.randn(*shape)"
202	adjudicated	label-na	"def test_median_filter_equivalence(shape):
    x = torch.randn(*shape)"
203	adjudicated	label-na	"def test_number_normalizer(std):
    assert std(""two"") == ""2""
    assert std(""thirty one"") == ""31""
    assert std(""five twenty four"") == ""524""
    assert std(""nineteen ninety nine"") == ""1999""
    assert std(""twenty nineteen"") == ""2019"""
204	adjudicated	label-na	"def test_spelling_normalizer():
    std = EnglishSpellingNormalizer()"
205	adjudicated	label-na	"def test_text_normalizer():
    std = EnglishTextNormalizer()
    assert std(""Let's"") == ""let us""
    assert std(""he's like"") == ""he is like""
    assert std(""she's been like"") == ""she has been like""
    assert std(""10km"") == ""10 km""
    assert std(""10mm"") == ""10 mm""
    assert std(""RC232"") == ""rc 232"""
206	adjudicated	label-na	"def test_audio():
    audio_path = os.path.join(os.path.dirname(__file__), ""jfk.flac"")
    audio = load_audio(audio_path)
    assert audio.ndim == 1
    assert SAMPLE_RATE * 10 < audio.shape[0] < SAMPLE_RATE * 12
    assert 0 < audio.std() < 1"
207	adjudicated	label-na	"def pytest_configure(config):
    config.addinivalue_line(""markers"", ""requires_cuda"")"
208	adjudicated	label-na	"def random():
    rand.seed(42)
    numpy.random.seed(42)"
209	adjudicated	label-na	"def test_transcribe(model_name: str):
    device = ""cuda"" if torch.cuda.is_available() else ""cpu""
    model = whisper.load_model(model_name).to(device)
    audio_path = os.path.join(os.path.dirname(__file__), ""jfk.flac"")"
210	adjudicated	label-na	"def test_tokenizer():
    gpt2_tokenizer = get_tokenizer(multilingual=False)
    multilingual_tokenizer = get_tokenizer(multilingual=True)"
211	adjudicated	label-na	"def test_split_on_unicode():
    multilingual_tokenizer = get_tokenizer(multilingual=True)"
212	adjudicated	label-na	"def _download(url: str, root: str, in_memory: bool) -> Union[bytes, str]:
    os.makedirs(root, exist_ok=True)"
213	adjudicated	label-na	"def available_models() -> List[str]:
    """"""Returns the names of available models""""""
    return list(_MODELS.keys())"
214	adjudicated	label-na	"def load_model(
    name: str,
    device: Optional[Union[str, torch.device]] = None,
    download_root: str = None,
    in_memory: bool = False,
) -> Whisper:
    """"""
    Load a Whisper ASR model"
215	adjudicated	label-na	"class _Undefined:
    def __repr__(self) -> str:
        return 'see-below'"
216	adjudicated	label-na	"class Snowflake(Protocol):
    """"""An ABC that details the common operations on a Discord model.
    """""""
217	adjudicated	label-na	"class User(Snowflake, Protocol):
    """"""An ABC that details the common operations on a Discord user.
    """""""
218	adjudicated	label-na	"class PrivateChannel:
    """"""An ABC that details the common operations on a private Discord channel.
    """""""
219	adjudicated	label-na	"class _Overwrites:
    __slots__ = ('id', 'allow', 'deny', 'type')"
220	adjudicated	label-na	"class VersionInfo(NamedTuple):
    major: int
    minor: int
    micro: int
    releaselevel: Literal[""alpha"", ""beta"", ""candidate"", ""final""]
    serial: int"
221	adjudicated	label-na	"class Bot(commands.{base}):
    def __init__(self, intents: discord.Intents, **kwargs):
        super().__init__(command_prefix=commands.when_mentioned_or('{prefix}'), intents=intents, **kwargs)"
222	adjudicated	label-na	"def show_version() -> None:
    entries = []"
223	adjudicated	label-na	"def core(parser: argparse.ArgumentParser, args: argparse.Namespace) -> None:
    if args.version:
        show_version()
    else:
        parser.print_help()"
224	adjudicated	label-na	"class Parameter:
    """"""A class that contains the parameter information of a :class:`Command` callback.
    """""""
225	adjudicated	label-na	"class ContextMenu:
    """"""A class that implements a context menu application command.
    """""""
226	adjudicated	label-na	"class BaseActivity:
    """"""The base activity that all user-settable activities inherit from.
    A user-settable activity is one that can be used in :meth:`Client.change_presence`.
    """""""
227	adjudicated	label-na	"class Activity(BaseActivity):
    """"""Represents an activity in Discord.
    """""""
228	adjudicated	label-na	"class Game(BaseActivity):
    """"""A slimmed down version of :class:`Activity` that represents a Discord game.
    """""""
229	adjudicated	label-na	"class Streaming(BaseActivity):
    """"""A slimmed down version of :class:`Activity` that represents a Discord streaming status.
    """""""
230	adjudicated	label-na	"class Spotify:
    """"""Represents a Spotify listening activity from Discord. This is a special case of
    :class:`Activity` that makes it easier to work with the Spotify integration.
    """""""
231	adjudicated	label-na	"class Cooldown:
    """"""Represents a cooldown for a command.
    """""""
232	adjudicated	label-na	"def __init__(self, rate: float, per: float) -> None:
    self.rate: int = int(rate)
    self.per: float = float(per)
    self._window: float = 0.0
    self._tokens: int = self.rate
    self._last: float = 0.0"
233	adjudicated	label-na	"def get_tokens(self, current: Optional[float] = None) -> int:
    """"""Returns the number of available tokens before rate limiting is applied.
    """""""
234	adjudicated	label-na	"def get_retry_after(self, current: Optional[float] = None) -> float:
    """"""Returns the time in seconds until the cooldown will be reset.
    """""""
235	adjudicated	label-na	"def update_rate_limit(self, current: Optional[float] = None, *, tokens: int = 1) -> Optional[float]:
    """"""Updates the cooldown rate limit.
    """""""
236	adjudicated	label-na	"def close_api_gracefully(apis):
    try:
        for api in apis.values():
            process = api['process']
            childs = get_child_pids(process.pid)
            for p in childs:
                try:
                    os.kill(p, signal.SIGTERM)
                except Exception:
                    p.kill()
            sys.stdout.flush()
            process.terminate()
            process.join()
            sys.stdout.flush()
    except KeyboardInterrupt:
        sys.exit(0)
    except psutil.NoSuchProcess:
        pass"
237	adjudicated	label-na	"async def wait_api_start(api_name, pid, port):
    timeout = 60
    start_time = time.time()
    started = is_pid_listen_port(pid, port)
    while (time.time() - start_time) < timeout and started is False:
        await asyncio.sleep(0.5)
        started = is_pid_listen_port(pid, port)
    return api_name, port, started"
238	adjudicated	label-na	"async def wait_apis_start():
    futures = [
        wait_api_start(api_name, api_data['process'].pid, api_data['port'])
        for api_name, api_data in apis.items() if 'port' in api_data
    ]
    for i, future in enumerate(asyncio.as_completed(futures)):
        api_name, port, started = await future
        if started:
            print(f""{api_name} API: started on {port}"")
        else:
            log.logger.error(f""ERROR: {api_name} API cant start on {port}"")"
239	adjudicated	label-na	"def index():
    return ""MindsDB Hanler Discovery"", 200"
240	adjudicated	label-na	"def register():
    try:
        params = request.json
        host = params.get(""host"")
        port = params.get(""port"")
        _type = params.get(""type"")
        Cache[(host, port)] = _type
        return ""OK"", 200
    except Exception as e:
        return str(e), 500"
241	adjudicated	label-na	"def discover():
    res = {}
    try:
        for k in Cache:
            _type = Cache[k]
            rec = {""host"": k[0], ""port"": k[1]}
            if _type not in res:
                res[_type] = [rec]
            else:
                res[_type].append(rec)
    except Exception as e:
        return {""error"": str(e)}, 500
    return res, 200"
242	adjudicated	label-na	"class QuietSimpleHTTPServer(SimpleHTTPRequestHandler):
    def log_message(self, *args, **kwargs):
        pass"
243	adjudicated	label-na	"class Context:
    benchmarks: ClassVar[List[BaseRunner]] = []
    stack: ExitStack = field(default_factory=ExitStack)
    runner: pyperf.Runner = field(default_factory=pyperf.Runner)"
244	adjudicated	label-na	"class BaseRunner:
    """"""
    An individual benchmark case. By default it has the category
    (e.g like startup or download) and a name.
    """""""
245	adjudicated	label-na	"class CommandRunner(BaseRunner):
    """"""
    Run a single command, and benchmark it.
    """""""
246	adjudicated	label-na	"def build_binaries() -> Iterator[Tuple[str, Path]]:
    for target_script, extra_args in TARGET_SCRIPTS.items():
        subprocess.check_call(
            [
                'pyinstaller',
                '--onefile',
                '--noupx',
                '-p',
                HTTPIE_DIR,
                '--additional-hooks-dir',
                HOOKS_DIR,
                *extra_args,
                target_script,
            ]
        )"
247	adjudicated	label-na	"def build_packages(http_binary: Path, httpie_binary: Path) -> None:
    import httpie"
248	adjudicated	label-na	"def main():
    binaries = dict(build_binaries())
    build_packages(binaries['http_cli'], binaries['httpie_cli'])"
249	adjudicated	label-na	"class FinishedForNow(Exception):
    """"""Raised when remaining GitHub rate limit is zero.""""""

    def main(previous_release: str, current_release: str) -> int:
    since = release_date(previous_release)
    until = release_date(current_release)"
