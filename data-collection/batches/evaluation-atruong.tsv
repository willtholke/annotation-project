250	label-na	atruong	"def find_committers(since: str, until: str) -> FullNames:
    url = f'{REPO_URL}/commits'
    page = 1
    per_page = 100
    params = {
        'since': since,
        'until': until,
        'per_page': per_page,
    }
    committers: FullNames = set()"
251	label-na	atruong	"def find_reporters(since: str, until: str) -> GitHubLogins:
    url = f'{API_URL}/search/issues'
    page = 1
    per_page = 100
    params = {
        'q': f'repo:{REPO}/{OWNER} is:issue closed:{since}..{until}',
        'per_page': per_page,
    }
    reporters: GitHubLogins = set()"
252	label-na	atruong	"def merge_all_the_people(release: str, contributors: People, committers: FullNames, reporters: GitHubLogins) -> None:
    """"""
    >>> contributors = {'Alice': new_person(github='alice', twitter='alice')}
    >>> merge_all_the_people('2.6.0', contributors, {}, {})
    >>> contributors
    {'Alice': {'committed': [], 'reported': [], 'github': 'alice', 'twitter': 'alice'}}
    """""""
253	label-na	atruong	"def hook(hook_api):
    for pkg in [
        'pip',
        'setuptools',
        'distutils',
        'pkg_resources'
    ]:
        datas, binaries, hiddenimports = collect_all(pkg)
        hook_api.add_datas(datas)
        hook_api.add_binaries(binaries)
        hook_api.add_imports(*hiddenimports)"
254	label-na	atruong	"def generate_documentation() -> str:
    database = load_database()
    structure = build_docs_structure(database)
    template = Template(source=TPL_FILE.read_text(encoding='utf-8'))
    output = template.render(structure=structure)
    output = clean_template_output(output)
    return output"
255	label-na	atruong	"def save_doc_file(content: str) -> None:
    current_doc = load_doc_file()
    marker_start = current_doc.find(MARKER_START) + len(MARKER_START)
    assert marker_start > 0, 'cannot find the start marker'
    marker_end = current_doc.find(MARKER_END, marker_start)
    assert marker_start < marker_end, f'{marker_end=} < {marker_start=}'
    updated_doc = (
        current_doc[:marker_start]
        + '\n\n'
        + content
        + '\n\n'
        + current_doc[marker_end:]
    )
    if current_doc != updated_doc:
        DOC_FILE.write_text(updated_doc, encoding='utf-8')"
256	label-na	atruong	"def build_docs_structure(database: Database):
    tools = database[KEY_TOOLS]
    assert len(tools) == len({tool['title'] for tool in tools.values()}), 'tool titles need to be unique'
    tree = database[KEY_DOC_STRUCTURE]
    structure = []
    for platform, tools_ids in tree.items():
        assert platform.isalnum(), f'{platform=} must be alphanumeric for generated links to work'
        platform_tools = [tools[tool_id] for tool_id in tools_ids]
        structure.append((platform, platform_tools))
    return structure
"
257	label-na	atruong	"def clean_template_output(output):
    output = '\n'.join(line.strip() for line in output.strip().splitlines())
    output = re.sub('\n{3,}', '\n\n', output)
    return output"
258	label-na	atruong	"def load_database() -> Database:
    return yaml.safe_load(DB_FILE.read_text(encoding='utf-8'))"
259	label-na	atruong	"def benchmark(ane):
  tin = ANETensor(512*0x20)
  tout = ANETensor(512*0x20)
  dat = open(""../ops/gemm.hwx"", ""rb"").read()
  for k,v in ane.debug(dat[0x4000:0x4300], 16).items():
    print(k,v)
  comp = ane.compile(dat)"
260	label-na	atruong	"def get_macho(fn):
  # mod to make the header okay
  # MH_CIGAM_64 is good
  dat = open(fn, ""rb"").read()
  dat = b""\xcf\xfa\xed\xfe""+dat[4:]
  from tempfile import NamedTemporaryFile
  with NamedTemporaryFile(delete=False) as f:
    f.write(dat)
    f.close()
  return MachO.MachO(f.name)"
261	label-na	atruong	"def compare(x, y):
  ss = []
  ln = []
  ln2 = []"
262	label-na	atruong	"def fj(x):
  ss = []
  for i in range(0, 0x10, 4):
    ss.append(' '.join(x[i:i+4]))
  return '  '.join(ss)"
263	label-na	atruong	"class ANETensor:
  def __init__(self, *shape):
    self.shape = shape
    self.dtype = np.float16
    self.sz = int(np.prod(shape))
    assert(self.sz <= 0x4000)
    self.tt = libane.ANE_TensorCreate(self.sz, 1)
    assert(self.tt is not None)"
264	label-na	atruong	"class ANE:
  def __init__(self):
    init_libane()
    libane.ANE_Open()"
265	label-na	atruong	"def init_libane():
  global libane, aneregs
  libane = cdll.LoadLibrary(os.path.join(basedir, ""libane.dylib""))"
266	label-na	atruong	"def __init__(self, *shape):
  self.shape = shape
  self.dtype = np.float16
  self.sz = int(np.prod(shape))
  assert(self.sz <= 0x4000)
  self.tt = libane.ANE_TensorCreate(self.sz, 1)
  assert(self.tt is not None)"
267	label-na	atruong	"def data(self):
  data = libane.ANE_TensorData(self.tt)
  assert(data is not None)
  #print(hex(addressof(data.contents)))
  buf = np.ctypeslib.as_array(data, shape=(self.sz,))
  ret = np.frombuffer(buf, dtype=self.dtype)
  #print(ret.data)
  return ret"
268	label-na	atruong	"class vm_region_submap_short_info_data_64(ctypes.Structure):
  _pack_ = 1
  _fields_ = [
      (""protection"", ctypes.c_uint32),
      (""max_protection"", ctypes.c_uint32),
      (""inheritance"", ctypes.c_uint32),
      (""offset"", ctypes.c_ulonglong),
      (""user_tag"", ctypes.c_uint32),
      (""ref_count"", ctypes.c_uint32),
      (""shadow_depth"", ctypes.c_uint16),
      (""external_pager"", ctypes.c_byte),
      (""share_mode"", ctypes.c_byte),
      (""is_submap"", ctypes.c_uint32),
      (""behavior"", ctypes.c_uint32),
      (""object_id"", ctypes.c_uint32),
      (""user_wired_count"", ctypes.c_uint32),
  ]
submap_info_size = ctypes.sizeof(vm_region_submap_short_info_data_64) // 4"
269	label-na	atruong	"def get_pid(name):
  try:
    output = check_output([""pgrep"", name])
    return int(output)
  except:
    return None"
270	label-na	atruong	"class Challenge(jose.TypedJSONObjectWithFields):
    # _fields_to_partial_json
    """"""ACME challenge.""""""
    TYPES: Dict[str, Type['Challenge']] = {}"
271	label-na	atruong	"class ChallengeResponse(jose.TypedJSONObjectWithFields):
    # _fields_to_partial_json
    """"""ACME challenge response.""""""
    TYPES: Dict[str, Type['ChallengeResponse']] = {}"
272	label-na	atruong	"class UnrecognizedChallenge(Challenge):
    """"""Unrecognized challenge."""""""
273	label-na	atruong	"class _TokenChallenge(Challenge):
    """"""Challenge with token."""""""
274	label-na	atruong	"class KeyAuthorizationChallengeResponse(ChallengeResponse):
    """"""Response to Challenges based on Key Authorization.
    """""""
275	label-na	atruong	"class Fixed(jose.Field):
    """"""Fixed field."""""""
276	label-na	atruong	"class RFC3339Field(jose.Field):
    """"""RFC3339 field encoder/decoder.""""""

    def __init__(self, json_name: str, value: Any) -> None:
    self.value = value
    super().__init__(
        json_name=json_name, default=value, omitempty=False)"
277	label-na	atruong	"def decode(self, value: Any) -> Any:
    if value != self.value:
        raise jose.DeserializationError('Expected {0!r}'.format(self.value))
    return self.value"
278	label-na	atruong	"def encode(self, value: Any) -> Any:
    if value != self.value:
        logger.warning(
            'Overriding fixed field (%s) with %r', self.json_name, value)
    return value"
279	label-na	atruong	"class _DefaultCertSelection:
    def __init__(self, certs: Mapping[bytes, Tuple[crypto.PKey, crypto.X509]]):
        self.certs = certs"
280	label-na	atruong	"class SSLSocket:  # pylint: disable=too-few-public-methods
    """"""SSL wrapper for sockets."""""""
281	label-na	atruong	"class FakeConnection:
    """"""Fake OpenSSL.SSL.Connection.""""""

    def __init__(self, certs: Mapping[bytes, Tuple[crypto.PKey, crypto.X509]]):
        self.certs = certs

    def __call__(self, connection: SSL.Connection) -> Optional[Tuple[crypto.PKey, crypto.X509]]:
        server_name = connection.get_servername()
        if server_name:
            return self.certs.get(server_name, None)
        return None # pragma: no cover"
282	label-na	atruong	"class Error(Exception):
    """"""Generic ACME error."""""""
283	label-na	atruong	"class DependencyError(Error):
    """"""Dependency error"""""""
284	label-na	atruong	"class SchemaValidationError(jose_errors.DeserializationError):
    """"""JSON schema ACME object validation error."""""""
285	label-na	atruong	"class ClientError(Error):
    """"""Network error."""""""
286	label-na	atruong	"class UnexpectedUpdate(ClientError):
    """"""Unexpected update error."""""""
287	label-na	atruong	"class _Constant(jose.JSONDeSerializable, Hashable):
    """"""ACME constant.""""""
    __slots__ = ('name',)
    POSSIBLE_NAMES: Dict[str, '_Constant'] = NotImplemented"
288	label-na	atruong	"class IdentifierType(_Constant):
    """"""ACME identifier type.""""""
    POSSIBLE_NAMES: Dict[str, _Constant] = {}"
289	label-na	atruong	"class Identifier(jose.JSONObjectWithFields):
    """"""ACME identifier."""""""
290	label-na	atruong	"class Error(jose.JSONObjectWithFields, errors.Error):
    """"""ACME error."""""""
291	label-na	atruong	"class Status(_Constant):
    """"""ACME ""status"" field.""""""
    POSSIBLE_NAMES: Dict[str, _Constant] = {}"
292	label-na	atruong	"class Header(jose.Header):
    """"""ACME-specific JOSE Header. Implements nonce, kid, and url.
    """"""
    nonce: Optional[bytes] = jose.field('nonce', omitempty=True, encoder=jose.encode_b64jose)
    kid: Optional[str] = jose.field('kid', omitempty=True)
    url: Optional[str] = jose.field('url', omitempty=True)"
293	label-na	atruong	"class Signature(jose.Signature):
    """"""ACME-specific Signature. Uses ACME-specific Header for customer fields.""""""
    __slots__ = jose.Signature._orig_slots  # type: ignore[attr-defined]  # pylint: disable=protected-access,no-member"
294	label-na	atruong	"class JWS(jose.JWS):
    """"""ACME-specific JWS. Includes none, url, and kid in protected header.""""""
    signature_cls = Signature
    __slots__ = jose.JWS._orig_slots  # type: ignore[attr-defined]  # pylint: disable=protected-access"
295	label-na	atruong	"def nonce(value: str) -> bytes:  # type: ignore[misc]  # pylint: disable=no-self-argument,missing-function-docstring
    try:
        return jose.decode_b64jose(value)
    except jose.DeserializationError as error:
        # TODO: custom error
        raise jose.DeserializationError(""Invalid nonce: {0}"".format(error))"
296	label-na	atruong	"def sign(cls, payload: bytes, key: jose.JWK, alg: jose.JWASignature, nonce: Optional[bytes],
         url: Optional[str] = None, kid: Optional[str] = None) -> jose.JWS:
    # Per ACME spec, jwk and kid are mutually exclusive, so only include a
    # jwk field if kid is not provided.
    include_jwk = kid is None
    return super().sign(payload, key=key, alg=alg,
                        protect=frozenset(['nonce', 'url', 'kid', 'jwk', 'alg']),
                        nonce=nonce, url=url, kid=kid,
                        include_jwk=include_jwk)"
297	label-na	atruong	"class ClientV2:
    """"""ACME client for a v2 API."""""""
298	label-na	atruong	"class ClientNetwork:
    """"""Wrapper around requests that signs POSTs for authentication.
    """""""
299	label-na	atruong	"def __init__(self, directory: messages.Directory, net: 'ClientNetwork') -> None:
    """"""Initialize."""""""
300	label-na	atruong	"def new_account(self, new_account: messages.NewRegistration) -> messages.RegistrationResource:
    """"""Register."""""""
301	label-na	atruong	"def query_registration(self, regr: messages.RegistrationResource
                       ) -> messages.RegistrationResource:
    """"""Query server about registration."""""""
302	label-na	atruong	"def get_random_crop_coords(height: int, width: int, crop_height: int, crop_width: int, h_start: float, w_start: float):
    # h_start is [0, 1) and should map to [0, (height - crop_height)]  (note inclusive)
    # This is conceptually equivalent to mapping onto `range(0, (height - crop_height + 1))`
    # See: https://github.com/albumentations-team/albumentations/pull/1080
    y1 = int((height - crop_height + 1) * h_start)
    y2 = y1 + crop_height
    x1 = int((width - crop_width + 1) * w_start)
    x2 = x1 + crop_width
    return x1, y1, x2, y2"
303	label-na	atruong	"def random_crop(img: np.ndarray, crop_height: int, crop_width: int, h_start: float, w_start: float):
    height, width = img.shape[:2]
    if height < crop_height or width < crop_width:
        raise ValueError(
            ""Requested crop size ({crop_height}, {crop_width}) is ""
            ""larger than the image size ({height}, {width})"".format(
                crop_height=crop_height, crop_width=crop_width, height=height, width=width
            )
        )
    x1, y1, x2, y2 = get_random_crop_coords(height, width, crop_height, crop_width, h_start, w_start)
    img = img[y1:y2, x1:x2]
    return img"
304	label-na	atruong	"def crop_bbox_by_coords(
    bbox: BoxInternalType,
    crop_coords: Tuple[int, int, int, int],
    crop_height: int,
    crop_width: int,
    rows: int,
    cols: int,
):
    """"""Crop a bounding box using the provided coordinates of bottom-left and top-right corners in pixels and the
    required height and width of the crop."""""""
305	label-na	atruong	"def bbox_random_crop(
    bbox: BoxInternalType, crop_height: int, crop_width: int, h_start: float, w_start: float, rows: int, cols: int
):
    crop_coords = get_random_crop_coords(rows, cols, crop_height, crop_width, h_start, w_start)
    return crop_bbox_by_coords(bbox, crop_coords, crop_height, crop_width, rows, cols)"
306	label-na	atruong	"def crop_keypoint_by_coords(
    keypoint: KeypointInternalType, crop_coords: Tuple[int, int, int, int]
):  # skipcq: PYL-W0613
    """"""Crop a keypoint using the provided coordinates of bottom-left and top-right corners in pixels and the
    required height and width of the crop."
307	label-na	atruong	"class Blur(ImageOnlyTransform):
    """"""Blur the input image using a random-sized kernel.
    """""""
308	label-na	atruong	"class MotionBlur(Blur):
    """"""Apply motion blur to the input image using a random-sized kernel.
    """""""
309	label-na	atruong	"class MedianBlur(Blur):
    """"""Blur the input image using a median filter with a random aperture linear size.
    """""""
310	label-na	atruong	"class GaussianBlur(ImageOnlyTransform):
    """"""Blur the input image using a Gaussian filter with a random kernel size.
    """""""
311	label-na	atruong	"class GlassBlur(Blur):
    """"""Apply glass noise to the input image."""""""
312	label-na	atruong	"class Command:
    def __init__(self, argv: Optional[str] = None) -> None:
        self.argv = argv or sys.argv[:]
        self.prog_name = Path(self.argv[0]).name"
313	label-na	atruong	"def print_provider(
    doc: Documentor,
    provider: BaseProvider,
    formatters: Dict[str, T],
    excludes: Optional[List[str]] = None,
    output: Optional[TextIO] = None,
) -> None:
    if output is None:
        output = sys.stdout
    if excludes is None:
        excludes = []"
314	label-na	atruong	"def print_doc(
    provider_or_field: Optional[str] = None,
    args: Optional[List[T]] = None,
    lang: str = DEFAULT_LOCALE,
    output: Optional[Union[TextIO, TextIOWrapper]] = None,
    seed: Optional[float] = None,
    includes: Optional[List[str]] = None,
) -> None:
    if args is None:
        args = []
    if output is None:
        output = sys.stdout
    fake = Faker(locale=lang, includes=includes)
    fake.seed_instance(seed)"
315	label-na	atruong	"def __init__(self, argv: Optional[str] = None) -> None:
    self.argv = argv or sys.argv[:]
    self.prog_name = Path(self.argv[0]).name"
316	label-na	atruong	"def _session_faker(request):
    """"""Fixture that stores the session level ``Faker`` instance."
317	label-na	atruong	"def faker(request):
    """"""Fixture that returns a seeded and suitable ``Faker`` instance.""""""
    if ""faker_locale"" in request.fixturenames:
        locale = request.getfixturevalue(""faker_locale"")
        fake = Faker(locale=locale)
    else:
        fake = request.getfixturevalue(""_session_faker"")"
318	label-na	atruong	"def timer(func):
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        tic = time.perf_counter()
        await func(*args, **kwargs)
        toc = time.perf_counter()
        return f""{toc - tic:.4f}"""
319	label-na	atruong	"async def wrapper(*args, **kwargs):
    tic = time.perf_counter()
    await func(*args, **kwargs)
    toc = time.perf_counter()
    return f""{toc - tic:.4f}"""
320	label-na	atruong	"async def set_str(client, gather, data):
    if gather:
        for _ in range(count // 100):
            await asyncio.gather(
                *(
                    asyncio.create_task(client.set(f""bench:str_{i}"", data))
                    for i in range(100)
                )
            )
    else:
        for i in range(count):
            await client.set(f""bench:str_{i}"", data)"
321	label-na	atruong	"async def set_int(client, gather, data):
    if gather:
        for _ in range(count // 100):
            await asyncio.gather(
                *(
                    asyncio.create_task(client.set(f""bench:int_{i}"", data))
                    for i in range(100)
                )
            )
    else:
        for i in range(count):
            await client.set(f""bench:int_{i}"", data)"
322	label-na	atruong	"async def get_str(client, gather):
    if gather:
        for _ in range(count // 100):
            await asyncio.gather(
                *(asyncio.create_task(client.get(f""bench:str_{i}"")) for i in range(100))
            )
    else:
        for i in range(count):
            await client.get(f""bench:str_{i}"")"
323	label-na	atruong	"class Benchmark:
    ARGUMENTS = ()

    def __init__(self):
        self._client = None

    def get_client(self, **kwargs):
        # eventually make this more robust and take optional args from
        # argparse
        if self._client is None or kwargs:
            defaults = {""db"": 9}
            defaults.update(kwargs)
            pool = redis.ConnectionPool(**kwargs)
            self._client = redis.Redis(connection_pool=pool)
        return self._client

     def setup(self, **kwargs):
        pass

    def run(self, **kwargs):
        pass"
324	label-na	atruong	"def __init__(self):
    self._client = None"
325	label-na	atruong	"def get_client(self, **kwargs):
    # eventually make this more robust and take optional args from
    # argparse
    if self._client is None or kwargs:
        defaults = {""db"": 9}
        defaults.update(kwargs)
        pool = redis.ConnectionPool(**kwargs)
        self._client = redis.Redis(connection_pool=pool)
    return self._client"
326	label-na	atruong	"def setup(self, **kwargs):
    pass"
327	label-na	atruong	"def run(self, **kwargs):
    pass"
328	label-na	atruong	"class StringJoiningConnection(Connection):
    def send_packed_command(self, command, check_health=True):
        ""Send an already packed command to the Redis server""
        if not self._sock:
            self.connect()
        try:
            self._sock.sendall(command)
        except OSError as e:
            self.disconnect()
            if len(e.args) == 1:
                _errno, errmsg = ""UNKNOWN"", e.args[0]
            else:
                _errno, errmsg = e.args
            raise ConnectionError(f""Error {_errno} while writing to socket. {errmsg}."")
        except Exception:
            self.disconnect()
            raise"
329	label-na	atruong	"class ListJoiningConnection(Connection):
    def send_packed_command(self, command, check_health=True):
        if not self._sock:
            self.connect()
        try:
            if isinstance(command, str):
                command = [command]
            for item in command:
                self._sock.sendall(item)
        except OSError as e:
            self.disconnect()
            if len(e.args) == 1:
                _errno, errmsg = ""UNKNOWN"", e.args[0]
            else:
                _errno, errmsg = e.args
            raise ConnectionError(f""Error {_errno} while writing to socket. {errmsg}."")
        except Exception:
            self.disconnect()
            raise"
330	label-na	atruong	"def pack_command(self, *args):
    ""Pack a series of arguments into a value Redis command""
    args_output = SYM_EMPTY.join(
        [
            SYM_EMPTY.join(
                (SYM_DOLLAR, str(len(k)).encode(), SYM_CRLF, k, SYM_CRLF)
            )
            for k in map(self.encoder.encode, args)
        ]
    )
    output = SYM_EMPTY.join(
        (SYM_STAR, str(len(args)).encode(), SYM_CRLF, args_output)
    )
    return output"
331	label-na	atruong	"def timer(func):
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        tic = time.perf_counter()
        await func(*args, **kwargs)
        toc = time.perf_counter()
        return f""{toc - tic:.4f}"""
332	label-na	atruong	"async def wrapper(*args, **kwargs):
    tic = time.perf_counter()
    await func(*args, **kwargs)
    toc = time.perf_counter()
    return f""{toc - tic:.4f}"""
333	label-na	atruong	"async def warmup(client):
    await asyncio.gather(
        *(asyncio.create_task(client.exists(f""bench:warmup_{i}"")) for i in range(100))
    )"
334	label-na	atruong	"async def run(client):
    data_str = ""a"" * size
    data_int = int(""1"" * size)"
335	label-na	atruong	"async def main(loop):
    arc = aredis.StrictRedisCluster(
        host=host,
        port=port,
        password=password,
        max_connections=2**31,
        max_connections_per_node=2**31,
        readonly=False,
        reinitialize_steps=count,
        skip_full_coverage_check=True,
        decode_responses=False,
        max_idle_time=count,
        idle_check_interval=count,
    )
    print(f""{loop} {await warmup(arc)} aredis"")
    print(await run(arc))
    arc.connection_pool.disconnect()"
336	label-na	atruong	"def parse_args():
    parser = ArgumentParser()
    parser.add_argument(
        ""-n"", type=int, help=""Total number of requests (default 100000)"", default=100000
    )
    parser.add_argument(
        ""-P"",
        type=int,
        help=(""Pipeline <numreq> requests. Default 1 (no pipeline).""),
        default=1,
    )
    parser.add_argument(
        ""-s"",
        type=int,
        help=""Data size of SET/GET value in bytes (default 2)"",
        default=2,
    )"
337	label-na	atruong	"def run():
    args = parse_args()
    r = redis.Redis()
    r.flushall()
    set_str(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)
    set_int(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)
    get_str(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)
    get_int(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)
    incr(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)
    lpush(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)
    lrange_300(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)
    lpop(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)
    hmset(conn=r, num=args.n, pipeline_size=args.P, data_size=args.s)"
338	label-na	atruong	"def timer(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.monotonic()
        ret = func(*args, **kwargs)
        duration = time.monotonic() - start
        if ""num"" in kwargs:
            count = kwargs[""num""]
        else:
            count = args[1]
        print(f""{func.__name__} - {count} Requests"")
        print(f""Duration  = {duration}"")
        print(f""Rate = {count/duration}"")
        print()
        return ret"
339	label-na	atruong	"def wrapper(*args, **kwargs):
    start = time.monotonic()
    ret = func(*args, **kwargs)
    duration = time.monotonic() - start
    if ""num"" in kwargs:
        count = kwargs[""num""]
    else:
        count = args[1]
    print(f""{func.__name__} - {count} Requests"")
    print(f""Duration  = {duration}"")
    print(f""Rate = {count/duration}"")
    print()
    return ret"
340	label-na	atruong	"def set_str(conn, num, pipeline_size, data_size):
    if pipeline_size > 1:
        conn = conn.pipeline()"
341	label-na	atruong	"def setup(self, value_size, read_size, parser):
    r = self.get_client(parser_class=parser, socket_read_size=read_size)
    r.set(""benchmark"", ""a"" * value_size)"
342	label-na	atruong	"def run(self, value_size, read_size, parser):
    r = self.get_client()
    r.get(""benchmark"")"
343	label-na	atruong	"def to_int(value):
    value = ''.join((x for x in value if x.isdigit()))
    try:
        return int(value)
    except Exception:
        return 0"
344	label-na	atruong	"def to_tuple(version):
    return tuple(to_int(x) for x in version.split('.'))"
345	label-na	atruong	"def main():
    project = sys.argv[1]
    json = requests.get('https://pypi.org/pypi/%s/json' % project).json()
    for version in sorted(json['releases'], key=to_tuple):
        print(version)
        wheel_packages = [
            p for p in json['releases'][version]
            if p['packagetype'] == 'bdist_wheel'
        ]
        for p in wheel_packages:
            print('    %(python_version)s %(filename)s' % p)"
346	label-na	atruong	"def _notebook_run(path):
    """"""Execute a notebook via nbconvert and collect output.
       :returns (parsed nb object, execution errors)
    """"""
    kernel_name = 'python%d' % sys.version_info[0]
    this_file_directory = os.path.dirname(__file__)
    errors = []
    with tempfile.NamedTemporaryFile(suffix="".ipynb"", mode='wt') as fout:
        with smart_open(path, 'rb') as f:
            nb = nbformat.read(f, as_version=4)
            nb.metadata.get('kernelspec', {})['name'] = kernel_name
            ep = ExecutePreprocessor(kernel_name=kernel_name, timeout=10)"
347	label-na	atruong	"def test_notebooks():
    for notebook in glob(""*.ipynb""):
        if "" "" in notebook:
            continue
        print(""Testing {}"".format(notebook))
        nb, errors = _notebook_run(notebook)
        assert errors == []"
348	label-na	atruong	"class MyCorpus:
    def __iter__(self):
        for line in open('https://radimrehurek.com/mycorpus.txt'):
            # assume there's one document per line, tokens separated by whitespace
            yield dictionary.doc2bow(line.lower().split())"
349	label-na	atruong	"def __iter__(self):
    for line in open('https://radimrehurek.com/mycorpus.txt'):
        # assume there's one document per line, tokens separated by whitespace
        yield dictionary.doc2bow(line.lower().split())"
350	label-na	atruong	"class BaseAdapter:
    """"""The Base Transport Adapter"""""""
351	label-na	atruong	"class HTTPAdapter(BaseAdapter):
    """"""The built-in HTTP Adapter for urllib3.
    """""""
352	label-na	atruong	"def request(method, url, **kwargs):
    """"""Constructs and sends a :class:`Request <Request>`.
    """""""
353	label-na	atruong	"def get(url, params=None, **kwargs):
    r""""""Sends a GET request.
    """"""
"
354	label-na	atruong	"def options(url, **kwargs):
    r""""""Sends an OPTIONS request.
    """""""
355	label-na	atruong	"def head(url, **kwargs):
    r""""""Sends a HEAD request.
    """""""
356	label-na	atruong	"def post(url, data=None, json=None, **kwargs):
    r""""""Sends a POST request.
    """""""
357	label-na	atruong	"class FlaskyStyle(Style):
    background_color = ""#f8f8f8""
    default_style = """""
358	label-na	atruong	"class AuthBase:
    """"""Base class that all auth implementations derive from"""""""
359	label-na	atruong	"class HTTPBasicAuth(AuthBase):
    """"""Attaches HTTP Basic Authentication to the given Request object."""""""
360	label-na	atruong	"class HTTPProxyAuth(HTTPBasicAuth):
    """"""Attaches HTTP Proxy Authentication to a given Request object."""""""
361	label-na	atruong	"class HTTPDigestAuth(AuthBase):
    """"""Attaches HTTP Digest Authentication to the given Request object."""""""
362	label-na	atruong	"def to_native_string(string, encoding=""ascii""):
    """"""Given a string object, regardless of type, returns a representation of
    that string in the native string type, encoding and decoding where
    necessary. This assumes ASCII unless told otherwise.
    """"""
    if isinstance(string, builtin_str):
        out = string
    else:
        out = string.decode(encoding)"
363	label-na	atruong	"def unicode_is_ascii(u_string):
    """"""Determine if unicode string only contains ASCII characters.
    """""""
364	label-na	atruong	"def check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):
    urllib3_version = urllib3_version.split(""."")
    assert urllib3_version != [""dev""]  # Verify urllib3 isn't installed from git."
365	label-na	atruong	"def _check_cryptography(cryptography_version):
    # cryptography < 1.3.4
    try:
        cryptography_version = list(map(int, cryptography_version.split(""."")))
    except ValueError:
        return"
366	label-na	atruong	class CompletionRefresher(object):
367	label-na	atruong	"def __init__(self):
    self._completer_thread = None
    self._restart_refresh = threading.Event()"
368	label-na	atruong	"def refresh(self, executor, callbacks, completer_options=None):
    """"""Creates a SQLCompleter object and populates it with the relevant
    completion suggestions in a background thread.
    """""""
369	label-na	atruong	"def is_refreshing(self):
    return self._completer_thread and self._completer_thread.is_alive()"
370	label-na	atruong	"def _bg_refresh(self, sqlexecute, callbacks, completer_options):
    completer = SQLCompleter(**completer_options)"
371	label-na	atruong	"class OutputStyle(PygmentsStyle):
    default_style = """"
    styles = style"
372	label-na	atruong	"def parse_pygments_style(token_name, style_object, style_dict):
    """"""Parse token type and style string.
    """""""
373	label-na	atruong	"def mycli_bindings(mycli):
    """"""Custom key bindings for mycli.""""""
    kb = KeyBindings()"
374	label-na	atruong	"def _(event):
    """"""Enable/Disable SmartCompletion Mode.""""""
    _logger.debug('Detected F2 key.')
    mycli.completer.smart_completion = not mycli.completer.smart_completion"
375	label-na	atruong	"def _(event):
    """"""Enable/Disable Multiline Mode.""""""
    _logger.debug('Detected F3 key.')
    mycli.multi_line = not mycli.multi_line"
376	label-na	atruong	"def _(event):
    """"""Toggle between Vi and Emacs mode.""""""
    _logger.debug('Detected F4 key.')
    if mycli.key_bindings == ""vi"":
        event.app.editing_mode = EditingMode.EMACS
        mycli.key_bindings = ""emacs""
    else:
        event.app.editing_mode = EditingMode.VI
        mycli.key_bindings = ""vi"""
377	label-na	atruong	"def _(event):
    """"""Force autocompletion at cursor.""""""
    _logger.debug('Detected <Tab> key.')
    b = event.app.current_buffer
    if b.complete_state:
        b.complete_next()
    else:
        b.start_completion(select_first=True)"
378	label-na	atruong	"def log(logger, level, message):
    """"""Logs message to stderr if logging isn't initialized."""""""
379	label-na	atruong	"def read_config_file(f, list_values=True):
    """"""Read a config file.
    """""""
380	label-na	atruong	"def get_included_configs(config_file: Union[str, TextIOWrapper]) -> list:
    """"""Get a list of configuration files that are included into config_path
    with !includedir directive.
    """""""
381	label-na	atruong	"def read_config_files(files, list_values=True):
    """"""Read and merge a list of config files."""""""
382	label-na	atruong	"def create_default_config(list_values=True):
    import mycli
    default_config_file = resources.open_text(mycli, 'myclirc')
    return read_config_file(default_config_file, list_values=list_values)"
383	label-na	atruong	"def cli_is_multiline(mycli):
    @Condition
    def cond():
        doc = get_app().layout.get_buffer_by_name(DEFAULT_BUFFER).document"
384	label-na	atruong	"def cond():
    doc = get_app().layout.get_buffer_by_name(DEFAULT_BUFFER).document"
385	label-na	atruong	"def _multiline_exception(text):
    orig = text
    text = text.strip()"
386	label-na	atruong	"def create_toolbar_tokens_func(mycli, show_fish_help):
    """"""Return a function that generates the toolbar tokens.""""""
    def get_toolbar_tokens():
        result = []
        result.append(('class:bottom-toolbar', ' '))"
387	label-na	atruong	"def get_toolbar_tokens():
    result = []
    result.append(('class:bottom-toolbar', ' '))"
388	label-na	atruong	"def _get_vi_mode():
    """"""Get the current vi mode for display.""""""
    return {
        InputMode.INSERT: 'I',
        InputMode.NAVIGATION: 'N',
        InputMode.REPLACE: 'R',
        InputMode.REPLACE_SINGLE: 'R',
        InputMode.INSERT_MULTIPLE: 'M',
    }[get_app().vi_state.input_mode]"
389	label-na	atruong	"class CountInstances(Subcommand):
    def add_subparser(self, parser: argparse._SubParsersAction) -> argparse.ArgumentParser:
        description = """"""Count the number of training instances in an experiment config file.""""""
        subparser = parser.add_parser(self.name, description=description, help=description)
        subparser.add_argument(""param_path"", type=str, help=""path to an experiment config file"")"
390	label-na	atruong	"def count_instances_from_args(args: argparse.Namespace):
    from allennlp.training.util import data_loaders_from_params"
391	label-na	atruong	"class CheckList(Subcommand):
    def add_subparser(self, parser: argparse._SubParsersAction) -> argparse.ArgumentParser:"
392	label-na	atruong	"class _CheckListManager:
    def __init__(
        self,
        task_suite: TaskSuite,
        predictor: Predictor,
        capabilities: Optional[List[str]] = None,
        max_examples: Optional[int] = None,
        output_file: Optional[str] = None,
        print_summary_args: Optional[Dict[str, Any]] = None,
    ) -> None:
        self._task_suite = task_suite
        self._predictor = predictor
        self._capabilities = capabilities
        self._max_examples = max_examples
        self._output_file = None if output_file is None else open(output_file, ""w"")
        self._print_summary_args = print_summary_args or {}"
393	label-na	atruong	"def _get_predictor(args: argparse.Namespace) -> Predictor:
    check_for_gpu(args.cuda_device)
    archive = load_archive(
        args.archive_file,
        cuda_device=args.cuda_device,
    )"
394	label-na	atruong	"def _get_task_suite(args: argparse.Namespace) -> TaskSuite:
    available_tasks = TaskSuite.list_available()
    if args.task in available_tasks:
        suite_name = args.task
    else:
        raise ConfigurationError(
            f""'{args.task}' is not a recognized task suite. ""
            f""Available tasks are: {available_tasks}.""
        )"
395	label-na	atruong	"class BuildVocab(Subcommand):
    def add_subparser(self, parser: argparse._SubParsersAction) -> argparse.ArgumentParser:
        description = """"""Build a vocabulary from an experiment config file.""""""
        subparser = parser.add_parser(self.name, description=description, help=description)"
396	label-na	atruong	"def add_subparser(self, parser: argparse._SubParsersAction) -> argparse.ArgumentParser:
    description = """"""Build a vocabulary from an experiment config file.""""""
    subparser = parser.add_parser(self.name, description=description, help=description)"
397	label-na	atruong	"def build_vocab_from_args(args: argparse.Namespace):
    if not args.output_path.endswith("".tar.gz""):
        raise ValueError(""param 'output_path' should end with '.tar.gz'"")"
398	label-na	atruong	"def _transformers_log_filter(record):
    if record.msg.startswith(""PyTorch version""):
        return False
    return True"
399	label-na	atruong	"def run():
    from allennlp.commands import main  # noqa
    from allennlp.common.util import install_sigterm_handler"
400	label-na	atruong	"class ArgumentParserWithDefaults(argparse.ArgumentParser):
    """"""
    Custom argument parser that will display the default value for an argument
    in the help message.
    """""""
401	label-na	atruong	"def _is_empty_default(default: Any) -> bool:
    if default is None:
        return True
    if isinstance(default, (str, list, tuple, set)):
        return not bool(default)
    return False"
402	label-na	atruong	"def add_argument(self, *args, **kwargs):
    # Add default value to the help message when the default is meaningful.
    default = kwargs.get(""default"")
    if kwargs.get(
        ""action""
    ) not in self._action_defaults_to_ignore and not self._is_empty_default(default):
        description = kwargs.get(""help"", """")
        kwargs[""help""] = f""{description} (default = {default})""
    super().add_argument(*args, **kwargs)"
403	label-na	atruong	"def parse_args(prog: Optional[str] = None) -> Tuple[argparse.ArgumentParser, argparse.Namespace]:
    """"""
    Creates the argument parser for the main program and uses it to parse the args.
    """"""
    parser = ArgumentParserWithDefaults(description=""Run AllenNLP"", prog=prog)
    parser.add_argument(""--version"", action=""version"", version=f""%(prog)s {__version__}"")"
404	label-na	atruong	"def add_subcommands():
    for subcommand_name in sorted(Subcommand.list_available()):
        if subcommand_name in subcommands:
            continue
        subcommands.add(subcommand_name)
        subcommand_class = Subcommand.by_name(subcommand_name)
        subcommand = subcommand_class()
        subparser = subcommand.add_subparser(subparsers)
        if subcommand_class.requires_plugins:
            subparser.add_argument(
                ""--include-package"",
                type=str,
                action=""append"",
                default=[],
                    help=""additional packages to include"",
        )"
405	label-na	atruong	"class CachedPath(Subcommand):
    requires_plugins: bool = False"
406	label-na	atruong	"def add_subparser(self,
                  parser: argparse._SubParsersAction) -> argparse.ArgumentParser:
    description = """"""Cache remote files to the AllenNLP cache.""""""
    subparser = parser.add_parser(
        self.name,
        description=description,
        help=description,
    )
    subparser.set_defaults(func=_cached_path)
    subparser.add_argument(
        ""resources"",
        type=str,
        help=""""""The URLs or paths to the resources.
        If using the --inspect or --remove flag, this can also contain glob patterns."""""",
        nargs=""*"",
    )
    subparser.add_argument(
        ""-d"",
        ""--cache-dir"",
        type=str,
        help=""""""Use a custom cache directory."""""",
        default=CACHE_DIRECTORY,
    )
    subparser.add_argument(
        ""-x"",
        ""--extract-archive"",
        action=""store_true"",
        help=""""""Automatically extract zip or tar.gz archive files."""""",
    )
    subparser.add_argument(
        ""-f"",
        ""--force-extract"",
        action=""store_true"",
        help=""""""Extract archives regardless of whether or not they already exist."""""",
    )
    subparser.add_argument(
        ""--inspect"",
        action=""store_true"",
        help=""""""Print some useful information about the cache."""""",
    )
    subparser.add_argument(
        ""--remove"",
        action=""store_true"",
        help=""""""Remove any cache entries matching the given resource patterns."""""",
    )
    return subparser"
407	label-na	atruong	"def _cached_path(args: argparse.Namespace):
    logger.info(""Cache directory: %s"", args.cache_dir)
    if args.inspect:
        if args.extract_archive or args.force_extract or args.remove:
            raise RuntimeError(
                ""cached-path cannot accept --extract-archive, --force-extract, or --remove ""
                ""options when --inspect flag is used.""
            )
        inspect_cache(patterns=args.resources, cache_dir=args.cache_dir)
    elif args.remove:
        from allennlp.common.util import format_size"
408	label-na	atruong	"class CheckList(Subcommand):  # type: ignore
    def add_subparser(self, parser: argparse._SubParsersAction) -> argparse.ArgumentParser:
        description = """"""Dummy command because checklist is not installed.""""""
        subparser = parser.add_parser(
            self.name,
            description=description,
            help=""Run a trained model through a checklist suite."",
        )
        subparser.set_defaults(func=_dummy_output)
        return subparser"
409	label-na	atruong	"def _dummy_output(args: argparse.Namespace):
   logger.info(
        ""The checklist integration of allennlp is optional; if you're using conda, ""
        ""it can be installed with `conda install allennlp-checklist`, ""
        ""otherwise use `pip install allennlp[checklist]`.""
    )"
410	label-na	atruong	"def add_subparser(self,
                  parser: argparse._SubParsersAction) -> argparse.ArgumentParser:
    description = """"""Dummy command because checklist is not installed.""""""
    subparser = parser.add_parser(
        self.name,
        description=description,
        help=""Run a trained model through a checklist suite."",
    )
    subparser.set_defaults(func=_dummy_output)
    return subparser"
411	label-na	atruong	"def pgcli_bindings(pgcli):
    """"""Custom key bindings for pgcli.""""""
    kb = KeyBindings()"
412	label-na	atruong	"def _(event):
    """"""Enable/Disable SmartCompletion Mode.""""""
    _logger.debug(""Detected F2 key."")
    pgcli.completer.smart_completion = not pgcli.completer.smart_completion"
413	label-na	atruong	"def _(event):
    """"""Enable/Disable Multiline Mode.""""""
    _logger.debug(""Detected F3 key."")
    pgcli.multi_line = not pgcli.multi_line"
414	label-na	atruong	"def _(event):
    """"""Toggle between Vi and Emacs mode.""""""
    _logger.debug(""Detected F4 key."")
    pgcli.vi_mode = not pgcli.vi_mode
    event.app.editing_mode = EditingMode.VI if pgcli.vi_mode else EditingMode.EMACS"
415	label-na	atruong	"def _(event):
    """"""Toggle between Vi and Emacs mode.""""""
    _logger.debug(""Detected F5 key."")
    pgcli.explain_mode = not pgcli.explain_mode"
416	label-na	atruong	"def keyring_initialize(keyring_enabled, *, logger):
    """"""Initialize keyring only if explicitly enabled""""""
    global keyring
    """""""
417	label-na	atruong	"def keyring_get_password(key):
    """"""Attempt to get password from keyring""""""
    # Find password from store
    passwd = """"
    try:
        passwd = keyring.get_password(""pgcli"", key) or """"
    except Exception as e:
        click.secho(
            keyring_error_message.format(
                ""Load your password from keyring returned:"", str(e)
            ),
            err=True,
            fg=""red"",
        )
    return passwd"
418	label-na	atruong	"def keyring_set_password(key, passwd):
    try:
        keyring.set_password(""pgcli"", key, passwd)
    except Exception as e:
        click.secho(
            keyring_error_message.format(""Set password in keyring returned:"", str(e)),
            err=True,
            fg=""red"",
        )"
419	label-na	atruong	"def config_location():
    if ""XDG_CONFIG_HOME"" in os.environ:
        return ""%s/pgcli/"" % expanduser(os.environ[""XDG_CONFIG_HOME""])
    elif platform.system() == ""Windows"":
        return os.getenv(""USERPROFILE"") + ""\\AppData\\Local\\dbcli\\pgcli\\""
    else:
        return expanduser(""~/.config/pgcli/"")"
420	label-na	atruong	"def load_config(usr_cfg, def_cfg=None):
    # avoid config merges when possible. For writing, we need an umerged config instance.
    # see https://github.com/dbcli/pgcli/issues/1240 and https://github.com/DiffSK/configobj/issues/171
    if def_cfg:
        cfg = ConfigObj()
        cfg.merge(ConfigObj(def_cfg, interpolation=False))
        cfg.merge(ConfigObj(expanduser(usr_cfg), interpolation=False, encoding=""utf-8""))
    else:
        cfg = ConfigObj(expanduser(usr_cfg), interpolation=False, encoding=""utf-8"")
    cfg.filename = expanduser(usr_cfg)
    return cfg"
421	label-na	atruong	"def ensure_dir_exists(path):
    parent_dir = expanduser(dirname(path))
    os.makedirs(parent_dir, exist_ok=True)"
422	label-na	atruong	"def write_default_config(source, destination, overwrite=False):
    destination = expanduser(destination)
    if not overwrite and exists(destination):
        return"
423	label-na	atruong	"def upgrade_config(config, def_config):
    cfg = load_config(config, def_config)
    cfg.write()"
424	label-na	atruong	"class ExplainOutputFormatter:
    def __init__(self, max_width):
        self.max_width = max_width"
425	label-na	atruong	"def __init__(self, max_width):
    self.max_width = max_width"
426	label-na	atruong	"def format_output(self, cur, headers, **output_kwargs):
    # explain query results should always contain 1 row each
    [(data,)] = list(cur)
    explain_list = json.loads(data)
    visualizer = Visualizer(self.max_width)
    for explain in explain_list:
        visualizer.load(explain)
        yield visualizer.get_list()"
427	label-na	atruong	"def load_ipython_extension(ipython):
    """"""This is called via the ipython command '%load_ext pgcli.magic'"""""""
428	label-na	atruong	"def pgcli_line_magic(line):
    _logger.debug(""pgcli magic called: %r"", line)
    parsed = sql.parse.parse(line, {})
    # ""get"" was renamed to ""set"" in ipython-sql:
    # https://github.com/catherinedevlin/ipython-sql/commit/f4283c65aaf68f961e84019e8b939e4a3c501d43
    if hasattr(sql.connection.Connection, ""get""):
        conn = sql.connection.Connection.get(parsed[""connection""])
    else:
        try:
            conn = sql.connection.Connection.set(parsed[""connection""])
        # a new positional argument was added to Connection.set in version 0.4.0 of ipython-sql
        except TypeError:
            conn = sql.connection.Connection.set(parsed[""connection""], False)"
429	label-na	atruong	"class CompletionRefresher:
    refreshers = OrderedDict()"
430	label-na	atruong	"def __init__(self):
    self._completer_thread = None
    self._restart_refresh = threading.Event()"
431	label-na	atruong	"def refresh(self, executor, special, callbacks, history=None, settings=None):
    """"""
    Creates a PGCompleter object and populates it with the relevant
    completion suggestions in a background thread.
    """""""
432	label-na	atruong	"def is_refreshing(self):
    return self._completer_thread and self._completer_thread.is_alive()"
433	label-na	atruong	"def _bg_refresh(self, pgexecute, special, callbacks, history=None, settings=None):
    settings = settings or {}
    completer = PGCompleter(
        smart_completion=True, pgspecial=special, settings=settings
    )"
434	label-na	atruong	"class CustomOutputChecker(OutputChecker):
    def check_output(self, want, got, optionflags):
        if IGNORE_RESULT & optionflags:
            return True
        return OutputChecker.check_output(self, want, got, optionflags)"
435	label-na	atruong	"def pytest_configure(config):
    config.addinivalue_line(
        ""markers"", ""is_pt_tf_cross_test: mark test to run only when PT and TF interactions are tested""
    )
    config.addinivalue_line(
        ""markers"", ""is_pt_flax_cross_test: mark test to run only when PT and FLAX interactions are tested""
    )
    config.addinivalue_line(
        ""markers"", ""is_pipeline_test: mark test to run only when pipelines are tested""
    )
    config.addinivalue_line(""markers"", ""is_staging_test: mark test to run only in the staging environment"")"
436	label-na	atruong	"def pytest_addoption(parser):
    from transformers.testing_utils import pytest_addoption_shared"
437	label-na	atruong	"def pytest_terminal_summary(terminalreporter):
    from transformers.testing_utils import pytest_terminal_summary_main"
438	label-na	atruong	"def pytest_sessionfinish(session, exitstatus):
    # If no tests are collected, pytest exists with code 5, which makes the CI fail.
    if exitstatus == 5:
        session.exitstatus = 0"
439	label-na	atruong	"class CircleCIJob:
    name: str
    additional_env: Dict[str, Any] = None
    cache_name: str = None
    cache_version: str = ""0.6""
    docker_image: List[Dict[str, str]] = None
    install_steps: List[str] = None
    marker: Optional[str] = None
    parallelism: Optional[int] = 1
    pytest_num_workers: int = 8
    pytest_options: Dict[str, Any] = None
    resource_class: Optional[str] = ""xlarge""
    tests_to_run: Optional[List[str]] = None
    working_directory: str = ""~/transformers"""
440	label-na	atruong	"def __post_init__(self):
    # Deal with defaults for mutable attributes.
    if self.additional_env is None:
        self.additional_env = {}
    if self.cache_name is None:
        self.cache_name = self.name
    if self.docker_image is None:
        # Let's avoid changing the default list and make a copy.
        self.docker_image = copy.deepcopy(DEFAULT_DOCKER_IMAGE)
    if self.install_steps is None:
        self.install_steps = []
    if self.pytest_options is None:
        self.pytest_options = {}
    if isinstance(self.tests_to_run, str):
        self.tests_to_run = [self.tests_to_run]
    if self.parallelism is None:
        self.parallelism = 1"
441	label-na	atruong	"def to_dict(self):
    env = COMMON_ENV_VARIABLES.copy()
    env.update(self.additional_env)
    job = {
        ""working_directory"": self.working_directory,
        ""docker"": self.docker_image,
        ""environment"": env,
    }
    if self.resource_class is not None:
        job[""resource_class""] = self.resource_class
    if self.parallelism is not None:
        job[""parallelism""] = self.parallelism
    steps = [
        ""checkout"",
        {""attach_workspace"": {""at"": ""~/transformers/test_preparation""}},
        {
            ""restore_cache"": {
                ""keys"": [
                    f""v{self.cache_version}-{self.cache_name}-"" + '{{ checksum ""setup.py"" }}',
                    f""v{self.cache_version}-{self.cache_name}-"",
                ]
            }
        },
    ]
    steps.extend([{""run"": l} for l in self.install_steps])
    steps.append(
        {
            ""save_cache"": {
                ""key"": f""v{self.cache_version}-{self.cache_name}-"" + '{{ checksum ""setup.py"" }}',
                ""paths"": [""~/.cache/pip""],
            }
        }
    )
    steps.append({""run"": {""name"": ""Show installed libraries and their versions"",
                          ""command"": ""pip freeze | tee installed.txt""}})
    steps.append({""store_artifacts"": {""path"": ""~/transformers/installed.txt""}})"
442	label-na	atruong	"def job_name(self):
    return self.name if ""examples"" in self.name else f""tests_{self.name}"""
443	label-na	atruong	"def create_circleci_config(folder=None):
    if folder is None:
        folder = os.getcwd()
    # Used in CircleCIJob.to_dict() to expand the test list (for using parallelism)
    os.environ[""test_preparation_dir""] = folder
    jobs = []
    all_test_file = os.path.join(folder, ""test_list.txt"")
    if os.path.exists(all_test_file):
        with open(all_test_file) as f:
            all_test_list = f.read()
    else:
        all_test_list = []
    if len(all_test_list) > 0:
        jobs.extend(PIPELINE_TESTS)"
444	label-na	atruong	"def hello(name: str = ""world""):
    prefect.get_run_logger().info(f""Hello {name}!"")"
445	label-na	atruong	"async def apply_deployment_20(deployment):
    async with prefect.get_client() as client:
        flow_id = await client.create_flow_from_name(deployment.flow_name)
        return await client.create_deployment(
            flow_id=flow_id,
            name=deployment.name,
            path=deployment.path,
            entrypoint=deployment.entrypoint,
        )"
446	label-na	atruong	"async def create_flow_run(deployment_id):
    async with prefect.get_client() as client:
        return await client.create_flow_run_from_deployment(
            deployment_id, parameters={""name"": ""integration tests""}
        )"
447	label-na	atruong	"async def read_flow_run(flow_run_id):
    async with prefect.get_client() as client:
        return await client.read_flow_run(flow_run_id)"
448	label-na	atruong	"def main():
    # Create deployment
    if Version(prefect.__version__) < Version(""2.1.0""):
        deployment = Deployment(
            name=""test-deployment"",
            flow_name=hello.name,
            parameter_openapi_schema=parameter_schema(hello),
            path=str(pathlib.Path(__file__).parent),
            entrypoint=f""{__file__}:hello"",
        )
        deployment_id = anyio.run(apply_deployment_20, deployment)
    else:
        deployment = Deployment.build_from_flow(flow=hello, name=""test-deployment"")
        deployment_id = deployment.apply()"
449	label-na	atruong	"def hello(name: str = ""world""):
    prefect.get_run_logger().info(f""Hello {name}!"")"
450	label-na	atruong	"async def apply_deployment(deployment):
    async with prefect.get_client() as client:
        flow_id = await client.create_flow_from_name(deployment.flow_name)
        await client.create_deployment(flow_id=flow_id, name=deployment.name)"
451	label-na	atruong	"def noop_function():
    pass"
452	label-na	atruong	"def bench_task_decorator(benchmark: BenchmarkFixture):
    benchmark(task, noop_function)"
453	label-na	atruong	"def bench_task_call(benchmark: BenchmarkFixture):
    noop_task = task(noop_function)"
454	label-na	atruong	"def benchmark_flow():
    benchmark(noop_task)"
455	label-na	atruong	"def bench_task_submit(benchmark: BenchmarkFixture, num_task_runs: int):
    noop_task = task(noop_function)"
456	label-na	atruong	"def reset_object_registry():
    """"""
    Ensures each test has a clean object registry.
    """"""
    from prefect.context import PrefectObjectRegistry"
457	label-na	atruong	"def noop_function():
    pass"
458	label-na	atruong	"async def anoop_function():
    pass"
459	label-na	atruong	"def bench_flow_decorator(benchmark: BenchmarkFixture):
    benchmark(flow, noop_function)"
460	label-na	atruong	"def bench_flow_call(benchmark: BenchmarkFixture, options):
    noop_flow = flow(**options)(noop_function)
    benchmark(noop_flow)"
461	label-na	atruong	"def bench_flow_with_submitted_tasks(benchmark: BenchmarkFixture, num_tasks: int):
    test_task = task(noop_function)"
462	label-na	atruong	"def convert(mxnet_name, torch_name):
    # download and load the pre-trained model
    net = gluoncv.model_zoo.get_model(mxnet_name, pretrained=True)"
463	label-na	atruong	"def map_mx_to_torch_model(mx_name):
    torch_name = mx_name.lower()
    if torch_name.startswith('se_'):
        torch_name = torch_name.replace('se_', 'se')
    elif torch_name.startswith('senet_'):
        torch_name = torch_name.replace('senet_', 'senet')
    elif torch_name.startswith('inceptionv3'):
        torch_name = torch_name.replace('inceptionv3', 'inception_v3')
    torch_name = 'gluon_' + torch_name
    return torch_name"
464	label-na	atruong	"def main():
    args = parser.parse_args()"
465	label-na	atruong	"def convert_nest(checkpoint_path, arch):
    """"""
    Expects path to checkpoint which is a dir containing 4 files like in each of these folders
        - https://console.cloud.google.com/storage/browser/gresearch/nest-checkpoints
    `arch` is needed to 
    Returns a state dict that can be used with `torch.nn.Module.load_state_dict`
    Hint: Follow timm.models.nest.Nest.__init__ and 
    https://github.com/google-research/nested-transformer/blob/main/models/nest_net.py
    """"""
    assert arch in ['nest_base', 'nest_small', 'nest_tiny'], ""Your `arch` is not supported"""
466	label-na	atruong	"class BenchmarkRunner:
    def __init__(
            self,
            model_name,
            detail=False,
            device='cuda',
            torchscript=False,
            torchcompile=None,
            aot_autograd=False,
            precision='float32',
            fuser='',
            num_warm_iter=10,
            num_bench_iter=50,
            use_train_size=False,
            **kwargs
    ):
        self.model_name = model_name
        self.detail = detail
        self.device = device
        self.amp_dtype, self.model_dtype, self.data_dtype = resolve_precision(precision)
        self.channels_last = kwargs.pop('channels_last', False)
        if self.amp_dtype is not None:
            self.amp_autocast = partial(torch.cuda.amp.autocast, dtype=self.amp_dtype)
        else:
            self.amp_autocast = suppress"
467	label-na	atruong	class InferenceBenchmarkRunner(BenchmarkRunner):
468	label-na	atruong	class TrainBenchmarkRunner(BenchmarkRunner):
469	label-na	atruong	class ProfileRunner(BenchmarkRunner):
470	label-na	atruong	"def timestamp(sync=False):
    return time.perf_counter()"
471	label-na	atruong	"def cmd_from_args(args) -> Tuple[Union[Callable, str], List[str]]:
    # If ``args`` not passed, defaults to ``sys.argv[:1]``
    with_python = not args.no_python
    cmd: Union[Callable, str]
    cmd_args = []
    if with_python:
        cmd = os.getenv(""PYTHON_EXEC"", sys.executable)
        cmd_args.append(""-u"")
        if args.module:
            cmd_args.append(""-m"")
        cmd_args.append(args.script)
    else:
        if args.module:
            raise ValueError(
                ""Don't use both the '--no_python' flag""
                "" and the '--module' flag at the same time.""
            )
        cmd = args.script
    cmd_args.extend(args.script_args)"
472	label-na	atruong	"def main():
    args = parser.parse_args()
    cmd, cmd_args = cmd_from_args(args)"
473	label-na	atruong	"def write_results(results_file, results):
    with open(results_file, mode='w') as cf:
        dw = csv.DictWriter(cf, fieldnames=results[0].keys())
        dw.writeheader()
        for r in results:
            dw.writerow(r)
        cf.flush()"
474	label-na	atruong	"def checkpoint_metric(checkpoint_path):
    if not checkpoint_path or not os.path.isfile(checkpoint_path):
        return {}
    print(""=> Extracting metric from checkpoint '{}'"".format(checkpoint_path))
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    metric = None
    if 'metric' in checkpoint:
        metric = checkpoint['metric']
    elif 'metrics' in checkpoint and 'metric_name' in checkpoint:
        metrics = checkpoint['metrics']
        print(metrics)
        metric = metrics[checkpoint['metric_name']]
    return metric"
475	label-na	atruong	"def main():
    args = parser.parse_args()
    # by default use the EMA weights (if present)
    args.use_ema = not args.no_use_ema
    # by default sort by checkpoint metric (if present) and avg top n checkpoints
    args.sort = not args.no_sort"
476	label-na	atruong	"def generate_readmes(templates_path: Path, dest_path: Path):
    """"""Add the code snippet template to the readmes""""""
    readme_templates_path = templates_path / ""models""
    code_template_path = templates_path / ""code_snippets.md"""
477	label-na	atruong	"def main():
    parser = argparse.ArgumentParser(description=""Model index generation config"")
    parser.add_argument(
        ""-t"",
        ""--templates"",
        default=Path(__file__).parent / "".templates"",
        type=str,
        help=""Location of the markdown templates"",
    )
    parser.add_argument(
        ""-d"",
        ""--dest"",
        default=Path(__file__).parent / ""models"",
        type=str,
        help=""Destination folder that contains the generated model-index files."",
    )
    args = parser.parse_args()
    templates_path = Path(args.templates)
    dest_readmes_path = Path(args.dest)"
478	label-na	atruong	"def main():
    args = parser.parse_args()"
479	label-na	atruong	"def clean_checkpoint(
        checkpoint,
        output,
        use_ema=True,
        no_hash=False,
        clean_aux_bn=False,
        safe_serialization: bool=False,
):
    # Load an existing checkpoint to CPU, strip everything but the state_dict and re-save
    if checkpoint and os.path.isfile(checkpoint):
        print(""=> Loading checkpoint '{}'"".format(checkpoint))
        state_dict = load_state_dict(checkpoint, use_ema=use_ema)
        new_state_dict = {}
        for k, v in state_dict.items():
            if clean_aux_bn and 'aux_bn' in k:
                # If all aux_bn keys are removed, the SplitBN layers will end up as normal and
                # load with the unmodified model using BatchNorm2d.
                continue
            name = k[7:] if k.startswith('module.') else k
            new_state_dict[name] = v
        print(""=> Loaded state_dict from '{}'"".format(checkpoint))"
480	label-na	atruong	"def pytest_addoption(parser):
    parser.addoption(""--runslow"", action=""store_true"", help=""run slow tests"")"
481	label-na	atruong	"def pytest_runtest_setup(item):
    if ""slow"" in item.keywords and not item.config.getoption(""--runslow""):
        pytest.skip(""need --runslow option to run"")"
482	label-na	atruong	"def pytest_collection_modifyitems(config, items):
    for item in items:
        if ""skip_with_pyarrow_strings"" in item.keywords:
            item.add_marker(skip_with_pyarrow_strings)
        if ""xfail_with_pyarrow_strings"" in item.keywords:
            item.add_marker(xfail_with_pyarrow_strings)"
483	label-na	atruong	"def shuffle_method(request):
    with dask.config.set({""dataframe.shuffle.method"": request.param}):
        yield request.param"
484	label-na	atruong	"class NumpyBackendEntrypoint(ArrayBackendEntrypoint):
    @classmethod
    def to_backend_dispatch(cls):
        return to_numpy_dispatch"
485	label-na	atruong	"def percentile(a, q, method=""linear""):
    return _percentile(a, q, method)"
486	label-na	atruong	"def _concatenate(arrays, axis=0):
    out = np.ma.concatenate(arrays, axis=axis)
    fill_values = [i.fill_value for i in arrays if hasattr(i, ""fill_value"")]
    if any(isinstance(f, np.ndarray) for f in fill_values):
        raise ValueError(
            ""Dask doesn't support masked array's with non-scalar `fill_value`s""
        )
    if fill_values:
        # If all the fill_values are the same copy over the fill value
        fill_values = np.unique(fill_values)
        if len(fill_values) == 1:
            out.fill_value = fill_values[0]
    return out
"
487	label-na	atruong	"def _tensordot(a, b, axes=2):
    # Much of this is stolen from numpy/core/numeric.py::tensordot
    # Please see license at https://github.com/numpy/numpy/blob/master/LICENSE.txt
    try:
        iter(axes)
    except TypeError:
        axes_a = list(range(-axes, 0))
        axes_b = list(range(0, axes))
    else:
        axes_a, axes_b = axes
    try:
        na = len(axes_a)
        axes_a = list(axes_a)
    except TypeError:
        axes_a = [axes_a]
        na = 1
    try:
        nb = len(axes_b)
        axes_b = list(axes_b)
    except TypeError:
        axes_b = [axes_b]
        nb = 1"
488	label-na	atruong	"def keepdims_wrapper(a_callable):
    """"""
    A wrapper for functions that don't provide keepdims to ensure that they do.
    """""""
489	label-na	atruong	"def keepdims_wrapped_callable(x, axis=None, keepdims=None, *args, **kwargs):
    r = a_callable(x, *args, axis=axis, **kwargs)"
490	label-na	atruong	"def coarsen(reduction, x, axes, trim_excess=False, **kwargs):
    """"""Coarsen array by applying reduction to fixed size neighborhoods
    """""""
491	label-na	atruong	"def trim(x, axes=None):
    """"""Trim boundaries off of array
    """""""
492	label-na	atruong	"def topk(a, k, axis, keepdims):
    """"""Chunk and combine function of topk
    """""""
493	label-na	atruong	"def blockwise(
    func,
    out_ind,
    *args,
    name=None,
    token=None,
    dtype=None,
    adjust_chunks=None,
    new_axes=None,
    align_arrays=True,
    concatenate=None,
    meta=None,
    **kwargs,
):
    """"""Tensor operation: Generalized inner and outer products
        >>> def sequence_dot(a_blocks, b_blocks):
    ...     result = 0
    ...     for a, b in zip(a_blocks, b_blocks):
    ...         result += a.dot(b)
    ...     return result
    >>> def f(a):
    ...     return a[:, None] * np.ones((1, 5))
    >>> def double(x):
    ...     return np.concatenate([x, x])
    """"""

"
494	label-na	atruong	"def main():
    run_cli()"
495	label-na	atruong	"class VersioneerConfig:
    """"""Container for Versioneer configuration parameters."""""""
496	label-na	atruong	"class NotThisMethod(Exception):
    """"""Exception raised if a method is not valid for the current scenario."""""""
497	label-na	atruong	"def get_keywords():
    """"""Get the keywords needed to look up the version information.""""""
    # these strings will be replaced by git during git-archive.
    # setup.py/versioneer.py will grep for the variable names, so they must
    # each be defined on a line of their own. _version.py will just call
    # get_keywords().
    git_refnames = ""$Format:%d$""
    git_full = ""$Format:%H$""
    keywords = {""refnames"": git_refnames, ""full"": git_full}
    return keywords"
498	label-na	atruong	"def get_config():
    """"""Create, populate and return the VersioneerConfig() object.""""""
    # these strings are filled in when 'setup.py versioneer' creates
    # _version.py
    cfg = VersioneerConfig()
    cfg.VCS = ""git""
    cfg.style = ""pep440""
    cfg.tag_prefix = """"
    cfg.parentdir_prefix = ""dask-""
    cfg.versionfile_source = ""dask/_version.py""
    cfg.verbose = False
    return cfg"
499	label-na	atruong	"def register_vcs_handler(vcs, method):  # decorator
    """"""Decorator to mark a method as the handler for a particular VCS."""""""
