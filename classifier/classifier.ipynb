{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Python Code Readability\n",
    "\n",
    "Will Tholke, Alex Truong, Andrew Zhang"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn import linear_model\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "import re\n",
    "from scipy.stats import norm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\r\n",
      "  warn(RuntimeWarning(msg))\r\n",
      "[nltk_data] Downloading package punkt to\r\n",
      "[nltk_data]     /Users/willtholke/nltk_data...\r\n",
      "[nltk_data]   Package punkt is already up-to-date!\r\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader punkt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading & Pre-processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    cleaned_text = text.replace('<newline>', '\\n')\n",
    "    return cleaned_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "outputs": [],
   "source": [
    "def load_ordinal_data(filename, ordering):\n",
    "    X = []\n",
    "    Y = []\n",
    "    orig_Y = []\n",
    "\n",
    "    for _ in ordering:\n",
    "        Y.append([])\n",
    "\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols = line.split(\"\\t\")\n",
    "            label = cols[2].lstrip().rstrip()\n",
    "            text = cols[3]\n",
    "\n",
    "            preprocess(text)\n",
    "            X.append(text)\n",
    "\n",
    "            index = ordering.index(label)\n",
    "            for i in range(len(ordering)):\n",
    "                if index > i:\n",
    "                    Y[i].append(1)\n",
    "                else:\n",
    "                    Y[i].append(0)\n",
    "            orig_Y.append(label)\n",
    "\n",
    "    return X, Y, orig_Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ordinal Classifier Definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "outputs": [],
   "source": [
    "class OrdinalClassifier:\n",
    "\n",
    "    def __init__(self, ordinal_values, feature_method, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY):\n",
    "        self.ordinal_values=ordinal_values\n",
    "        self.feature_vocab = {}\n",
    "        self.feature_method = feature_method\n",
    "        self.min_feature_count=2\n",
    "        self.log_regs = [None] * (len(self.ordinal_values)-1)\n",
    "\n",
    "        self.trainY=trainY\n",
    "        self.devY=devY\n",
    "        self.testY=testY\n",
    "\n",
    "        self.orig_trainY=orig_trainY\n",
    "        self.orig_devY=orig_devY\n",
    "        self.orig_testY=orig_testY\n",
    "\n",
    "        self.trainX = self.process(trainX, training=True)\n",
    "        self.devX = self.process(devX, training=False)\n",
    "        self.testX = self.process(testX, training=False)\n",
    "\n",
    "        self.predictions = []\n",
    "\n",
    "    # Featurize entire dataset\n",
    "    def featurize(self, data):\n",
    "        featurized_data = []\n",
    "        for text in data:\n",
    "            feats = self.feature_method(text)\n",
    "            featurized_data.append(feats)\n",
    "        return featurized_data\n",
    "\n",
    "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
    "    def process(self, X_data, training = False):\n",
    "\n",
    "        data = self.featurize(X_data)\n",
    "\n",
    "        if training:\n",
    "            fid = 0\n",
    "            feature_doc_count = Counter()\n",
    "            for feats in data:\n",
    "                for feat in feats:\n",
    "                    feature_doc_count[feat]+= 1\n",
    "\n",
    "            for feat in feature_doc_count:\n",
    "                if feature_doc_count[feat] >= self.min_feature_count:\n",
    "                    self.feature_vocab[feat] = fid\n",
    "                    fid += 1\n",
    "\n",
    "        F = len(self.feature_vocab)\n",
    "        D = len(data)\n",
    "        X = sparse.dok_matrix((D, F))\n",
    "        for idx, feats in enumerate(data):\n",
    "            for feat in feats:\n",
    "                if feat in self.feature_vocab:\n",
    "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
    "\n",
    "        return X\n",
    "\n",
    "    def train(self):\n",
    "        (D,F) = self.trainX.shape\n",
    "\n",
    "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
    "            best_dev_accuracy=0\n",
    "            best_model=None\n",
    "            for C in [0.0001, 0.001, 0.1, 1, 5, 10, 50, 100, 1000]:\n",
    "\n",
    "                log_reg = linear_model.LogisticRegression(C = C, max_iter=1000)\n",
    "                log_reg.fit(self.trainX, self.trainY[idx])\n",
    "\n",
    "                development_accuracy = log_reg.score(self.devX, self.devY[idx])\n",
    "                if development_accuracy > best_dev_accuracy:\n",
    "                    best_dev_accuracy=development_accuracy\n",
    "                    best_model=log_reg\n",
    "\n",
    "\n",
    "            self.log_regs[idx]=best_model\n",
    "\n",
    "    def test(self):\n",
    "        cor=tot=0\n",
    "        counts=Counter()\n",
    "        preds=[None]*(len(self.ordinal_values)-1)\n",
    "        for idx, ordinal_value in enumerate(self.ordinal_values[:-1]):\n",
    "            preds[idx]=self.log_regs[idx].predict_proba(self.testX)[:,1]\n",
    "\n",
    "        preds=np.array(preds)\n",
    "\n",
    "        for data_point in range(len(preds[0])):\n",
    "\n",
    "\n",
    "            ordinal_preds=np.zeros(len(self.ordinal_values))\n",
    "            for ordinal in range(len(self.ordinal_values)-1):\n",
    "                if ordinal == 0:\n",
    "                    ordinal_preds[ordinal]=1-preds[ordinal][data_point]\n",
    "                else:\n",
    "                    ordinal_preds[ordinal]=preds[ordinal-1][data_point]-preds[ordinal][data_point]\n",
    "\n",
    "            ordinal_preds[len(self.ordinal_values)-1]=preds[len(preds)-1][data_point]\n",
    "\n",
    "            prediction=np.argmax(ordinal_preds)\n",
    "            self.predictions.append(prediction+1)\n",
    "\n",
    "            counts[prediction]+=1\n",
    "            if prediction == self.ordinal_values.index(self.orig_testY[data_point]):\n",
    "                cor+=1\n",
    "            tot+=1\n",
    "\n",
    "        return cor/tot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature 1: Code Length and Repetition (Section 2.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "outputs": [],
   "source": [
    "def check_line_length(text, code_max_length=79, docstring_max_length=72):\n",
    "    \"\"\" Check if lines of code, docstrings, and inline comments do not exceed their maximum allowable lengths. \"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if len(line) > code_max_length:\n",
    "            return False\n",
    "        if line.startswith('#') or line.strip().startswith('\"\"\"') or line.strip().startswith(\"'''\"):\n",
    "            if len(line) > docstring_max_length:\n",
    "                return False\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature 2: Inline Comments and Docstrings (Section 2.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "outputs": [],
   "source": [
    "def check_comments_docstrings(text):\n",
    "    \"\"\" Check if at least one of the following is present: docstring, inline comment, assert statement, error handling. \"\"\"\n",
    "    if re.search(r'\"\"\"(.|\\n)*?\"\"\"', text) or re.search(r\"'''(.|\\n)*?'''\", text) or re.search(r'#', text):\n",
    "        return True\n",
    "    # Omitted: checks for assert statements and error handling\n",
    "\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature 3: Naming Conventions and Case (Section 2.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "outputs": [],
   "source": [
    "def check_naming_conventions(text):\n",
    "    \"\"\" Check if the class name is in CamelCase or the function name is in snake_case. Check if variables are in snake_case. \"\"\"\n",
    "    if not (re.search(r'\\bclass\\s+[A-Z][a-zA-Z0-9]*', text) or re.search(r'\\bdef\\s+[a-z_][a-zA-Z0-9]*', text)):\n",
    "        return False\n",
    "\n",
    "    variable_pattern = r'\\b[a-z][a-zA-Z0-9_]*\\s*='\n",
    "    variable_matches = re.findall(variable_pattern, text)\n",
    "\n",
    "    for match in variable_matches:\n",
    "        var_name = match.strip().rstrip('=').strip()\n",
    "        if not re.match(r'^[a-z][a-zA-Z0-9_]*$', var_name):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def check_descriptive_params(text):\n",
    "    \"\"\" Check if function and class parameters are self-explanatory. \"\"\"\n",
    "    bad_params = {'x', 'y', 'temp', 'param', 'input', 'temp', 'i', 'j', 'k'}\n",
    "    function_pattern = r'\\bdef\\s+[a-z_][a-zA-Z0-9]*\\s*\\((.*?)\\)'\n",
    "    class_pattern = r'\\bclass\\s+[A-Z][a-zA-Z0-9]*\\s*\\((.*?)\\)'\n",
    "    function_matches = re.findall(function_pattern, text)\n",
    "    class_matches = re.findall(class_pattern, text)\n",
    "\n",
    "    for params in function_matches + class_matches:\n",
    "        param_list = [p.strip() for p in params.split(',')]\n",
    "        for param in param_list:\n",
    "            if param in bad_params:\n",
    "                return False\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature 4: Whitespace (Section 2.4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "outputs": [],
   "source": [
    "def check_whitespace(text):\n",
    "    \"\"\" Check for consistency between tabs and spaces for indentation. \"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    space_indented = [line.startswith(' ') for line in lines if line.strip()]\n",
    "    tab_indented = [line.startswith('\\t') for line in lines if line.strip()]\n",
    "    return not (any(space_indented) and any(tab_indented))\n",
    "\n",
    "def check_blank_lines(text):\n",
    "    \"\"\" Check whether blank lines are used sparingly. \"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    blank_line = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            blank_line += 1\n",
    "            if blank_line > 1:\n",
    "                return False\n",
    "        else:\n",
    "            blank_line = 0\n",
    "\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature 5: Miscellaneous (Section 2.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "outputs": [],
   "source": [
    "def check_misc(text):\n",
    "    \"\"\" Check for residual to-do statements and comparison of boolean values. \"\"\"\n",
    "    if re.search(r'\\bTrue\\b', text) or re.search(r'\\bFalse\\b', text) or re.search(r'todo', text, re.IGNORECASE):\n",
    "        return False\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Combination"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "outputs": [],
   "source": [
    "def feature_method(text):\n",
    "    features = {\n",
    "        'line_length': check_line_length(text),\n",
    "        'comments_docstrings': check_comments_docstrings(text),\n",
    "        'naming_conventions': check_naming_conventions(text),\n",
    "        'descriptive_params': check_descriptive_params(text),\n",
    "        'whitespace_consistency': check_whitespace(text),\n",
    "        'blank_lines': check_blank_lines(text),\n",
    "        'misc': check_misc(text),\n",
    "    }\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "outputs": [],
   "source": [
    "def confidence_intervals(accuracy, n, significance_level):\n",
    "    critical_value=(1-significance_level)/2\n",
    "    z_alpha=-1*norm.ppf(critical_value)\n",
    "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
    "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "outputs": [],
   "source": [
    "def run(trainingFile, devFile, testFile, ordinal_values):\n",
    "    trainX, trainY, orig_trainY = load_ordinal_data(trainingFile, ordinal_values)\n",
    "    devX, devY, orig_devY = load_ordinal_data(devFile, ordinal_values)\n",
    "    testX, testY, orig_testY = load_ordinal_data(testFile, ordinal_values)\n",
    "\n",
    "    simple_classifier = OrdinalClassifier(ordinal_values, feature_method, trainX, trainY, devX, devY, testX, testY, orig_trainY, orig_devY, orig_testY)\n",
    "    simple_classifier.train()\n",
    "    accuracy = simple_classifier.test()\n",
    "\n",
    "    lower, upper = confidence_intervals(accuracy, len(testY[0]), .95)\n",
    "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
    "    return simple_classifier.predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for best dev model: 0.730, 95% CIs: [0.643 0.817]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingFile = \"splits/train.txt\"\n",
    "devFile = \"splits/dev.txt\"\n",
    "testFile = \"splits/test.txt\"\n",
    "\n",
    "ordinal_values = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "run(trainingFile, devFile, testFile, ordinal_values);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part B: Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "outputs": [],
   "source": [
    "# The analysis here should communicate what kind of information others should know if they were to use our model as well as aspects of some fundamental concept that you hadn't considered while annotating. We will be graded on the depth of our analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for best dev model: 0.730, 95% CIs: [0.643 0.817]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run(trainingFile, devFile, testFile, ordinal_values);"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
